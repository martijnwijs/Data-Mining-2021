{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np \n",
    "from sklearn.model_selection import train_test_split\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>no</th>\n",
       "      <th>target</th>\n",
       "      <th>t</th>\n",
       "      <th>activity</th>\n",
       "      <th>appCat.builtin</th>\n",
       "      <th>appCat.communication</th>\n",
       "      <th>appCat.entertainment</th>\n",
       "      <th>appCat.finance</th>\n",
       "      <th>appCat.game</th>\n",
       "      <th>...</th>\n",
       "      <th>appCat.travel</th>\n",
       "      <th>appCat.unknown</th>\n",
       "      <th>appCat.utilities</th>\n",
       "      <th>appCat.weather</th>\n",
       "      <th>call</th>\n",
       "      <th>circumplex.arousal</th>\n",
       "      <th>circumplex.valence</th>\n",
       "      <th>mood</th>\n",
       "      <th>screen</th>\n",
       "      <th>sms</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0.641645</td>\n",
       "      <td>1.103108</td>\n",
       "      <td>1.636492</td>\n",
       "      <td>0.244791</td>\n",
       "      <td>1.129913</td>\n",
       "      <td>-0.259976</td>\n",
       "      <td>...</td>\n",
       "      <td>4.689448</td>\n",
       "      <td>-0.322651</td>\n",
       "      <td>7.439909</td>\n",
       "      <td>-0.230130</td>\n",
       "      <td>1.319838</td>\n",
       "      <td>0.485487</td>\n",
       "      <td>-1.266137</td>\n",
       "      <td>-1.209901</td>\n",
       "      <td>2.770542</td>\n",
       "      <td>-0.497599</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1.074310</td>\n",
       "      <td>-0.242798</td>\n",
       "      <td>1.062958</td>\n",
       "      <td>-0.575133</td>\n",
       "      <td>0.292739</td>\n",
       "      <td>-0.259976</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.207470</td>\n",
       "      <td>-0.322651</td>\n",
       "      <td>1.198651</td>\n",
       "      <td>-0.230130</td>\n",
       "      <td>0.287520</td>\n",
       "      <td>1.143750</td>\n",
       "      <td>-0.496733</td>\n",
       "      <td>-0.899697</td>\n",
       "      <td>0.106958</td>\n",
       "      <td>0.147818</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>0.065088</td>\n",
       "      <td>0.067334</td>\n",
       "      <td>1.182367</td>\n",
       "      <td>-0.574217</td>\n",
       "      <td>0.949321</td>\n",
       "      <td>-0.259976</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.415500</td>\n",
       "      <td>-0.322651</td>\n",
       "      <td>0.063147</td>\n",
       "      <td>2.406086</td>\n",
       "      <td>-0.744797</td>\n",
       "      <td>0.485487</td>\n",
       "      <td>0.272670</td>\n",
       "      <td>-0.279289</td>\n",
       "      <td>0.249101</td>\n",
       "      <td>-0.497599</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>-0.085503</td>\n",
       "      <td>-0.167041</td>\n",
       "      <td>2.937521</td>\n",
       "      <td>0.217447</td>\n",
       "      <td>0.675919</td>\n",
       "      <td>-0.259976</td>\n",
       "      <td>...</td>\n",
       "      <td>1.925529</td>\n",
       "      <td>-0.322651</td>\n",
       "      <td>1.991383</td>\n",
       "      <td>-0.230130</td>\n",
       "      <td>2.696262</td>\n",
       "      <td>1.472881</td>\n",
       "      <td>-1.779072</td>\n",
       "      <td>-1.520105</td>\n",
       "      <td>2.110863</td>\n",
       "      <td>-0.497599</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>1.074310</td>\n",
       "      <td>-0.242798</td>\n",
       "      <td>1.062958</td>\n",
       "      <td>-0.575133</td>\n",
       "      <td>0.292739</td>\n",
       "      <td>-0.259976</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.207470</td>\n",
       "      <td>-0.322651</td>\n",
       "      <td>1.198651</td>\n",
       "      <td>-0.230130</td>\n",
       "      <td>0.287520</td>\n",
       "      <td>1.143750</td>\n",
       "      <td>-0.496733</td>\n",
       "      <td>-0.899697</td>\n",
       "      <td>0.106958</td>\n",
       "      <td>0.147818</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4191</th>\n",
       "      <td>4191</td>\n",
       "      <td>1048</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>0.272023</td>\n",
       "      <td>0.774332</td>\n",
       "      <td>-0.254069</td>\n",
       "      <td>-0.107484</td>\n",
       "      <td>-0.327054</td>\n",
       "      <td>-0.259976</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.415500</td>\n",
       "      <td>-0.322651</td>\n",
       "      <td>0.070671</td>\n",
       "      <td>-0.230130</td>\n",
       "      <td>2.696262</td>\n",
       "      <td>0.156356</td>\n",
       "      <td>1.298542</td>\n",
       "      <td>1.892137</td>\n",
       "      <td>1.947385</td>\n",
       "      <td>0.147818</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4192</th>\n",
       "      <td>4192</td>\n",
       "      <td>1049</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.328753</td>\n",
       "      <td>-0.065428</td>\n",
       "      <td>-0.559067</td>\n",
       "      <td>-0.041053</td>\n",
       "      <td>-0.327054</td>\n",
       "      <td>-0.259976</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.415500</td>\n",
       "      <td>-0.322651</td>\n",
       "      <td>-0.327129</td>\n",
       "      <td>-0.230130</td>\n",
       "      <td>2.696262</td>\n",
       "      <td>-0.501907</td>\n",
       "      <td>-1.779072</td>\n",
       "      <td>-2.450716</td>\n",
       "      <td>2.983480</td>\n",
       "      <td>1.438652</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4193</th>\n",
       "      <td>4193</td>\n",
       "      <td>1049</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>-1.058736</td>\n",
       "      <td>-0.245614</td>\n",
       "      <td>-0.192281</td>\n",
       "      <td>-0.546996</td>\n",
       "      <td>-0.327054</td>\n",
       "      <td>-0.259976</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.415500</td>\n",
       "      <td>-0.322651</td>\n",
       "      <td>0.401548</td>\n",
       "      <td>-0.230130</td>\n",
       "      <td>-0.400691</td>\n",
       "      <td>-0.831038</td>\n",
       "      <td>-0.753201</td>\n",
       "      <td>-1.209901</td>\n",
       "      <td>-0.354860</td>\n",
       "      <td>0.793235</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4194</th>\n",
       "      <td>4194</td>\n",
       "      <td>1049</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>0.272023</td>\n",
       "      <td>0.774332</td>\n",
       "      <td>-0.254069</td>\n",
       "      <td>-0.107484</td>\n",
       "      <td>-0.327054</td>\n",
       "      <td>-0.259976</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.415500</td>\n",
       "      <td>-0.322651</td>\n",
       "      <td>0.070671</td>\n",
       "      <td>-0.230130</td>\n",
       "      <td>2.696262</td>\n",
       "      <td>0.156356</td>\n",
       "      <td>1.298542</td>\n",
       "      <td>1.892137</td>\n",
       "      <td>1.947385</td>\n",
       "      <td>0.147818</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4195</th>\n",
       "      <td>4195</td>\n",
       "      <td>1049</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>1.242266</td>\n",
       "      <td>-0.428041</td>\n",
       "      <td>-0.907386</td>\n",
       "      <td>-0.536193</td>\n",
       "      <td>-0.327054</td>\n",
       "      <td>-0.259976</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.410263</td>\n",
       "      <td>-0.322651</td>\n",
       "      <td>-0.285631</td>\n",
       "      <td>-0.230130</td>\n",
       "      <td>0.975732</td>\n",
       "      <td>-2.037854</td>\n",
       "      <td>0.785606</td>\n",
       "      <td>0.030914</td>\n",
       "      <td>-0.471995</td>\n",
       "      <td>0.147818</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4196 rows × 23 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Unnamed: 0    no  target  t  activity  appCat.builtin  \\\n",
       "0              0     1       4  0  0.641645        1.103108   \n",
       "1              1     1       4  1  1.074310       -0.242798   \n",
       "2              2     1       4  2  0.065088        0.067334   \n",
       "3              3     1       4  3 -0.085503       -0.167041   \n",
       "4              4     2       4  0  1.074310       -0.242798   \n",
       "...          ...   ...     ... ..       ...             ...   \n",
       "4191        4191  1048       4  3  0.272023        0.774332   \n",
       "4192        4192  1049       4  0 -0.328753       -0.065428   \n",
       "4193        4193  1049       4  1 -1.058736       -0.245614   \n",
       "4194        4194  1049       4  2  0.272023        0.774332   \n",
       "4195        4195  1049       4  3  1.242266       -0.428041   \n",
       "\n",
       "      appCat.communication  appCat.entertainment  appCat.finance  appCat.game  \\\n",
       "0                 1.636492              0.244791        1.129913    -0.259976   \n",
       "1                 1.062958             -0.575133        0.292739    -0.259976   \n",
       "2                 1.182367             -0.574217        0.949321    -0.259976   \n",
       "3                 2.937521              0.217447        0.675919    -0.259976   \n",
       "4                 1.062958             -0.575133        0.292739    -0.259976   \n",
       "...                    ...                   ...             ...          ...   \n",
       "4191             -0.254069             -0.107484       -0.327054    -0.259976   \n",
       "4192             -0.559067             -0.041053       -0.327054    -0.259976   \n",
       "4193             -0.192281             -0.546996       -0.327054    -0.259976   \n",
       "4194             -0.254069             -0.107484       -0.327054    -0.259976   \n",
       "4195             -0.907386             -0.536193       -0.327054    -0.259976   \n",
       "\n",
       "      ...  appCat.travel  appCat.unknown  appCat.utilities  appCat.weather  \\\n",
       "0     ...       4.689448       -0.322651          7.439909       -0.230130   \n",
       "1     ...      -0.207470       -0.322651          1.198651       -0.230130   \n",
       "2     ...      -0.415500       -0.322651          0.063147        2.406086   \n",
       "3     ...       1.925529       -0.322651          1.991383       -0.230130   \n",
       "4     ...      -0.207470       -0.322651          1.198651       -0.230130   \n",
       "...   ...            ...             ...               ...             ...   \n",
       "4191  ...      -0.415500       -0.322651          0.070671       -0.230130   \n",
       "4192  ...      -0.415500       -0.322651         -0.327129       -0.230130   \n",
       "4193  ...      -0.415500       -0.322651          0.401548       -0.230130   \n",
       "4194  ...      -0.415500       -0.322651          0.070671       -0.230130   \n",
       "4195  ...      -0.410263       -0.322651         -0.285631       -0.230130   \n",
       "\n",
       "          call  circumplex.arousal  circumplex.valence      mood    screen  \\\n",
       "0     1.319838            0.485487           -1.266137 -1.209901  2.770542   \n",
       "1     0.287520            1.143750           -0.496733 -0.899697  0.106958   \n",
       "2    -0.744797            0.485487            0.272670 -0.279289  0.249101   \n",
       "3     2.696262            1.472881           -1.779072 -1.520105  2.110863   \n",
       "4     0.287520            1.143750           -0.496733 -0.899697  0.106958   \n",
       "...        ...                 ...                 ...       ...       ...   \n",
       "4191  2.696262            0.156356            1.298542  1.892137  1.947385   \n",
       "4192  2.696262           -0.501907           -1.779072 -2.450716  2.983480   \n",
       "4193 -0.400691           -0.831038           -0.753201 -1.209901 -0.354860   \n",
       "4194  2.696262            0.156356            1.298542  1.892137  1.947385   \n",
       "4195  0.975732           -2.037854            0.785606  0.030914 -0.471995   \n",
       "\n",
       "           sms  \n",
       "0    -0.497599  \n",
       "1     0.147818  \n",
       "2    -0.497599  \n",
       "3    -0.497599  \n",
       "4     0.147818  \n",
       "...        ...  \n",
       "4191  0.147818  \n",
       "4192  1.438652  \n",
       "4193  0.793235  \n",
       "4194  0.147818  \n",
       "4195  0.147818  \n",
       "\n",
       "[4196 rows x 23 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load dataset\n",
    "#dataset = \"dataframe_normalized_outliers_removed.csv\" \n",
    "dataset = \"dataframe_standardized_outliers_removed_classes.csv\"\n",
    "#dataset = \"dataframe_new.csv\"  ## debug\n",
    "df = pd.read_csv(dataset) # dataframe in pandas\n",
    "\n",
    "\n",
    "#df = df[df['target'] != 7] # debug check if it learns to predict not only 7\n",
    "df['target'] = df['target'].sub(3)# change to 7 classes 0 1 2 3 4 5 6\n",
    "#df = df[df['target'] != 7]\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>no</th>\n",
       "      <th>target</th>\n",
       "      <th>t</th>\n",
       "      <th>activity</th>\n",
       "      <th>appCat.builtin</th>\n",
       "      <th>appCat.communication</th>\n",
       "      <th>appCat.entertainment</th>\n",
       "      <th>appCat.finance</th>\n",
       "      <th>appCat.game</th>\n",
       "      <th>...</th>\n",
       "      <th>appCat.travel</th>\n",
       "      <th>appCat.unknown</th>\n",
       "      <th>appCat.utilities</th>\n",
       "      <th>appCat.weather</th>\n",
       "      <th>call</th>\n",
       "      <th>circumplex.arousal</th>\n",
       "      <th>circumplex.valence</th>\n",
       "      <th>mood</th>\n",
       "      <th>screen</th>\n",
       "      <th>sms</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>0 rows × 23 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [Unnamed: 0, no, target, t, activity, appCat.builtin, appCat.communication, appCat.entertainment, appCat.finance, appCat.game, appCat.office, appCat.other, appCat.social, appCat.travel, appCat.unknown, appCat.utilities, appCat.weather, call, circumplex.arousal, circumplex.valence, mood, screen, sms]\n",
       "Index: []\n",
       "\n",
       "[0 rows x 23 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[df['target'] == 7]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      Unnamed: 0   no  target  t  activity  appCat.builtin  \\\n",
      "2888        2888  723       4  0 -0.499064       -0.032645   \n",
      "2889        2889  723       4  1  0.989888        0.949300   \n",
      "2890        2890  723       4  2  0.457188        0.335828   \n",
      "2891        2891  723       4  3 -0.154787       -0.272890   \n",
      "\n",
      "      appCat.communication  appCat.entertainment  appCat.finance  appCat.game  \\\n",
      "2888              0.554783             -0.628182       -0.327054    -0.259976   \n",
      "2889              0.538962             -0.513537       -0.327054    -0.259976   \n",
      "2890             -0.591393             -0.658839       -0.327054    -0.259976   \n",
      "2891             -0.855933             -0.658839       -0.327054    -0.259976   \n",
      "\n",
      "      ...  appCat.travel  appCat.unknown  appCat.utilities  appCat.weather  \\\n",
      "2888  ...        -0.4155       -0.322651         -0.089520        -0.23013   \n",
      "2889  ...        -0.4155        0.060803         -0.166846        -0.23013   \n",
      "2890  ...        -0.4155       -0.322651         -0.327129        -0.23013   \n",
      "2891  ...        -0.4155       -0.243459         -0.327129        -0.23013   \n",
      "\n",
      "          call  circumplex.arousal  circumplex.valence      mood    screen  \\\n",
      "2888  1.319838            2.213427           -1.779072 -1.520105 -0.158017   \n",
      "2889  0.975732            0.156356           -0.069287 -1.003098  0.490905   \n",
      "2890 -0.744797           -1.160170            0.785606  0.651322 -0.339057   \n",
      "2891 -0.744797           -1.489301            0.785606  0.030914 -0.797037   \n",
      "\n",
      "           sms  \n",
      "2888 -0.497599  \n",
      "2889  0.793235  \n",
      "2890 -0.497599  \n",
      "2891 -0.497599  \n",
      "\n",
      "[4 rows x 23 columns]\n",
      "Empty DataFrame\n",
      "Columns: [Unnamed: 0, no, target, t, activity, appCat.builtin, appCat.communication, appCat.entertainment, appCat.finance, appCat.game, appCat.office, appCat.other, appCat.social, appCat.travel, appCat.unknown, appCat.utilities, appCat.weather, call, circumplex.arousal, circumplex.valence, mood, screen, sms]\n",
      "Index: []\n",
      "\n",
      "[0 rows x 23 columns]\n"
     ]
    }
   ],
   "source": [
    "print(df[df['no'] == 723])\n",
    "for i in range(710, 730):  ### debug\n",
    "    df = df[df['no'] != i]\n",
    "print(df[df['no'] == 723])\n",
    "df = df.sample(frac=1) # shuffle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([4, 4, 5, ..., 5, 4, 5], dtype=int64)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get labels\n",
    "Y = df['target'].to_numpy()\n",
    "Y = Y[::4]\n",
    "Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get input \n",
    "X = df.iloc[:, 3:].to_numpy()\n",
    "X = X[:, 1:]\n",
    "split = len(X[:, 0]) / 4\n",
    "X = np.array_split(X, split)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split train and test set\n",
    "x_train, x_test, y_train, y_test = train_test_split(X, Y, test_size=0.2, random_state=123, shuffle=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 16\n",
    "def batch_generator(X, Y, batch_size):\n",
    "    batchesx = []\n",
    "    batchesy = []\n",
    "    batchx = [] # batches\n",
    "    batchy = []\n",
    "    for i in range(len(X)):\n",
    "        batchx.append(X[i]) # add to batch\n",
    "        batchy.append(Y[i])\n",
    "        #print(batchy)\n",
    "        if i % batch_size == 0: # batch full?\n",
    "            batchesx.append([batchx])\n",
    "            batchesy.append([batchy])\n",
    "            batchx = [] # batches\n",
    "            batchy = []\n",
    "    print(batchesy)\n",
    "    return batchesx, batchesy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# to torch tensor\n",
    "x_train = torch.tensor(x_train)\n",
    "#x_train = x_train[:724]#### debug\n",
    "#for i in range(710, 730):  ### debug\n",
    "    #np.delete(x_train, i)\n",
    "    #np.delete(y_train, i)\n",
    "#x_train = x_train[4:] ## debug\n",
    "y_train = torch.tensor(y_train).to(torch.int64)\n",
    "#print(x_train[724])\n",
    "#print(y_train[724])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test = torch.tensor(x_test)\n",
    "y_test = torch.tensor(y_test).to(torch.int64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(x_train[728])\n",
    "#print(y_train[728])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cpu\n"
     ]
    }
   ],
   "source": [
    "# training on GPU\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class lstm(nn.Module):\n",
    "    def __init__ (self, input_size, hidden_size, num_layers, seq_length, output_size):\n",
    "        super(). __init__()\n",
    "        self.input_size = input_size\n",
    "        self.hidden_size = hidden_size\n",
    "        self.num_layers = num_layers\n",
    "        self.seq_length = seq_length\n",
    "        self.output_size = output_size\n",
    "        self.hidden_lin_size = 20\n",
    "        \n",
    "        self.ltsm = torch.nn.LSTM(self.input_size, self.hidden_size, batch_first=True) \n",
    "        #self.dropout = torch.nn.Dropout(0.3)\n",
    "        self.lin1 = nn.Linear(self.hidden_size, self.hidden_lin_size) \n",
    "        self.lin2 = nn.Linear(self.hidden_lin_size, self.output_size)\n",
    "    def forward(self, x):\n",
    "        x, (hn, cn) = self.ltsm(x)\n",
    "        #x  = self.dropout(x)\n",
    "        x = F.relu(x) # is this ok?\n",
    "        x = F.relu(self.lin1(x))  \n",
    "        x = self.lin2(x)\n",
    "        return x, (hn, cn)\n",
    "net = lstm(input_size=19, hidden_size=100, num_layers=1, seq_length=4, output_size=7).float()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 1 2 3 4 5 6]\n",
      "[  3   9  17 143 421 223   7]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([0.9964, 0.9891, 0.9793, 0.8262, 0.4885, 0.7290, 0.9915])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# weighted cross entropy\n",
    "unique, counts = np.unique(y_train, return_counts=True)\n",
    "print(unique)\n",
    "print(counts)\n",
    "nSamples = [887, 6130, 480, 317, 972, 101, 128]\n",
    "normedWeights = [(1 - (x / sum(counts))) for x in counts]\n",
    "normedWeights = torch.FloatTensor(normedWeights).to(device)\n",
    "normedWeights\n",
    "# way 2\n",
    "#normedWeights = counts / sum(counts)\n",
    "#normedWeights = torch.FloatTensor(normedWeights).to(device)\n",
    "#normedWeights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "\n",
    "learning_rate = 0.0001\n",
    "#criterion =  nn.MSELoss()    # MSE for regression\n",
    "criterion = nn.CrossEntropyLoss(weight=normedWeights)\n",
    "optimizer = optim.Adam(net.parameters(), lr=learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "target = torch.randint(0, 10, (10,))\n",
    "one_hot = torch.nn.functional.one_hot(target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1,   100] loss: 1.015\n",
      "[1,   200] loss: 1.081\n",
      "[1,   300] loss: 0.884\n",
      "[1,   400] loss: 0.944\n",
      "[1,   500] loss: 0.962\n",
      "[1,   600] loss: 0.947\n",
      "[1,   700] loss: 0.935\n",
      "[1,   800] loss: 0.776\n",
      "[2,   100] loss: 1.018\n",
      "[2,   200] loss: 1.070\n",
      "[2,   300] loss: 0.875\n",
      "[2,   400] loss: 0.935\n",
      "[2,   500] loss: 0.955\n",
      "[2,   600] loss: 0.937\n",
      "[2,   700] loss: 0.928\n",
      "[2,   800] loss: 0.765\n",
      "[3,   100] loss: 1.012\n",
      "[3,   200] loss: 1.060\n",
      "[3,   300] loss: 0.867\n",
      "[3,   400] loss: 0.925\n",
      "[3,   500] loss: 0.948\n",
      "[3,   600] loss: 0.928\n",
      "[3,   700] loss: 0.921\n",
      "[3,   800] loss: 0.753\n",
      "[4,   100] loss: 1.005\n",
      "[4,   200] loss: 1.048\n",
      "[4,   300] loss: 0.859\n",
      "[4,   400] loss: 0.915\n",
      "[4,   500] loss: 0.941\n",
      "[4,   600] loss: 0.918\n",
      "[4,   700] loss: 0.914\n",
      "[4,   800] loss: 0.742\n",
      "[5,   100] loss: 0.999\n",
      "[5,   200] loss: 1.037\n",
      "[5,   300] loss: 0.850\n",
      "[5,   400] loss: 0.905\n",
      "[5,   500] loss: 0.934\n",
      "[5,   600] loss: 0.908\n",
      "[5,   700] loss: 0.906\n",
      "[5,   800] loss: 0.731\n",
      "[6,   100] loss: 0.992\n",
      "[6,   200] loss: 1.025\n",
      "[6,   300] loss: 0.842\n",
      "[6,   400] loss: 0.894\n",
      "[6,   500] loss: 0.927\n",
      "[6,   600] loss: 0.898\n",
      "[6,   700] loss: 0.897\n",
      "[6,   800] loss: 0.720\n",
      "[7,   100] loss: 0.985\n",
      "[7,   200] loss: 1.013\n",
      "[7,   300] loss: 0.834\n",
      "[7,   400] loss: 0.883\n",
      "[7,   500] loss: 0.920\n",
      "[7,   600] loss: 0.888\n",
      "[7,   700] loss: 0.889\n",
      "[7,   800] loss: 0.709\n",
      "[8,   100] loss: 0.977\n",
      "[8,   200] loss: 1.001\n",
      "[8,   300] loss: 0.826\n",
      "[8,   400] loss: 0.871\n",
      "[8,   500] loss: 0.913\n",
      "[8,   600] loss: 0.878\n",
      "[8,   700] loss: 0.880\n",
      "[8,   800] loss: 0.698\n",
      "[9,   100] loss: 0.970\n",
      "[9,   200] loss: 0.989\n",
      "[9,   300] loss: 0.818\n",
      "[9,   400] loss: 0.858\n",
      "[9,   500] loss: 0.906\n",
      "[9,   600] loss: 0.868\n",
      "[9,   700] loss: 0.871\n",
      "[9,   800] loss: 0.687\n",
      "[10,   100] loss: 0.963\n",
      "[10,   200] loss: 0.977\n",
      "[10,   300] loss: 0.810\n",
      "[10,   400] loss: 0.846\n",
      "[10,   500] loss: 0.898\n",
      "[10,   600] loss: 0.858\n",
      "[10,   700] loss: 0.862\n",
      "[10,   800] loss: 0.675\n",
      "[11,   100] loss: 0.955\n",
      "[11,   200] loss: 0.964\n",
      "[11,   300] loss: 0.803\n",
      "[11,   400] loss: 0.833\n",
      "[11,   500] loss: 0.890\n",
      "[11,   600] loss: 0.848\n",
      "[11,   700] loss: 0.852\n",
      "[11,   800] loss: 0.664\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-29-7e6711bfcaa7>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     23\u001b[0m         \u001b[1;31m#print(output[0])\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     24\u001b[0m         \u001b[1;31m#print(labels[0])\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 25\u001b[1;33m         \u001b[0mloss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     26\u001b[0m         \u001b[0mloss\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     27\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m    887\u001b[0m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    888\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 889\u001b[1;33m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    890\u001b[0m         for hook in itertools.chain(\n\u001b[0;32m    891\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\loss.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, input, target)\u001b[0m\n\u001b[0;32m   1045\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1046\u001b[0m         \u001b[1;32massert\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mweight\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mTensor\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1047\u001b[1;33m         return F.cross_entropy(input, target, weight=self.weight,\n\u001b[0m\u001b[0;32m   1048\u001b[0m                                ignore_index=self.ignore_index, reduction=self.reduction)\n\u001b[0;32m   1049\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\torch\\nn\\functional.py\u001b[0m in \u001b[0;36mcross_entropy\u001b[1;34m(input, target, weight, size_average, ignore_index, reduce, reduction)\u001b[0m\n\u001b[0;32m   2691\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0msize_average\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mreduce\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2692\u001b[0m         \u001b[0mreduction\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_Reduction\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlegacy_get_string\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msize_average\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreduce\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2693\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mnll_loss\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlog_softmax\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mignore_index\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreduction\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2694\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2695\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\torch\\nn\\functional.py\u001b[0m in \u001b[0;36mlog_softmax\u001b[1;34m(input, dim, _stacklevel, dtype)\u001b[0m\n\u001b[0;32m   1670\u001b[0m         \u001b[0mdim\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_get_softmax_dim\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"log_softmax\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdim\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_stacklevel\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1671\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mdtype\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1672\u001b[1;33m         \u001b[0mret\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlog_softmax\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdim\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1673\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1674\u001b[0m         \u001b[0mret\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlog_softmax\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdim\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# train the network\n",
    "\n",
    "n = 10 # for one hot\n",
    "\n",
    "for epoch in range(100):\n",
    "    running_loss = 0.0\n",
    "    net.train()\n",
    "    for i in range(len(x_train)):\n",
    "        \n",
    "        # get the inputs\n",
    "        #print(torch.unsqueeze(x_train[i], 0))\n",
    "        inputs, labels =torch.unsqueeze(x_train[i], 0).to(device).float(), torch.unsqueeze(y_train[i], 0).to(device)\n",
    "        labels_onehot = torch.nn.functional.one_hot(labels[0].to(torch.int64), n)\n",
    "        # zero the parameter gradients\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # forward + backward + optimize\n",
    "        outputs, (hn, cn) = net(inputs)\n",
    "        #print(outputs)\n",
    "        output = torch.mean(outputs, dim=1) # takes the average over the outputs \n",
    "        #output = outputs[3] # takes the last, (does that makes more sense)\n",
    "        \n",
    "        #print(output[0])\n",
    "        #print(labels[0])\n",
    "        loss = criterion(output, labels)\n",
    "        loss.backward() \n",
    "        optimizer.step()\n",
    "        #print(i, loss.item())\n",
    "        # running loss\n",
    "        running_loss += loss.item()\n",
    "        #print(i, loss.item())\n",
    "        # statistics tensorboard\n",
    "        if i % 100 == 99:    # every 30 mini-batches\n",
    "\n",
    "            # print\n",
    "            print('[%d, %5d] loss: %.3f' %\n",
    "                  (epoch + 1, i + 1, running_loss / 100))\n",
    "            \n",
    "            '''\n",
    "            # ...log the running loss\n",
    "            writer.add_scalar('training loss',\n",
    "                            running_loss / 30,\n",
    "                            epoch * len(x_train) + i)\n",
    "            '''\n",
    "            running_loss = 0.0\n",
    "'''\n",
    "    # run on validation set\n",
    "    net.eval()\n",
    "    for j, data in enumerate(x_val, 0):\n",
    "        inputs, labels = x_val[j].to(device), y_val[j].to(device)\n",
    "        \n",
    "        # calculate outputs and loss\n",
    "        outputs, (hn, cn) = net(inputs)\n",
    "        output = torch.mean(outputs, dim=1)  \n",
    "        loss = criterion(output, labels)\n",
    "        \n",
    "        # running loss\n",
    "        running_loss += loss.item()\n",
    "        \n",
    "    # add to tensorboard\n",
    "    writer.add_scalar('validation_loss',\n",
    "                            running_loss / j,\n",
    "                            epoch)\n",
    "    print(\"validation loss:\", running_loss / j, j)\n",
    "'''\n",
    "print('Finished Training')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-3.6343, -3.7073, -2.2717,  0.1479,  2.6823,  1.3109, -2.2149]])\n",
      "tensor([4])\n",
      "tensor([[-4.4275, -4.1350, -2.3474,  0.4295,  2.5611,  1.7917, -2.7467]])\n",
      "tensor([4])\n",
      "tensor([[-4.3369, -4.1531, -2.7581,  0.6955,  3.3542,  0.8116, -2.7740]])\n",
      "tensor([4])\n",
      "tensor([[-3.7750, -3.5555, -1.8019,  0.0337,  1.8387,  2.1555, -2.2260]])\n",
      "tensor([5])\n",
      "tensor([[-3.2720, -2.4844, -1.7618,  1.0890,  1.7393,  0.0440, -2.0710]])\n",
      "tensor([4])\n",
      "tensor([[-6.2658, -5.4707, -2.8081,  0.7794,  2.4029,  3.2365, -3.7725]])\n",
      "tensor([5])\n",
      "tensor([[-4.6099, -4.5075, -2.5047,  0.2216,  2.8591,  2.1819, -2.8491]])\n",
      "tensor([4])\n",
      "tensor([[-4.2368, -3.1512, -1.2108,  0.7556,  0.1671,  2.4691, -2.6686]])\n",
      "tensor([5])\n",
      "tensor([[-1.6905, -1.0923, -0.7436,  0.7280,  0.6042, -0.2943, -1.3807]])\n",
      "tensor([3])\n",
      "tensor([[-3.1217, -2.5735, -1.8578,  1.0264,  2.0613, -0.3446, -2.2429]])\n",
      "tensor([4])\n",
      "tensor([[-4.4457, -4.5737, -2.7447,  0.3072,  3.2916,  1.7552, -2.8760]])\n",
      "tensor([4])\n",
      "tensor([[-4.7071, -4.1703, -2.4877,  0.7478,  2.4969,  1.6216, -2.9752]])\n",
      "tensor([4])\n",
      "tensor([[-3.9496, -3.7449, -2.0786,  0.0865,  2.1462,  2.0566, -2.3084]])\n",
      "tensor([4])\n",
      "tensor([[-5.0969, -4.0460, -2.3378,  1.2715,  2.0491,  1.5932, -3.1189]])\n",
      "tensor([4])\n",
      "tensor([[-4.1848, -3.7498, -2.6679,  1.1624,  3.1713, -0.2168, -2.8962]])\n",
      "tensor([4])\n",
      "tensor([[-6.3012, -5.2941, -2.7016,  1.0282,  2.0656,  3.2110, -3.8060]])\n",
      "tensor([5])\n",
      "tensor([[-3.5780, -2.9281, -1.6934,  0.8151,  1.5329,  1.1107, -2.4319]])\n",
      "tensor([4])\n",
      "tensor([[-5.4189, -4.3365, -2.8417,  1.8530,  2.9055,  0.6098, -3.6866]])\n",
      "tensor([4])\n",
      "tensor([[-5.1701, -4.8003, -3.0395,  1.0771,  3.5434,  1.0386, -3.5283]])\n",
      "tensor([4])\n",
      "tensor([[-2.7355, -2.2989, -1.3089,  0.4019,  1.3266,  0.8590, -1.7880]])\n",
      "tensor([4])\n",
      "tensor([[-2.7255, -2.3104, -1.5537,  0.7368,  1.7131,  0.0790, -1.9269]])\n",
      "tensor([4])\n",
      "tensor([[-3.3280, -3.0949, -2.0857,  0.7028,  2.5824,  0.1876, -2.3134]])\n",
      "tensor([4])\n",
      "tensor([[-3.6949, -3.7972, -2.4386,  0.3610,  2.9963,  1.0666, -2.4812]])\n",
      "tensor([4])\n",
      "tensor([[-5.0359, -4.6621, -2.6066,  0.5044,  2.6760,  2.2605, -3.0646]])\n",
      "tensor([4])\n",
      "tensor([[-3.9147, -2.8446, -1.9887,  1.6106,  2.0820, -0.3484, -2.8463]])\n",
      "tensor([4])\n",
      "tensor([[-2.9223, -2.8352, -1.7972,  0.4576,  2.1865,  0.6120, -2.1169]])\n",
      "tensor([4])\n",
      "tensor([[-3.2450, -2.8249, -1.7835,  0.8461,  1.9781,  0.4050, -2.3995]])\n",
      "tensor([4])\n",
      "tensor([[-2.6612, -2.0456, -1.6161,  0.9013,  1.7426, -0.5250, -1.7918]])\n",
      "tensor([4])\n",
      "tensor([[-4.2548, -4.3120, -2.6703,  0.3839,  3.2554,  1.4435, -2.7961]])\n",
      "tensor([4])\n",
      "tensor([[-2.5276, -0.9687, -0.4847,  1.6516, -0.0074, -0.9335, -2.1148]])\n",
      "tensor([3])\n",
      "tensor([[-2.7229, -1.8393, -1.1955,  1.1583,  1.0407, -0.0683, -2.1360]])\n",
      "tensor([3])\n",
      "tensor([[-4.0008, -3.8933, -2.5589,  0.7966,  3.0808,  0.5283, -2.7640]])\n",
      "tensor([4])\n",
      "tensor([[-2.5441, -1.9938, -1.0948,  0.4349,  0.8845,  0.9262, -1.7102]])\n",
      "tensor([5])\n",
      "tensor([[-4.5512, -3.9846, -1.5735,  0.0665,  0.9557,  3.4303, -2.4711]])\n",
      "tensor([5])\n",
      "tensor([[-5.6114, -5.0436, -2.7797,  0.8268,  2.7462,  2.3713, -3.5637]])\n",
      "tensor([4])\n",
      "tensor([[-3.7489, -3.8591, -2.3093,  0.1597,  2.8044,  1.4850, -2.3665]])\n",
      "tensor([4])\n",
      "tensor([[-4.0462, -4.1329, -2.6027,  0.2727,  3.2213,  1.2639, -2.5492]])\n",
      "tensor([4])\n",
      "tensor([[-2.9600, -2.7955, -1.5755,  0.0780,  1.7216,  1.4001, -1.8601]])\n",
      "tensor([4])\n",
      "tensor([[-3.5728, -3.1966, -2.0448,  0.5235,  2.1682,  1.1225, -2.1968]])\n",
      "tensor([4])\n",
      "tensor([[-3.2675, -3.0777, -1.7669,  0.3399,  1.8814,  1.2033, -2.1071]])\n",
      "tensor([4])\n",
      "tensor([[-1.5832, -0.8491, -0.6124,  0.7741,  0.4412, -0.5490, -1.2912]])\n",
      "tensor([3])\n",
      "tensor([[-4.4652, -4.0821, -2.0440,  0.1852,  1.8224,  2.7080, -2.5737]])\n",
      "tensor([5])\n",
      "tensor([[-4.9151, -4.4926, -2.5306,  0.5478,  2.6056,  2.0667, -2.9387]])\n",
      "tensor([4])\n",
      "tensor([[-3.3095, -2.9088, -1.9287,  1.0146,  2.1430,  0.1878, -2.5105]])\n",
      "tensor([4])\n",
      "tensor([[-3.4987, -3.3346, -2.0409,  0.4109,  2.3840,  1.1619, -2.3426]])\n",
      "tensor([4])\n",
      "tensor([[-3.1908, -2.5830, -1.6802,  0.8176,  1.6918,  0.5083, -2.0404]])\n",
      "tensor([4])\n",
      "tensor([[-4.8900, -5.1047, -3.1592,  0.3629,  3.8414,  1.7758, -3.1231]])\n",
      "tensor([4])\n",
      "tensor([[-2.7561, -2.1602, -1.5221,  0.8721,  1.5225,  0.1465, -1.9148]])\n",
      "tensor([4])\n",
      "tensor([[-2.3206, -1.8869, -1.1880,  0.4651,  1.2487,  0.2087, -1.5152]])\n",
      "tensor([4])\n",
      "tensor([[-3.7915, -3.1687, -1.5181,  0.4086,  1.0739,  2.0944, -2.3095]])\n",
      "tensor([5])\n",
      "tensor([[-4.6817, -4.3737, -2.6778,  0.9163,  2.9912,  1.2943, -3.2329]])\n",
      "tensor([4])\n",
      "tensor([[-4.8417, -4.5287, -2.4212,  0.3415,  2.4504,  2.4969, -2.9874]])\n",
      "tensor([5])\n",
      "tensor([[-4.4039, -3.7719, -1.9822,  0.5431,  1.7384,  2.1358, -2.6390]])\n",
      "tensor([5])\n",
      "tensor([[-4.4167, -4.5089, -2.5927,  0.0806,  3.0498,  2.1414, -2.6771]])\n",
      "tensor([4])\n",
      "tensor([[-2.2839, -2.0181, -1.3636,  0.4794,  1.5398,  0.1646, -1.6083]])\n",
      "tensor([4])\n",
      "tensor([[-2.8543, -2.7069, -1.4891,  0.0484,  1.6391,  1.3694, -1.7880]])\n",
      "tensor([4])\n",
      "tensor([[-4.5362, -4.1396, -1.7963, -0.0626,  1.4393,  3.2712, -2.4972]])\n",
      "tensor([5])\n",
      "tensor([[-4.3630, -4.4268, -2.7144,  0.2489,  3.2737,  1.6721, -2.6935]])\n",
      "tensor([4])\n",
      "tensor([[-3.2364, -2.9314, -1.9776,  0.7799,  2.3445,  0.1537, -2.3123]])\n",
      "tensor([4])\n",
      "tensor([[-3.7035, -3.5906, -2.0937,  0.2929,  2.3276,  1.4430, -2.3418]])\n",
      "tensor([4])\n",
      "tensor([[-3.2626, -2.5306, -1.7054,  1.3033,  1.7465, -0.1300, -2.5582]])\n",
      "tensor([4])\n",
      "tensor([[-2.6208, -1.8471, -1.4231,  1.1055,  1.3581, -0.4791, -1.9017]])\n",
      "tensor([4])\n",
      "tensor([[-4.0806, -3.5372, -1.8714,  0.3926,  1.7539,  2.0147, -2.4807]])\n",
      "tensor([5])\n",
      "tensor([[-4.6629, -4.2656, -2.3896,  0.5365,  2.3448,  2.1262, -2.9363]])\n",
      "tensor([4])\n",
      "tensor([[-4.0869e+00, -3.8704e+00, -2.0021e+00,  2.7141e-03,  1.8793e+00,\n",
      "          2.5657e+00, -2.3145e+00]])\n",
      "tensor([5])\n",
      "tensor([[-3.6719, -3.4895, -2.3391,  0.6481,  2.8619,  0.4761, -2.4166]])\n",
      "tensor([4])\n",
      "tensor([[-7.0750, -5.6580, -2.9974,  1.7541,  2.4899,  2.5183, -4.5646]])\n",
      "tensor([5])\n",
      "tensor([[-3.6872, -3.7035, -2.2369,  0.2565,  2.7395,  1.2846, -2.4019]])\n",
      "tensor([4])\n",
      "tensor([[-6.1923, -5.9446, -3.3623,  0.5019,  3.6580,  2.8161, -3.7250]])\n",
      "tensor([4])\n",
      "tensor([[-3.6434, -3.4049, -1.8646,  0.1061,  1.8643,  1.9490, -2.1631]])\n",
      "tensor([5])\n",
      "tensor([[-4.0595, -3.9994, -2.5659,  0.7047,  3.1134,  0.7545, -2.7843]])\n",
      "tensor([4])\n",
      "tensor([[-2.9415, -2.6599, -1.7802,  0.6546,  2.0000,  0.4278, -2.0348]])\n",
      "tensor([4])\n",
      "tensor([[-5.2650, -3.8446, -2.0733,  1.6097,  1.5549,  1.5545, -3.4077]])\n",
      "tensor([3])\n",
      "tensor([[-3.4239, -3.0858, -1.9884,  0.8680,  2.2507,  0.4784, -2.5040]])\n",
      "tensor([4])\n",
      "tensor([[-3.9149, -3.9229, -2.5100,  0.5124,  3.0627,  1.0008, -2.6653]])\n",
      "tensor([4])\n",
      "tensor([[-2.5636, -1.1941, -0.7682,  1.5686,  0.2979, -0.5933, -2.1001]])\n",
      "tensor([3])\n",
      "tensor([[-2.7639, -2.1571, -1.5191,  0.8278,  1.5222,  0.1423, -1.8430]])\n",
      "tensor([4])\n",
      "tensor([[-5.4067, -4.9945, -2.4160,  0.1883,  2.0800,  3.4212, -3.0217]])\n",
      "tensor([5])\n",
      "tensor([[-2.1066, -0.8907, -0.4238,  1.1539, -0.2079, -0.0758, -1.6524]])\n",
      "tensor([3])\n",
      "tensor([[-4.3040, -4.2912, -2.7353,  0.3773,  3.2491,  1.3576, -2.6064]])\n",
      "tensor([4])\n",
      "tensor([[-3.5010, -3.4220, -2.0636,  0.4035,  2.4511,  1.0760, -2.3812]])\n",
      "tensor([4])\n",
      "tensor([[-3.8798, -3.1127, -2.0845,  1.2004,  2.1907,  0.3126, -2.5992]])\n",
      "tensor([4])\n",
      "tensor([[-4.4818, -4.5308, -2.7288,  0.2985,  3.2711,  1.6690, -2.7971]])\n",
      "tensor([4])\n",
      "tensor([[-3.3596, -2.8424, -1.3840,  0.2530,  1.0664,  1.9418, -1.9994]])\n",
      "tensor([5])\n",
      "tensor([[-3.2224, -2.9860, -1.4580, -0.0887,  1.3711,  1.9877, -1.8159]])\n",
      "tensor([5])\n",
      "tensor([[-4.6272, -4.3575, -2.1662, -0.0303,  2.1422,  2.9634, -2.5854]])\n",
      "tensor([5])\n",
      "tensor([[-2.8399, -2.6849, -1.7615,  0.5104,  2.1252,  0.4131, -2.0384]])\n",
      "tensor([4])\n",
      "tensor([[-4.3151, -4.0054, -2.0522,  0.2178,  2.0043,  2.4147, -2.6213]])\n",
      "tensor([5])\n",
      "tensor([[-4.0298, -1.7716, -0.9514,  2.5263,  0.2673, -0.7571, -3.1056]])\n",
      "tensor([3])\n",
      "tensor([[-5.1367, -4.0259, -2.5004,  1.6813,  2.4389,  0.8174, -3.5402]])\n",
      "tensor([4])\n",
      "tensor([[-2.8848, -2.1380, -1.5299,  1.2079,  1.4824, -0.2904, -2.1681]])\n",
      "tensor([4])\n",
      "tensor([[-3.8943, -3.3708, -2.1694,  0.9026,  2.3495,  0.6883, -2.6676]])\n",
      "tensor([4])\n",
      "tensor([[-3.0552, -2.3833, -1.6343,  1.0809,  1.7589, -0.0613, -2.2603]])\n",
      "tensor([4])\n",
      "tensor([[-4.5398, -3.6893, -1.9575,  0.7891,  1.3790,  2.2184, -2.7461]])\n",
      "tensor([5])\n",
      "tensor([[-4.1875, -4.0678, -2.4025,  0.2581,  2.8328,  1.5931, -2.5028]])\n",
      "tensor([4])\n",
      "tensor([[-2.9512, -2.8832, -1.8790,  0.3785,  2.2898,  0.6149, -2.0265]])\n",
      "tensor([4])\n",
      "tensor([[-4.3486, -4.2701, -2.7710,  0.6146,  3.2918,  1.1196, -2.8626]])\n",
      "tensor([4])\n",
      "tensor([[-2.5247, -2.2913, -1.2971,  0.2988,  1.3940,  0.7628, -1.7307]])\n",
      "tensor([4])\n",
      "tensor([[-3.6532, -3.7342, -2.3705,  0.3453,  2.9272,  1.0498, -2.4392]])\n",
      "tensor([4])\n",
      "tensor([[-4.1857, -4.0282, -2.5582,  0.6325,  3.0331,  1.0618, -2.8321]])\n",
      "tensor([4])\n",
      "tensor([[-4.0835, -3.8955, -2.5547,  0.7092,  3.0747,  0.7666, -2.7212]])\n",
      "tensor([4])\n",
      "tensor([[-3.1396, -3.0804, -1.9506,  0.4019,  2.3614,  0.7599, -2.1423]])\n",
      "tensor([4])\n",
      "tensor([[-4.3647, -4.2745, -2.6409,  0.5872,  3.1506,  1.2986, -2.9718]])\n",
      "tensor([4])\n",
      "tensor([[-4.6502, -4.4577, -2.7337,  0.7279,  3.1375,  1.3193, -3.0895]])\n",
      "tensor([4])\n",
      "tensor([[-3.4519, -3.2625, -1.9999,  0.3347,  2.1576,  1.2710, -2.1553]])\n",
      "tensor([4])\n",
      "tensor([[-3.8412, -3.7974, -2.4918,  0.5692,  3.0555,  0.7935, -2.5881]])\n",
      "tensor([4])\n",
      "tensor([[-1.8134, -0.6375, -0.3916,  1.1614, -0.0485, -0.6027, -1.5507]])\n",
      "tensor([3])\n",
      "tensor([[-4.5644, -4.4663, -2.7865,  0.6124,  3.3272,  1.2905, -2.9684]])\n",
      "tensor([4])\n",
      "tensor([[-4.2456, -3.9033, -2.3238,  0.5081,  2.5127,  1.5078, -2.6745]])\n",
      "tensor([4])\n",
      "tensor([[-4.0106, -3.4872, -1.9670,  0.5090,  1.6726,  1.9238, -2.3193]])\n",
      "tensor([5])\n",
      "tensor([[-2.4849, -1.9715, -1.3278,  0.5703,  1.2317,  0.5445, -1.6220]])\n",
      "tensor([4])\n",
      "tensor([[-4.6854, -4.2575, -2.7043,  0.8998,  3.0720,  1.1185, -3.0603]])\n",
      "tensor([4])\n",
      "tensor([[-5.9675, -5.5168, -2.7870,  0.2242,  2.6452,  3.5507, -3.3312]])\n",
      "tensor([5])\n",
      "tensor([[-4.7925, -3.4239, -2.1899,  2.0869,  1.8919,  0.2118, -3.4322]])\n",
      "tensor([3])\n",
      "tensor([[-3.0931, -1.2793, -0.7383,  1.9070,  0.1308, -0.9568, -2.4628]])\n",
      "tensor([3])\n",
      "tensor([[-2.4008, -2.0318, -1.0759,  0.2533,  0.9447,  1.0157, -1.4784]])\n",
      "tensor([5])\n",
      "tensor([[-3.1215, -2.5847, -1.5378,  0.6098,  1.5560,  0.8919, -2.0783]])\n",
      "tensor([4])\n",
      "tensor([[-3.7167e+00, -3.7351e+00, -2.0770e+00, -2.4904e-03,  2.4441e+00,\n",
      "          1.9082e+00, -2.2551e+00]])\n",
      "tensor([4])\n",
      "tensor([[-3.2662, -3.3527, -1.8898,  0.0416,  2.3044,  1.3770, -2.0343]])\n",
      "tensor([4])\n",
      "tensor([[-3.3582, -2.8984, -1.6915,  0.3522,  1.6643,  1.2782, -1.9682]])\n",
      "tensor([4])\n",
      "tensor([[-3.5759, -3.5140, -2.2331,  0.4233,  2.7356,  0.9493, -2.3852]])\n",
      "tensor([4])\n",
      "tensor([[-3.9716, -3.4596, -2.3110,  1.0931,  2.7320,  0.1121, -2.7995]])\n",
      "tensor([4])\n",
      "tensor([[-4.4398, -3.6393, -2.1692,  1.0181,  2.0371,  1.2818, -2.8244]])\n",
      "tensor([4])\n",
      "tensor([[-3.3753, -2.4835, -1.8284,  1.5150,  1.8776, -0.6746, -2.5718]])\n",
      "tensor([4])\n",
      "tensor([[-4.9552, -4.3249, -2.2482,  0.5240,  1.9627,  2.5083, -2.9005]])\n",
      "tensor([5])\n",
      "tensor([[-4.1454, -4.2255, -2.5551,  0.2683,  3.1319,  1.5416, -2.7031]])\n",
      "tensor([4])\n",
      "tensor([[-2.6979, -1.1248, -0.5997,  1.7039, -0.0573, -0.3738, -2.2089]])\n",
      "tensor([3])\n",
      "tensor([[-1.9790, -1.4689, -0.9262,  0.5305,  0.8583,  0.2367, -1.4574]])\n",
      "tensor([4])\n",
      "tensor([[-4.7271, -4.6438, -3.0788,  0.6464,  3.6578,  1.1807, -2.8911]])\n",
      "tensor([4])\n",
      "tensor([[-5.4525, -4.6071, -2.3037,  0.9158,  1.8507,  2.5473, -3.5058]])\n",
      "tensor([5])\n",
      "tensor([[-3.4078, -3.4784, -2.3579,  0.5999,  2.9319,  0.4014, -2.4536]])\n",
      "tensor([4])\n",
      "tensor([[-2.3520, -1.9981, -1.0595,  0.1222,  0.8615,  1.2302, -1.3872]])\n",
      "tensor([5])\n",
      "tensor([[-3.8027, -3.6602, -2.2161,  0.3165,  2.5440,  1.4107, -2.4497]])\n",
      "tensor([4])\n",
      "tensor([[-4.3460, -4.0425, -2.3338,  0.4335,  2.4294,  1.8194, -2.7056]])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([4])\n",
      "tensor([[-2.3366, -1.7198, -1.1204,  0.9254,  1.0309,  0.0328, -1.9062]])\n",
      "tensor([4])\n",
      "tensor([[-3.8254, -1.9140, -1.1153,  2.2672,  0.5586, -0.6200, -2.9801]])\n",
      "tensor([3])\n",
      "tensor([[-2.7069, -2.6599, -1.7528,  0.4469,  2.1377,  0.3378, -1.9537]])\n",
      "tensor([4])\n",
      "tensor([[-3.1971, -3.3096, -2.2058,  0.4306,  2.7837,  0.4840, -2.2555]])\n",
      "tensor([4])\n",
      "tensor([[-4.0704, -4.2577, -2.7055,  0.3945,  3.4672,  1.0582, -2.7310]])\n",
      "tensor([4])\n",
      "tensor([[-3.0579, -2.6996, -1.5791,  0.4014,  1.6814,  1.0875, -2.0039]])\n",
      "tensor([4])\n",
      "tensor([[-4.2729, -3.4217, -2.3381,  1.6341,  2.4812, -0.2147, -3.1946]])\n",
      "tensor([4])\n",
      "tensor([[-4.4576, -3.9011, -2.2364,  0.5766,  2.2579,  1.8252, -2.7284]])\n",
      "tensor([4])\n",
      "tensor([[-2.9534, -2.9713, -1.8258,  0.1444,  2.1913,  1.0695, -1.9254]])\n",
      "tensor([4])\n",
      "tensor([[-3.0035, -2.7805, -1.1962, -0.0894,  1.1256,  2.0222, -1.7448]])\n",
      "tensor([5])\n",
      "tensor([[-4.9619, -4.2220, -2.1647,  0.6543,  1.7560,  2.6489, -3.0224]])\n",
      "tensor([5])\n",
      "tensor([[-1.8989, -1.6448, -1.1087,  0.4820,  1.2263,  0.0463, -1.4901]])\n",
      "tensor([4])\n",
      "tensor([[-3.0993, -2.7482, -1.6632,  0.4593,  1.7104,  1.0390, -2.0899]])\n",
      "tensor([4])\n",
      "tensor([[-6.6430, -6.0730, -3.6156,  1.0786,  3.8552,  2.2318, -4.1669]])\n",
      "tensor([4])\n",
      "tensor([[-5.6240, -4.9324, -2.4627,  0.6490,  2.1261,  2.9211, -3.4255]])\n",
      "tensor([5])\n",
      "tensor([[-3.7265, -3.7596, -2.2730,  0.3213,  2.7778,  1.2622, -2.4804]])\n",
      "tensor([4])\n",
      "tensor([[-3.9164, -3.7658, -2.4058,  0.6116,  2.8778,  0.8635, -2.5989]])\n",
      "tensor([4])\n",
      "tensor([[-3.6879, -3.7374, -2.4052,  0.4866,  2.9926,  0.8421, -2.5249]])\n",
      "tensor([4])\n",
      "tensor([[-3.3638, -2.8921, -2.0856,  1.0434,  2.2585, -0.0622, -2.3779]])\n",
      "tensor([4])\n",
      "tensor([[-3.8116, -3.7445, -2.3768,  0.4649,  2.7801,  1.1081, -2.4731]])\n",
      "tensor([4])\n",
      "tensor([[-5.6544, -4.2276, -1.8093,  1.3212,  0.7760,  2.8558, -3.4372]])\n",
      "tensor([5])\n",
      "tensor([[-2.5135, -2.0957, -0.9287,  0.0570,  0.6730,  1.5447, -1.4970]])\n",
      "tensor([5])\n",
      "tensor([[-3.6092, -3.6860, -2.3652,  0.3536,  2.9271,  0.9642, -2.4015]])\n",
      "tensor([4])\n",
      "tensor([[-5.3924, -4.7156, -2.1495,  0.3920,  1.4861,  3.5697, -3.1365]])\n",
      "tensor([5])\n",
      "tensor([[-5.2073, -4.5834, -2.3000,  0.4762,  2.0638,  2.8508, -3.1264]])\n",
      "tensor([5])\n",
      "tensor([[-6.1181, -5.5044, -2.7293,  0.4874,  2.3264,  3.5680, -3.5647]])\n",
      "tensor([5])\n",
      "tensor([[-2.2615, -0.7854, -0.3772,  1.4873, -0.1245, -0.8185, -1.9182]])\n",
      "tensor([3])\n",
      "tensor([[-2.5759, -0.8826, -0.4063,  1.7797, -0.2773, -0.5210, -2.2074]])\n",
      "tensor([3])\n",
      "tensor([[-5.2756, -4.8279, -2.8010,  0.6867,  3.0075,  1.9999, -3.3204]])\n",
      "tensor([4])\n",
      "tensor([[-6.3500, -4.6778, -2.4166,  1.9007,  1.7377,  2.1128, -3.8966]])\n",
      "tensor([5])\n",
      "tensor([[-2.6546, -2.4600, -1.6673,  0.5314,  1.9628,  0.2597, -1.8738]])\n",
      "tensor([4])\n",
      "tensor([[-3.2325, -3.2452, -2.2496,  0.4327,  2.7093,  0.5814, -2.1058]])\n",
      "tensor([4])\n",
      "tensor([[-3.4403, -2.5776, -1.6334,  1.4379,  1.5612,  0.0444, -2.7443]])\n",
      "tensor([4])\n",
      "tensor([[-2.5625, -2.2472, -1.2465,  0.2765,  1.3319,  0.8104, -1.6593]])\n",
      "tensor([4])\n",
      "tensor([[-2.7358, -2.3948, -1.6974,  0.8381,  1.8037, -0.0181, -2.0156]])\n",
      "tensor([4])\n",
      "tensor([[-2.7967, -2.5991, -1.7149,  0.4633,  1.9678,  0.4936, -1.8891]])\n",
      "tensor([4])\n",
      "tensor([[-3.8816, -2.4841, -1.5979,  1.7814,  1.2675,  0.0477, -2.7395]])\n",
      "tensor([3])\n",
      "tensor([[-3.5681, -3.5529, -2.1684,  0.3239,  2.6158,  1.2034, -2.3841]])\n",
      "tensor([4])\n",
      "tensor([[-3.1833, -3.2768, -2.1305,  0.3000,  2.6495,  0.8000, -2.1415]])\n",
      "tensor([4])\n",
      "tensor([[-3.6284, -3.5461, -2.2256,  0.4940,  2.7036,  0.8560, -2.4799]])\n",
      "tensor([4])\n",
      "tensor([[-3.6838, -3.3933, -1.6240,  0.0087,  1.4190,  2.4600, -2.0134]])\n",
      "tensor([5])\n",
      "tensor([[-3.3373, -2.6989, -1.1629,  0.3937,  0.6189,  1.9856, -2.0026]])\n",
      "tensor([5])\n",
      "tensor([[-4.6729, -4.6406, -2.7352,  0.3005,  3.1935,  1.8673, -2.8753]])\n",
      "tensor([4])\n",
      "tensor([[-4.5003, -4.2430, -2.5035,  0.4994,  2.7600,  1.7469, -2.8218]])\n",
      "tensor([4])\n",
      "tensor([[-2.9904, -2.3979, -1.2871,  0.4900,  1.0077,  1.2292, -1.9390]])\n",
      "tensor([5])\n",
      "tensor([[-3.2812, -3.0572, -1.7277,  0.1950,  1.8561,  1.4649, -2.0641]])\n",
      "tensor([4])\n",
      "tensor([[-2.1059, -0.5690, -0.2380,  1.4730, -0.3658, -0.7099, -1.8124]])\n",
      "tensor([3])\n",
      "tensor([[-3.4766, -3.4246, -2.2887,  0.5777,  2.8284,  0.5321, -2.3974]])\n",
      "tensor([4])\n",
      "tensor([[-3.5469, -3.3622, -2.2022,  0.6326,  2.5959,  0.6452, -2.3902]])\n",
      "tensor([4])\n",
      "tensor([[-5.5968, -5.2580, -3.0431,  0.5939,  3.3877,  2.1627, -3.4527]])\n",
      "tensor([4])\n",
      "tensor([[-4.1423, -3.9943, -2.3557,  0.3672,  2.6496,  1.6356, -2.6621]])\n",
      "tensor([4])\n",
      "tensor([[-3.4697, -3.3734, -2.1440,  0.5504,  2.5549,  0.8022, -2.4514]])\n",
      "tensor([4])\n",
      "tensor([[-5.1215, -5.0563, -2.9044,  0.3264,  3.1548,  2.4626, -3.1482]])\n",
      "tensor([4])\n",
      "tensor([[-5.1448, -5.4018, -3.3992,  0.4559,  4.1595,  1.7000, -3.2847]])\n",
      "tensor([4])\n",
      "tensor([[-4.2903, -4.3330, -2.7291,  0.5078,  3.3112,  1.2292, -2.8482]])\n",
      "tensor([4])\n",
      "tensor([[-2.6324, -2.6817, -1.5774,  0.1174,  1.9821,  0.8333, -1.7896]])\n",
      "tensor([4])\n",
      "tensor([[-2.9250, -2.7733, -1.6680,  0.2726,  1.9285,  0.9845, -1.9561]])\n",
      "tensor([4])\n",
      "tensor([[-2.0562, -1.0208, -0.4800,  0.8690, -0.0864,  0.3127, -1.4814]])\n",
      "tensor([3])\n",
      "tensor([[-3.4346, -3.4113, -2.2176,  0.4295,  2.7247,  0.8112, -2.3260]])\n",
      "tensor([4])\n",
      "tensor([[-3.6403, -3.5701, -2.2077,  0.4527,  2.6362,  1.0335, -2.5021]])\n",
      "tensor([4])\n",
      "tensor([[-3.1451, -2.2906, -1.6192,  1.2398,  1.6390, -0.2107, -2.3043]])\n",
      "tensor([4])\n",
      "tensor([[-2.5536, -2.0331, -1.4747,  0.8236,  1.5267,  0.0165, -1.8455]])\n",
      "tensor([4])\n",
      "tensor([[-3.1653, -2.9990, -1.8704,  0.4307,  2.2068,  0.8084, -2.1893]])\n",
      "tensor([4])\n",
      "tensor([[-2.8881, -2.7235, -1.6920,  0.2875,  1.9866,  0.8337, -1.9198]])\n",
      "tensor([4])\n",
      "tensor([[-4.2315, -3.9111, -2.0703,  0.1693,  2.0768,  2.2939, -2.4481]])\n",
      "tensor([5])\n",
      "tensor([[-4.0371, -4.1509, -2.6026,  0.4056,  3.2485,  1.1398, -2.7127]])\n",
      "tensor([4])\n",
      "tensor([[-3.9736, -3.2084, -1.7534,  0.9039,  1.5338,  1.2857, -2.7238]])\n",
      "tensor([4])\n",
      "tensor([[-3.6380, -2.9574, -1.9704,  1.4187,  2.1039, -0.2316, -2.8613]])\n",
      "tensor([4])\n",
      "tensor([[-4.5324, -4.0771, -2.2317,  0.4514,  2.1875,  2.1276, -2.7438]])\n",
      "tensor([4])\n",
      "tensor([[-4.2617, -3.8525, -2.1645,  0.4759,  2.1401,  1.8751, -2.7406]])\n",
      "tensor([4])\n",
      "tensor([[-2.3444, -1.6788, -1.1890,  0.8380,  1.0851,  0.0417, -1.7110]])\n",
      "tensor([4])\n",
      "tensor([[-4.7026, -4.6449, -2.8060,  0.3728,  3.2226,  1.8166, -2.9170]])\n",
      "tensor([4])\n",
      "Accuracy on the test set: 54 %\n"
     ]
    }
   ],
   "source": [
    "correct = 0\n",
    "total = 0\n",
    "with torch.no_grad():\n",
    "    net.eval()\n",
    "    for i in range(len(x_test)):\n",
    "        inputs, labels =torch.unsqueeze(x_test[i], 0).to(device).float(), torch.unsqueeze(y_test[i], 0).to(device)\n",
    "        outputs, (hn, cn) = net(inputs)\n",
    "        output = torch.mean(outputs, dim=1)  \n",
    "        #print(inputs)\n",
    "        print(output)\n",
    "        _, predicted = torch.max(output.data, 1)\n",
    "        print(predicted)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "final = 100 * correct / total\n",
    "print('Accuracy on the test set: %d %%' % (final))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
