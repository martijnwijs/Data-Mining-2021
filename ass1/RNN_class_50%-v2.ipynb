{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np \n",
    "from sklearn.model_selection import train_test_split\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>no</th>\n",
       "      <th>target</th>\n",
       "      <th>t</th>\n",
       "      <th>activity</th>\n",
       "      <th>appCat.builtin</th>\n",
       "      <th>appCat.communication</th>\n",
       "      <th>appCat.entertainment</th>\n",
       "      <th>appCat.finance</th>\n",
       "      <th>appCat.game</th>\n",
       "      <th>...</th>\n",
       "      <th>appCat.travel</th>\n",
       "      <th>appCat.unknown</th>\n",
       "      <th>appCat.utilities</th>\n",
       "      <th>appCat.weather</th>\n",
       "      <th>call</th>\n",
       "      <th>circumplex.arousal</th>\n",
       "      <th>circumplex.valence</th>\n",
       "      <th>mood</th>\n",
       "      <th>screen</th>\n",
       "      <th>sms</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0.641645</td>\n",
       "      <td>1.103108</td>\n",
       "      <td>1.636492</td>\n",
       "      <td>0.244791</td>\n",
       "      <td>1.129913</td>\n",
       "      <td>-0.259976</td>\n",
       "      <td>...</td>\n",
       "      <td>4.689448</td>\n",
       "      <td>-0.322651</td>\n",
       "      <td>7.439909</td>\n",
       "      <td>-0.230130</td>\n",
       "      <td>1.319838</td>\n",
       "      <td>0.485487</td>\n",
       "      <td>-1.266137</td>\n",
       "      <td>-1.209901</td>\n",
       "      <td>2.770542</td>\n",
       "      <td>-0.497599</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1.074310</td>\n",
       "      <td>-0.242798</td>\n",
       "      <td>1.062958</td>\n",
       "      <td>-0.575133</td>\n",
       "      <td>0.292739</td>\n",
       "      <td>-0.259976</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.207470</td>\n",
       "      <td>-0.322651</td>\n",
       "      <td>1.198651</td>\n",
       "      <td>-0.230130</td>\n",
       "      <td>0.287520</td>\n",
       "      <td>1.143750</td>\n",
       "      <td>-0.496733</td>\n",
       "      <td>-0.899697</td>\n",
       "      <td>0.106958</td>\n",
       "      <td>0.147818</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>0.065088</td>\n",
       "      <td>0.067334</td>\n",
       "      <td>1.182367</td>\n",
       "      <td>-0.574217</td>\n",
       "      <td>0.949321</td>\n",
       "      <td>-0.259976</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.415500</td>\n",
       "      <td>-0.322651</td>\n",
       "      <td>0.063147</td>\n",
       "      <td>2.406086</td>\n",
       "      <td>-0.744797</td>\n",
       "      <td>0.485487</td>\n",
       "      <td>0.272670</td>\n",
       "      <td>-0.279289</td>\n",
       "      <td>0.249101</td>\n",
       "      <td>-0.497599</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>-0.085503</td>\n",
       "      <td>-0.167041</td>\n",
       "      <td>2.937521</td>\n",
       "      <td>0.217447</td>\n",
       "      <td>0.675919</td>\n",
       "      <td>-0.259976</td>\n",
       "      <td>...</td>\n",
       "      <td>1.925529</td>\n",
       "      <td>-0.322651</td>\n",
       "      <td>1.991383</td>\n",
       "      <td>-0.230130</td>\n",
       "      <td>2.696262</td>\n",
       "      <td>1.472881</td>\n",
       "      <td>-1.779072</td>\n",
       "      <td>-1.520105</td>\n",
       "      <td>2.110863</td>\n",
       "      <td>-0.497599</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>1.074310</td>\n",
       "      <td>-0.242798</td>\n",
       "      <td>1.062958</td>\n",
       "      <td>-0.575133</td>\n",
       "      <td>0.292739</td>\n",
       "      <td>-0.259976</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.207470</td>\n",
       "      <td>-0.322651</td>\n",
       "      <td>1.198651</td>\n",
       "      <td>-0.230130</td>\n",
       "      <td>0.287520</td>\n",
       "      <td>1.143750</td>\n",
       "      <td>-0.496733</td>\n",
       "      <td>-0.899697</td>\n",
       "      <td>0.106958</td>\n",
       "      <td>0.147818</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4191</th>\n",
       "      <td>4191</td>\n",
       "      <td>1048</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>0.272023</td>\n",
       "      <td>0.774332</td>\n",
       "      <td>-0.254069</td>\n",
       "      <td>-0.107484</td>\n",
       "      <td>-0.327054</td>\n",
       "      <td>-0.259976</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.415500</td>\n",
       "      <td>-0.322651</td>\n",
       "      <td>0.070671</td>\n",
       "      <td>-0.230130</td>\n",
       "      <td>2.696262</td>\n",
       "      <td>0.156356</td>\n",
       "      <td>1.298542</td>\n",
       "      <td>1.892137</td>\n",
       "      <td>1.947385</td>\n",
       "      <td>0.147818</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4192</th>\n",
       "      <td>4192</td>\n",
       "      <td>1049</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.328753</td>\n",
       "      <td>-0.065428</td>\n",
       "      <td>-0.559067</td>\n",
       "      <td>-0.041053</td>\n",
       "      <td>-0.327054</td>\n",
       "      <td>-0.259976</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.415500</td>\n",
       "      <td>-0.322651</td>\n",
       "      <td>-0.327129</td>\n",
       "      <td>-0.230130</td>\n",
       "      <td>2.696262</td>\n",
       "      <td>-0.501907</td>\n",
       "      <td>-1.779072</td>\n",
       "      <td>-2.450716</td>\n",
       "      <td>2.983480</td>\n",
       "      <td>1.438652</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4193</th>\n",
       "      <td>4193</td>\n",
       "      <td>1049</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>-1.058736</td>\n",
       "      <td>-0.245614</td>\n",
       "      <td>-0.192281</td>\n",
       "      <td>-0.546996</td>\n",
       "      <td>-0.327054</td>\n",
       "      <td>-0.259976</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.415500</td>\n",
       "      <td>-0.322651</td>\n",
       "      <td>0.401548</td>\n",
       "      <td>-0.230130</td>\n",
       "      <td>-0.400691</td>\n",
       "      <td>-0.831038</td>\n",
       "      <td>-0.753201</td>\n",
       "      <td>-1.209901</td>\n",
       "      <td>-0.354860</td>\n",
       "      <td>0.793235</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4194</th>\n",
       "      <td>4194</td>\n",
       "      <td>1049</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>0.272023</td>\n",
       "      <td>0.774332</td>\n",
       "      <td>-0.254069</td>\n",
       "      <td>-0.107484</td>\n",
       "      <td>-0.327054</td>\n",
       "      <td>-0.259976</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.415500</td>\n",
       "      <td>-0.322651</td>\n",
       "      <td>0.070671</td>\n",
       "      <td>-0.230130</td>\n",
       "      <td>2.696262</td>\n",
       "      <td>0.156356</td>\n",
       "      <td>1.298542</td>\n",
       "      <td>1.892137</td>\n",
       "      <td>1.947385</td>\n",
       "      <td>0.147818</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4195</th>\n",
       "      <td>4195</td>\n",
       "      <td>1049</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>1.242266</td>\n",
       "      <td>-0.428041</td>\n",
       "      <td>-0.907386</td>\n",
       "      <td>-0.536193</td>\n",
       "      <td>-0.327054</td>\n",
       "      <td>-0.259976</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.410263</td>\n",
       "      <td>-0.322651</td>\n",
       "      <td>-0.285631</td>\n",
       "      <td>-0.230130</td>\n",
       "      <td>0.975732</td>\n",
       "      <td>-2.037854</td>\n",
       "      <td>0.785606</td>\n",
       "      <td>0.030914</td>\n",
       "      <td>-0.471995</td>\n",
       "      <td>0.147818</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4196 rows × 23 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Unnamed: 0    no  target  t  activity  appCat.builtin  \\\n",
       "0              0     1       4  0  0.641645        1.103108   \n",
       "1              1     1       4  1  1.074310       -0.242798   \n",
       "2              2     1       4  2  0.065088        0.067334   \n",
       "3              3     1       4  3 -0.085503       -0.167041   \n",
       "4              4     2       4  0  1.074310       -0.242798   \n",
       "...          ...   ...     ... ..       ...             ...   \n",
       "4191        4191  1048       4  3  0.272023        0.774332   \n",
       "4192        4192  1049       4  0 -0.328753       -0.065428   \n",
       "4193        4193  1049       4  1 -1.058736       -0.245614   \n",
       "4194        4194  1049       4  2  0.272023        0.774332   \n",
       "4195        4195  1049       4  3  1.242266       -0.428041   \n",
       "\n",
       "      appCat.communication  appCat.entertainment  appCat.finance  appCat.game  \\\n",
       "0                 1.636492              0.244791        1.129913    -0.259976   \n",
       "1                 1.062958             -0.575133        0.292739    -0.259976   \n",
       "2                 1.182367             -0.574217        0.949321    -0.259976   \n",
       "3                 2.937521              0.217447        0.675919    -0.259976   \n",
       "4                 1.062958             -0.575133        0.292739    -0.259976   \n",
       "...                    ...                   ...             ...          ...   \n",
       "4191             -0.254069             -0.107484       -0.327054    -0.259976   \n",
       "4192             -0.559067             -0.041053       -0.327054    -0.259976   \n",
       "4193             -0.192281             -0.546996       -0.327054    -0.259976   \n",
       "4194             -0.254069             -0.107484       -0.327054    -0.259976   \n",
       "4195             -0.907386             -0.536193       -0.327054    -0.259976   \n",
       "\n",
       "      ...  appCat.travel  appCat.unknown  appCat.utilities  appCat.weather  \\\n",
       "0     ...       4.689448       -0.322651          7.439909       -0.230130   \n",
       "1     ...      -0.207470       -0.322651          1.198651       -0.230130   \n",
       "2     ...      -0.415500       -0.322651          0.063147        2.406086   \n",
       "3     ...       1.925529       -0.322651          1.991383       -0.230130   \n",
       "4     ...      -0.207470       -0.322651          1.198651       -0.230130   \n",
       "...   ...            ...             ...               ...             ...   \n",
       "4191  ...      -0.415500       -0.322651          0.070671       -0.230130   \n",
       "4192  ...      -0.415500       -0.322651         -0.327129       -0.230130   \n",
       "4193  ...      -0.415500       -0.322651          0.401548       -0.230130   \n",
       "4194  ...      -0.415500       -0.322651          0.070671       -0.230130   \n",
       "4195  ...      -0.410263       -0.322651         -0.285631       -0.230130   \n",
       "\n",
       "          call  circumplex.arousal  circumplex.valence      mood    screen  \\\n",
       "0     1.319838            0.485487           -1.266137 -1.209901  2.770542   \n",
       "1     0.287520            1.143750           -0.496733 -0.899697  0.106958   \n",
       "2    -0.744797            0.485487            0.272670 -0.279289  0.249101   \n",
       "3     2.696262            1.472881           -1.779072 -1.520105  2.110863   \n",
       "4     0.287520            1.143750           -0.496733 -0.899697  0.106958   \n",
       "...        ...                 ...                 ...       ...       ...   \n",
       "4191  2.696262            0.156356            1.298542  1.892137  1.947385   \n",
       "4192  2.696262           -0.501907           -1.779072 -2.450716  2.983480   \n",
       "4193 -0.400691           -0.831038           -0.753201 -1.209901 -0.354860   \n",
       "4194  2.696262            0.156356            1.298542  1.892137  1.947385   \n",
       "4195  0.975732           -2.037854            0.785606  0.030914 -0.471995   \n",
       "\n",
       "           sms  \n",
       "0    -0.497599  \n",
       "1     0.147818  \n",
       "2    -0.497599  \n",
       "3    -0.497599  \n",
       "4     0.147818  \n",
       "...        ...  \n",
       "4191  0.147818  \n",
       "4192  1.438652  \n",
       "4193  0.793235  \n",
       "4194  0.147818  \n",
       "4195  0.147818  \n",
       "\n",
       "[4196 rows x 23 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load dataset\n",
    "#dataset = \"dataframe_normalized_outliers_removed.csv\" \n",
    "dataset = \"dataframe_standardized_outliers_removed_classes.csv\"\n",
    "#dataset = \"dataframe_new.csv\"  ## debug\n",
    "df = pd.read_csv(dataset) # dataframe in pandas\n",
    "\n",
    "\n",
    "#df = df[df['target'] != 7] # debug check if it learns to predict not only 7\n",
    "df['target'] = df['target'].sub(3)# change to 7 classes 0 1 2 3 4 5 6\n",
    "#df = df[df['target'] != 7]\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>no</th>\n",
       "      <th>target</th>\n",
       "      <th>t</th>\n",
       "      <th>activity</th>\n",
       "      <th>appCat.builtin</th>\n",
       "      <th>appCat.communication</th>\n",
       "      <th>appCat.entertainment</th>\n",
       "      <th>appCat.finance</th>\n",
       "      <th>appCat.game</th>\n",
       "      <th>...</th>\n",
       "      <th>appCat.travel</th>\n",
       "      <th>appCat.unknown</th>\n",
       "      <th>appCat.utilities</th>\n",
       "      <th>appCat.weather</th>\n",
       "      <th>call</th>\n",
       "      <th>circumplex.arousal</th>\n",
       "      <th>circumplex.valence</th>\n",
       "      <th>mood</th>\n",
       "      <th>screen</th>\n",
       "      <th>sms</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>0 rows × 23 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [Unnamed: 0, no, target, t, activity, appCat.builtin, appCat.communication, appCat.entertainment, appCat.finance, appCat.game, appCat.office, appCat.other, appCat.social, appCat.travel, appCat.unknown, appCat.utilities, appCat.weather, call, circumplex.arousal, circumplex.valence, mood, screen, sms]\n",
       "Index: []\n",
       "\n",
       "[0 rows x 23 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[df['target'] == 7]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      Unnamed: 0   no  target  t  activity  appCat.builtin  \\\n",
      "2888        2888  723       4  0 -0.499064       -0.032645   \n",
      "2889        2889  723       4  1  0.989888        0.949300   \n",
      "2890        2890  723       4  2  0.457188        0.335828   \n",
      "2891        2891  723       4  3 -0.154787       -0.272890   \n",
      "\n",
      "      appCat.communication  appCat.entertainment  appCat.finance  appCat.game  \\\n",
      "2888              0.554783             -0.628182       -0.327054    -0.259976   \n",
      "2889              0.538962             -0.513537       -0.327054    -0.259976   \n",
      "2890             -0.591393             -0.658839       -0.327054    -0.259976   \n",
      "2891             -0.855933             -0.658839       -0.327054    -0.259976   \n",
      "\n",
      "      ...  appCat.travel  appCat.unknown  appCat.utilities  appCat.weather  \\\n",
      "2888  ...        -0.4155       -0.322651         -0.089520        -0.23013   \n",
      "2889  ...        -0.4155        0.060803         -0.166846        -0.23013   \n",
      "2890  ...        -0.4155       -0.322651         -0.327129        -0.23013   \n",
      "2891  ...        -0.4155       -0.243459         -0.327129        -0.23013   \n",
      "\n",
      "          call  circumplex.arousal  circumplex.valence      mood    screen  \\\n",
      "2888  1.319838            2.213427           -1.779072 -1.520105 -0.158017   \n",
      "2889  0.975732            0.156356           -0.069287 -1.003098  0.490905   \n",
      "2890 -0.744797           -1.160170            0.785606  0.651322 -0.339057   \n",
      "2891 -0.744797           -1.489301            0.785606  0.030914 -0.797037   \n",
      "\n",
      "           sms  \n",
      "2888 -0.497599  \n",
      "2889  0.793235  \n",
      "2890 -0.497599  \n",
      "2891 -0.497599  \n",
      "\n",
      "[4 rows x 23 columns]\n",
      "Empty DataFrame\n",
      "Columns: [Unnamed: 0, no, target, t, activity, appCat.builtin, appCat.communication, appCat.entertainment, appCat.finance, appCat.game, appCat.office, appCat.other, appCat.social, appCat.travel, appCat.unknown, appCat.utilities, appCat.weather, call, circumplex.arousal, circumplex.valence, mood, screen, sms]\n",
      "Index: []\n",
      "\n",
      "[0 rows x 23 columns]\n"
     ]
    }
   ],
   "source": [
    "print(df[df['no'] == 723])\n",
    "for i in range(720, 730):  ### debug\n",
    "    df = df[df['no'] != i]\n",
    "print(df[df['no'] == 723])\n",
    "df = df.sample(frac=1) # shuffle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1039"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get labels\n",
    "Y = df['target'].to_numpy()\n",
    "Y = Y[::4]\n",
    "len(Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get input \n",
    "X = df.iloc[:, 3:].to_numpy()\n",
    "X = X[:, 1:]\n",
    "split = len(X[:, 0]) / 4\n",
    "X = np.array_split(X, split)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split train and test set\n",
    "x_train, x_test, y_train, y_test = train_test_split(X, Y, test_size=0.2, random_state=123, shuffle=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# k-fold cross validation\n",
    "from sklearn import cross_validation\n",
    "kf = cross_validation.KFold(1039, n_folds=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 16\n",
    "def batch_generator(X, Y, batch_size):\n",
    "    batchesx = []\n",
    "    batchesy = []\n",
    "    batchx = [] # batches\n",
    "    batchy = []\n",
    "    for i in range(len(X)):\n",
    "        batchx.append(X[i]) # add to batch\n",
    "        batchy.append(Y[i])\n",
    "        #print(batchy)\n",
    "        if i % batch_size == 0: # batch full?\n",
    "            batchesx.append([batchx])\n",
    "            batchesy.append([batchy])\n",
    "            batchx = [] # batches\n",
    "            batchy = []\n",
    "    print(batchesy)\n",
    "    return batchesx, batchesy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# to torch tensor\n",
    "x_train = torch.tensor(x_train)\n",
    "#x_train = x_train[:724]#### debug\n",
    "#for i in range(710, 730):  ### debug\n",
    "    #np.delete(x_train, i)\n",
    "    #np.delete(y_train, i)\n",
    "#x_train = x_train[4:] ## debug\n",
    "y_train = torch.tensor(y_train).to(torch.int64)\n",
    "#print(x_train[724])\n",
    "#print(y_train[724])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test = torch.tensor(x_test)\n",
    "y_test = torch.tensor(y_test).to(torch.int64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(x_train[728])\n",
    "#print(y_train[728])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cpu\n"
     ]
    }
   ],
   "source": [
    "# training on GPU\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class lstm(nn.Module):\n",
    "    def __init__ (self, input_size, hidden_size, num_layers, seq_length, output_size):\n",
    "        super(). __init__()\n",
    "        self.input_size = input_size\n",
    "        self.hidden_size = hidden_size\n",
    "        self.num_layers = num_layers\n",
    "        self.seq_length = seq_length\n",
    "        self.output_size = output_size\n",
    "        self.hidden_lin_size = 20\n",
    "        \n",
    "        self.ltsm = torch.nn.LSTM(self.input_size, self.hidden_size, batch_first=True) \n",
    "        #self.dropout = torch.nn.Dropout(0.3)\n",
    "        self.lin1 = nn.Linear(self.hidden_size, self.hidden_lin_size) \n",
    "        self.lin2 = nn.Linear(self.hidden_lin_size, self.output_size)\n",
    "    def forward(self, x):\n",
    "        x, (hn, cn) = self.ltsm(x)\n",
    "        #x  = self.dropout(x)\n",
    "        x = F.relu(x) # is this ok?\n",
    "        x = F.relu(self.lin1(x))  \n",
    "        x = self.lin2(x)\n",
    "        return x, (hn, cn)\n",
    "net = lstm(input_size=19, hidden_size=100, num_layers=1, seq_length=4, output_size=7).float()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 1 2 3 4 5 6]\n",
      "[  1   9  18 189 414 189  11]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([0.9988, 0.9892, 0.9783, 0.7726, 0.5018, 0.7726, 0.9868])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# weighted cross entropy\n",
    "unique, counts = np.unique(y_train, return_counts=True)\n",
    "print(unique)\n",
    "print(counts)\n",
    "nSamples = [887, 6130, 480, 317, 972, 101, 128]\n",
    "normedWeights = [(1 - (x / sum(counts))) for x in counts]\n",
    "normedWeights = torch.FloatTensor(normedWeights).to(device)\n",
    "normedWeights\n",
    "# way 2\n",
    "#normedWeights = counts / sum(counts)\n",
    "#normedWeights = torch.FloatTensor(normedWeights).to(device)\n",
    "#normedWeights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "\n",
    "learning_rate = 0.001\n",
    "#criterion =  nn.MSELoss()    # MSE for regression\n",
    "criterion = nn.CrossEntropyLoss(weight=normedWeights)\n",
    "optimizer = optim.Adam(net.parameters(), lr=learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "target = torch.randint(0, 10, (10,))\n",
    "one_hot = torch.nn.functional.one_hot(target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1,   100] loss: 1.649\n",
      "[1,   200] loss: 1.269\n",
      "[1,   300] loss: 1.185\n",
      "[1,   400] loss: 1.361\n",
      "[1,   500] loss: 1.154\n",
      "[1,   600] loss: 1.277\n",
      "[1,   700] loss: 1.211\n",
      "[1,   800] loss: 1.206\n",
      "[2,   100] loss: 1.204\n",
      "[2,   200] loss: 1.192\n",
      "[2,   300] loss: 1.169\n",
      "[2,   400] loss: 1.283\n",
      "[2,   500] loss: 1.136\n",
      "[2,   600] loss: 1.253\n",
      "[2,   700] loss: 1.195\n",
      "[2,   800] loss: 1.174\n",
      "[3,   100] loss: 1.163\n",
      "[3,   200] loss: 1.146\n",
      "[3,   300] loss: 1.143\n",
      "[3,   400] loss: 1.200\n",
      "[3,   500] loss: 1.105\n",
      "[3,   600] loss: 1.219\n",
      "[3,   700] loss: 1.182\n",
      "[3,   800] loss: 1.113\n",
      "[4,   100] loss: 1.110\n",
      "[4,   200] loss: 1.101\n",
      "[4,   300] loss: 1.093\n",
      "[4,   400] loss: 1.124\n",
      "[4,   500] loss: 1.077\n",
      "[4,   600] loss: 1.172\n",
      "[4,   700] loss: 1.167\n",
      "[4,   800] loss: 1.075\n",
      "[5,   100] loss: 1.066\n",
      "[5,   200] loss: 1.044\n",
      "[5,   300] loss: 1.057\n",
      "[5,   400] loss: 1.067\n",
      "[5,   500] loss: 1.045\n",
      "[5,   600] loss: 1.132\n",
      "[5,   700] loss: 1.135\n",
      "[5,   800] loss: 1.035\n",
      "Finished Training\n"
     ]
    }
   ],
   "source": [
    "# train the network\n",
    "\n",
    "n = 10 # for one hot\n",
    "\n",
    "for epoch in range(5):\n",
    "    running_loss = 0.0\n",
    "    net.train()\n",
    "    for i in range(len(x_train)):\n",
    "        \n",
    "        # get the inputs\n",
    "        #print(torch.unsqueeze(x_train[i], 0))\n",
    "        inputs, labels =torch.unsqueeze(x_train[i], 0).to(device).float(), torch.unsqueeze(y_train[i], 0).to(device)\n",
    "        labels_onehot = torch.nn.functional.one_hot(labels[0].to(torch.int64), n)\n",
    "        # zero the parameter gradients\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # forward + backward + optimize\n",
    "        outputs, (hn, cn) = net(inputs)\n",
    "        #print(outputs)\n",
    "        output = torch.mean(outputs, dim=1) # takes the average over the outputs \n",
    "        #output = outputs[3] # takes the last, (does that makes more sense)\n",
    "        \n",
    "        #print(output[0])\n",
    "        #print(labels[0])\n",
    "        loss = criterion(output, labels)\n",
    "        loss.backward() \n",
    "        optimizer.step()\n",
    "        #print(i, loss.item())\n",
    "        # running loss\n",
    "        running_loss += loss.item()\n",
    "        #print(i, loss.item())\n",
    "        # statistics tensorboard\n",
    "        if i % 100 == 99:    # every 30 mini-batches\n",
    "\n",
    "            # print\n",
    "            print('[%d, %5d] loss: %.3f' %\n",
    "                  (epoch + 1, i + 1, running_loss / 100))\n",
    "            \n",
    "            '''\n",
    "            # ...log the running loss\n",
    "            writer.add_scalar('training loss',\n",
    "                            running_loss / 30,\n",
    "                            epoch * len(x_train) + i)\n",
    "            '''\n",
    "            running_loss = 0.0\n",
    "'''\n",
    "    # run on validation set\n",
    "    net.eval()\n",
    "    for j, data in enumerate(x_val, 0):\n",
    "        inputs, labels = x_val[j].to(device), y_val[j].to(device)\n",
    "        \n",
    "        # calculate outputs and loss\n",
    "        outputs, (hn, cn) = net(inputs)\n",
    "        output = torch.mean(outputs, dim=1)  \n",
    "        loss = criterion(output, labels)\n",
    "        \n",
    "        # running loss\n",
    "        running_loss += loss.item()\n",
    "        \n",
    "    # add to tensorboard\n",
    "    writer.add_scalar('validation_loss',\n",
    "                            running_loss / j,\n",
    "                            epoch)\n",
    "    print(\"validation loss:\", running_loss / j, j)\n",
    "'''\n",
    "print('Finished Training')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-6.0773, -2.6571, -2.0613,  1.0869,  1.9190,  0.1081, -2.9969]])\n",
      "tensor([4])\n",
      "tensor([[-7.9946, -3.6186, -2.6556,  1.7467,  2.3851, -0.4765, -4.3830]])\n",
      "tensor([4])\n",
      "tensor([[-5.0270, -2.5029, -1.5327,  1.2578,  0.7767,  0.1048, -2.6059]])\n",
      "tensor([3])\n",
      "tensor([[-6.2161, -2.7991, -2.0840,  1.1434,  1.7831,  0.2237, -3.0527]])\n",
      "tensor([4])\n",
      "tensor([[-7.5548, -3.5459, -2.3874,  1.9479,  2.0439, -0.8438, -4.4658]])\n",
      "tensor([4])\n",
      "tensor([[-8.0933, -3.6407, -2.8047,  1.5400,  2.3070,  0.0439, -4.1144]])\n",
      "tensor([4])\n",
      "tensor([[-5.4212, -2.2722, -2.2242,  0.2066,  1.5678,  1.7872, -1.5237]])\n",
      "tensor([5])\n",
      "tensor([[-8.6763, -3.9870, -2.8921,  2.0557,  2.5123, -0.8182, -4.9384]])\n",
      "tensor([4])\n",
      "tensor([[-4.8633, -2.4356, -1.3560,  1.5155,  1.0495, -0.7573, -3.0892]])\n",
      "tensor([3])\n",
      "tensor([[-6.4433, -3.2139, -1.8610,  1.9750,  1.4001, -0.9848, -4.0811]])\n",
      "tensor([3])\n",
      "tensor([[-5.9610, -2.7898, -1.8459,  1.4719,  1.5774, -0.3874, -3.3380]])\n",
      "tensor([4])\n",
      "tensor([[-7.5407, -3.3804, -2.5903,  1.4779,  2.2148, -0.0523, -3.8557]])\n",
      "tensor([4])\n",
      "tensor([[-6.7634, -3.1374, -2.0867,  1.6086,  1.9148, -0.5186, -3.8536]])\n",
      "tensor([4])\n",
      "tensor([[-10.0331,  -4.6970,  -3.6991,   1.7237,   2.0950,   0.9528,  -4.6279]])\n",
      "tensor([4])\n",
      "tensor([[-7.2856, -3.2597, -2.3911,  1.5916,  2.2951, -0.4955, -4.0271]])\n",
      "tensor([4])\n",
      "tensor([[-5.5818, -2.5296, -2.1637,  0.5337,  1.2679,  1.4381, -1.9078]])\n",
      "tensor([5])\n",
      "tensor([[-6.9374, -3.0624, -2.5284,  1.0216,  2.0039,  0.6444, -3.0660]])\n",
      "tensor([4])\n",
      "tensor([[-8.3636, -3.7469, -3.0547,  1.3338,  2.2987,  0.6131, -3.8606]])\n",
      "tensor([4])\n",
      "tensor([[-5.6233, -2.6209, -1.8599,  1.1648,  1.4368,  0.0983, -2.8243]])\n",
      "tensor([4])\n",
      "tensor([[-4.9224, -2.2908, -1.6435,  0.9424,  1.2207,  0.3469, -2.2958]])\n",
      "tensor([4])\n",
      "tensor([[-4.8475, -2.1043, -1.8823,  0.3059,  1.1620,  1.6340, -1.4088]])\n",
      "tensor([5])\n",
      "tensor([[-6.7293, -2.9247, -2.8017,  0.3298,  1.5324,  2.3079, -1.9180]])\n",
      "tensor([5])\n",
      "tensor([[-6.5214, -3.3000, -1.8602,  2.0497,  1.1944, -1.0186, -4.2168]])\n",
      "tensor([3])\n",
      "tensor([[-7.3315, -3.2904, -2.8839,  0.8091,  1.7967,  1.4229, -2.7796]])\n",
      "tensor([4])\n",
      "tensor([[-6.9948, -3.1786, -2.3045,  1.3890,  1.9334,  0.1209, -3.5142]])\n",
      "tensor([4])\n",
      "tensor([[-5.3637, -2.4993, -1.6892,  1.1980,  1.3517,  0.0127, -2.7545]])\n",
      "tensor([4])\n",
      "tensor([[-3.4686, -1.5656, -1.2345,  0.3102,  0.8308,  1.0474, -1.1056]])\n",
      "tensor([5])\n",
      "tensor([[-3.3328, -1.6346, -0.9292,  0.7856,  0.6873,  0.1664, -1.6137]])\n",
      "tensor([3])\n",
      "tensor([[-5.6422, -2.5189, -2.2484,  0.3780,  1.2355,  1.7937, -1.7412]])\n",
      "tensor([5])\n",
      "tensor([[-5.5031, -2.7604, -1.4442,  1.7946,  1.1467, -1.1382, -3.7885]])\n",
      "tensor([3])\n",
      "tensor([[-7.6929, -3.5042, -2.5175,  1.6938,  2.2295, -0.3967, -4.2162]])\n",
      "tensor([4])\n",
      "tensor([[-7.0001, -3.1461, -2.4060,  1.3400,  2.0439,  0.0492, -3.5228]])\n",
      "tensor([4])\n",
      "tensor([[-8.4722, -3.8289, -3.0063,  1.5117,  2.2822,  0.3612, -4.0962]])\n",
      "tensor([4])\n",
      "tensor([[-10.3484,  -4.7056,  -3.8135,   1.7306,   2.6959,   0.5744,  -4.9639]])\n",
      "tensor([4])\n",
      "tensor([[-6.3894, -3.1852, -1.8655,  1.9813,  1.3323, -1.0076, -4.0856]])\n",
      "tensor([3])\n",
      "tensor([[-4.7473, -2.0795, -1.8847,  0.2402,  1.0861,  1.7160, -1.3089]])\n",
      "tensor([5])\n",
      "tensor([[-9.8252, -4.4190, -3.5489,  1.7123,  2.7024,  0.3636, -4.7873]])\n",
      "tensor([4])\n",
      "tensor([[-6.8861, -3.1331, -2.2334,  1.4298,  1.9513, -0.0462, -3.5849]])\n",
      "tensor([4])\n",
      "tensor([[-6.5946, -3.0253, -2.2231,  1.3208,  1.8266,  0.0307, -3.3562]])\n",
      "tensor([4])\n",
      "tensor([[-7.9328, -3.4501, -3.0514,  0.9093,  2.2882,  1.1788, -3.2239]])\n",
      "tensor([4])\n",
      "tensor([[-7.0441, -3.1191, -2.5894,  0.9664,  1.9546,  0.8497, -3.0316]])\n",
      "tensor([4])\n",
      "tensor([[-7.1546, -3.1480, -2.8011,  0.7412,  1.9331,  1.3577, -2.7235]])\n",
      "tensor([4])\n",
      "tensor([[-9.4818, -4.2412, -3.6521,  1.2410,  2.4667,  1.2348, -4.0075]])\n",
      "tensor([4])\n",
      "tensor([[-4.6149, -2.3426, -1.3065,  1.2574,  0.6185, -0.0246, -2.5029]])\n",
      "tensor([3])\n",
      "tensor([[-4.5506, -2.0671, -1.5751,  0.7046,  1.1922,  0.6066, -1.9045]])\n",
      "tensor([4])\n",
      "tensor([[-4.7806, -2.0228, -1.9230,  0.1835,  1.2439,  1.7829, -1.2614]])\n",
      "tensor([5])\n",
      "tensor([[-9.7367, -4.6402, -3.1846,  2.4597,  2.1962, -0.6720, -5.5359]])\n",
      "tensor([3])\n",
      "tensor([[-5.6492, -2.6596, -2.0175,  0.9015,  1.1074,  0.8618, -2.3476]])\n",
      "tensor([4])\n",
      "tensor([[-5.2079, -2.6363, -1.4015,  1.6181,  0.9100, -0.6964, -3.2970]])\n",
      "tensor([3])\n",
      "tensor([[-4.8081, -2.2651, -1.3062,  1.2559,  1.3010, -0.3336, -2.7616]])\n",
      "tensor([4])\n",
      "tensor([[-6.8994, -3.3995, -2.2166,  1.6436,  1.1174,  0.0960, -3.6355]])\n",
      "tensor([3])\n",
      "tensor([[-4.8392, -2.4391, -1.1673,  1.5259,  0.8758, -0.6592, -3.1418]])\n",
      "tensor([3])\n",
      "tensor([[-3.8891, -1.9506, -0.9745,  1.1503,  0.7846, -0.3338, -2.3309]])\n",
      "tensor([3])\n",
      "tensor([[-6.1886, -2.7429, -2.4167,  0.5929,  1.5871,  1.4414, -2.1658]])\n",
      "tensor([4])\n",
      "tensor([[-5.9784, -2.5972, -2.4577,  0.2971,  1.4906,  1.9409, -1.7285]])\n",
      "tensor([5])\n",
      "tensor([[-8.0747, -3.7199, -3.0594,  1.1715,  1.7785,  1.1672, -3.4177]])\n",
      "tensor([4])\n",
      "tensor([[-4.9114, -2.1679, -1.7819,  0.5844,  1.3734,  0.8920, -1.9112]])\n",
      "tensor([4])\n",
      "tensor([[-5.1682, -2.4268, -1.5025,  1.2526,  1.3297, -0.1513, -2.8124]])\n",
      "tensor([4])\n",
      "tensor([[-7.8294, -3.6310, -2.7562,  1.4153,  1.8758,  0.5035, -3.7491]])\n",
      "tensor([4])\n",
      "tensor([[-5.9567, -2.6254, -2.2871,  0.6309,  1.6161,  1.2128, -2.1801]])\n",
      "tensor([4])\n",
      "tensor([[-3.3844, -1.6241, -0.8941,  0.8174,  0.8063,  0.0426, -1.7511]])\n",
      "tensor([3])\n",
      "tensor([[-7.0653, -3.1424, -2.5405,  1.1137,  2.0050,  0.5351, -3.2468]])\n",
      "tensor([4])\n",
      "tensor([[-7.1631, -3.2692, -2.2619,  1.6600,  2.1056, -0.4948, -4.0176]])\n",
      "tensor([4])\n",
      "tensor([[-6.4382, -2.8745, -2.5833,  0.4280,  1.2958,  2.0893, -2.0090]])\n",
      "tensor([5])\n",
      "tensor([[-4.5016, -1.8934, -1.8117,  0.1372,  1.1887,  1.7495, -1.1225]])\n",
      "tensor([5])\n",
      "tensor([[-4.3354, -1.9861, -1.3704,  0.8441,  1.1954,  0.2175, -2.0703]])\n",
      "tensor([4])\n",
      "tensor([[-5.6657, -2.7097, -1.6925,  1.5316,  1.3328, -0.5015, -3.2604]])\n",
      "tensor([3])\n",
      "tensor([[-6.5295, -2.9891, -2.0851,  1.4143,  1.8562, -0.1594, -3.4763]])\n",
      "tensor([4])\n",
      "tensor([[-5.8228, -2.6442, -2.0173,  0.9771,  1.5384,  0.5169, -2.6515]])\n",
      "tensor([4])\n",
      "tensor([[-5.9859, -2.8347, -1.7615,  1.6471,  1.6742, -0.8472, -3.7089]])\n",
      "tensor([4])\n",
      "tensor([[-6.9763, -3.2803, -2.1941,  1.8113,  1.7884, -0.6304, -4.0163]])\n",
      "tensor([3])\n",
      "tensor([[-6.1691, -2.9289, -2.1541,  1.1003,  1.2473,  0.6765, -2.7529]])\n",
      "tensor([4])\n",
      "tensor([[-5.9929, -2.7781, -1.9281,  1.2617,  1.5733,  0.0461, -3.0701]])\n",
      "tensor([4])\n",
      "tensor([[-7.8289, -3.6419, -2.5290,  1.8660,  2.0947, -0.5416, -4.4064]])\n",
      "tensor([4])\n",
      "tensor([[-4.9244, -2.2572, -1.7483,  0.8095,  1.2407,  0.5636, -2.1018]])\n",
      "tensor([4])\n",
      "tensor([[-4.5158, -2.3329, -1.1476,  1.3919,  0.6532, -0.4598, -2.7729]])\n",
      "tensor([3])\n",
      "tensor([[-6.1756, -2.9253, -1.8304,  1.6273,  1.5914, -0.5743, -3.6006]])\n",
      "tensor([3])\n",
      "tensor([[-8.4781, -3.8739, -2.7890,  1.8529,  2.3064, -0.3046, -4.5801]])\n",
      "tensor([4])\n",
      "tensor([[-5.9443, -2.8490, -1.8130,  1.5188,  1.3407, -0.2737, -3.2614]])\n",
      "tensor([3])\n",
      "tensor([[-6.3551, -2.8192, -2.4300,  0.7464,  1.6725,  1.1471, -2.4150]])\n",
      "tensor([4])\n",
      "tensor([[-6.7628, -3.1287, -2.2380,  1.4544,  1.7995, -0.1487, -3.5707]])\n",
      "tensor([4])\n",
      "tensor([[-7.5089, -3.6403, -2.3668,  1.9988,  1.6157, -0.5838, -4.3416]])\n",
      "tensor([3])\n",
      "tensor([[-6.2470, -2.8812, -2.0910,  1.1534,  1.6268,  0.3145, -3.0156]])\n",
      "tensor([4])\n",
      "tensor([[-5.3726, -2.5164, -1.9890,  0.6393,  1.0385,  1.2531, -1.9717]])\n",
      "tensor([5])\n",
      "tensor([[-7.6162, -3.4743, -2.7695,  1.2741,  1.9052,  0.6160, -3.4950]])\n",
      "tensor([4])\n",
      "tensor([[-4.6594, -2.1913, -1.3233,  1.1690,  1.2513, -0.2316, -2.5825]])\n",
      "tensor([4])\n",
      "tensor([[-5.4214, -2.4412, -2.0815,  0.4267,  1.1069,  1.6729, -1.7164]])\n",
      "tensor([5])\n",
      "tensor([[-6.7580, -3.1905, -2.0462,  1.7771,  1.8238, -0.7567, -4.0279]])\n",
      "tensor([4])\n",
      "tensor([[-6.3228, -2.9838, -2.1948,  1.1979,  1.4008,  0.4666, -2.9512]])\n",
      "tensor([4])\n",
      "tensor([[-7.6442, -3.5432, -2.8887,  1.1015,  1.6650,  1.1695, -3.1906]])\n",
      "tensor([4])\n",
      "tensor([[-6.5099, -3.0037, -2.0569,  1.4353,  1.7652, -0.1360, -3.4646]])\n",
      "tensor([4])\n",
      "tensor([[-7.9231, -3.7256, -3.0137,  0.8080,  1.0740,  2.1892, -2.8491]])\n",
      "tensor([5])\n",
      "tensor([[-4.9037, -2.3041, -1.3480,  1.3021,  1.3792, -0.4577, -2.8972]])\n",
      "tensor([4])\n",
      "tensor([[-6.9482, -3.1870, -2.4383,  1.2126,  1.7525,  0.5550, -3.2229]])\n",
      "tensor([4])\n",
      "tensor([[-5.6121, -2.4201, -2.2292,  0.3468,  1.3305,  1.8507, -1.6733]])\n",
      "tensor([5])\n",
      "tensor([[-7.5571, -3.4601, -2.4551,  1.7625,  2.2104, -0.6183, -4.2788]])\n",
      "tensor([4])\n",
      "tensor([[-9.5130, -4.2964, -3.2351,  2.0158,  2.7850, -0.4592, -5.1600]])\n",
      "tensor([4])\n",
      "tensor([[-6.3647, -2.8568, -2.3263,  0.9450,  1.7483,  0.6868, -2.7514]])\n",
      "tensor([4])\n",
      "tensor([[-6.3120, -2.9731, -1.9269,  1.6731,  1.6985, -0.7040, -3.7387]])\n",
      "tensor([4])\n",
      "tensor([[-7.8592, -3.4897, -2.6709,  1.5358,  2.4040, -0.1268, -4.0771]])\n",
      "tensor([4])\n",
      "tensor([[-9.0884, -4.1371, -3.2759,  1.6191,  2.4012,  0.3749, -4.4325]])\n",
      "tensor([4])\n",
      "tensor([[-8.1665, -3.8853, -2.7097,  1.8645,  1.8621, -0.1565, -4.3733]])\n",
      "tensor([3])\n",
      "tensor([[-6.6553, -3.0274, -2.1193,  1.4827,  1.9058, -0.2480, -3.5878]])\n",
      "tensor([4])\n",
      "tensor([[-6.0913, -2.8171, -1.8682,  1.3661,  1.6345, -0.0924, -3.2548]])\n",
      "tensor([4])\n",
      "tensor([[-3.1416, -1.5767, -0.7347,  0.9458,  0.6904, -0.3085, -1.8538]])\n",
      "tensor([3])\n",
      "tensor([[-3.3657, -1.5529, -0.8872,  0.8319,  1.0575, -0.1734, -1.8412]])\n",
      "tensor([4])\n",
      "tensor([[-7.2811, -3.3222, -2.7956,  0.9476,  1.6876,  1.2089, -2.9334]])\n",
      "tensor([4])\n",
      "tensor([[-7.3169, -3.4649, -2.2937,  1.8555,  1.8801, -0.6332, -4.2120]])\n",
      "tensor([4])\n",
      "tensor([[-8.1009, -3.7087, -3.1908,  0.8383,  1.6883,  1.9142, -2.9317]])\n",
      "tensor([5])\n",
      "tensor([[-4.8617, -2.1145, -1.9048,  0.3455,  1.3452,  1.3563, -1.5030]])\n",
      "tensor([5])\n",
      "tensor([[-7.2476, -3.5386, -2.5587,  0.9878,  0.6932,  1.6574, -2.8999]])\n",
      "tensor([5])\n",
      "tensor([[-6.6378, -2.8936, -2.5979,  0.6092,  1.7927,  1.4515, -2.3825]])\n",
      "tensor([4])\n",
      "tensor([[-7.9026, -3.5960, -2.5826,  1.7844,  2.3238, -0.5232, -4.3881]])\n",
      "tensor([4])\n",
      "tensor([[-6.6671, -3.0295, -2.1837,  1.4519,  1.9895, -0.3338, -3.6327]])\n",
      "tensor([4])\n",
      "tensor([[-9.9781, -4.5875, -3.3917,  2.1962,  2.6479, -0.4580, -5.4430]])\n",
      "tensor([4])\n",
      "tensor([[-5.5338, -2.6946, -1.6625,  1.4457,  1.1673, -0.3416, -3.1398]])\n",
      "tensor([3])\n",
      "tensor([[-9.5723, -4.3118, -3.3410,  1.8738,  2.7499, -0.1239, -4.9683]])\n",
      "tensor([4])\n",
      "tensor([[-7.1092, -3.2026, -2.2576,  1.5926,  2.1812, -0.4515, -3.9448]])\n",
      "tensor([4])\n",
      "tensor([[-7.5322, -3.3518, -2.8703,  0.9533,  2.0162,  1.1050, -3.0981]])\n",
      "tensor([4])\n",
      "tensor([[-5.8545, -2.6655, -2.2427,  0.7073,  1.3471,  1.1998, -2.1717]])\n",
      "tensor([4])\n",
      "tensor([[-7.8854, -3.6142, -2.8275,  1.4431,  2.0261,  0.3085, -3.8362]])\n",
      "tensor([4])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-7.3381, -3.4708, -2.4676,  1.6662,  1.7316, -0.1516, -3.9013]])\n",
      "tensor([4])\n",
      "tensor([[-4.2333, -1.7129, -1.7544,  0.0419,  1.2838,  1.6605, -1.0077]])\n",
      "tensor([5])\n",
      "tensor([[-7.7827, -3.6305, -3.0223,  0.8721,  1.4243,  1.8258, -2.8742]])\n",
      "tensor([5])\n",
      "tensor([[-5.4786, -2.4768, -1.7691,  1.1117,  1.5823,  0.0220, -2.7923]])\n",
      "tensor([4])\n",
      "tensor([[-5.7385, -2.8138, -1.6746,  1.6263,  1.2360, -0.5363, -3.3745]])\n",
      "tensor([3])\n",
      "tensor([[-5.4171, -2.6025, -1.5837,  1.5096,  1.4807, -0.7399, -3.3075]])\n",
      "tensor([3])\n",
      "tensor([[-8.6589, -3.9144, -2.9806,  1.7533,  2.4509, -0.1686, -4.5463]])\n",
      "tensor([4])\n",
      "tensor([[-7.6707, -3.4822, -2.5412,  1.5945,  2.1977, -0.1518, -4.0499]])\n",
      "tensor([4])\n",
      "tensor([[-5.1135, -2.3985, -1.8328,  0.7222,  1.0302,  0.9558, -2.0407]])\n",
      "tensor([4])\n",
      "tensor([[-6.0500, -2.6714, -2.3115,  0.6359,  1.6333,  1.2070, -2.2748]])\n",
      "tensor([4])\n",
      "tensor([[-5.3330, -2.4661, -1.7004,  1.2468,  1.5614, -0.3167, -2.8990]])\n",
      "tensor([4])\n",
      "tensor([[-7.6714, -3.4926, -2.5341,  1.7865,  2.3903, -0.7972, -4.4216]])\n",
      "tensor([4])\n",
      "tensor([[-4.6415, -2.2588, -1.3506,  1.2971,  1.0889, -0.3949, -2.6758]])\n",
      "tensor([3])\n",
      "tensor([[-5.6476, -2.6715, -1.7284,  1.4988,  1.5049, -0.5696, -3.2711]])\n",
      "tensor([4])\n",
      "tensor([[-6.8442, -3.2334, -2.5435,  0.7628,  0.9318,  1.8065, -2.4960]])\n",
      "tensor([5])\n",
      "tensor([[-10.4027,  -4.8983,  -3.5846,   2.2873,   2.2957,  -0.0847,  -5.5268]])\n",
      "tensor([4])\n",
      "tensor([[-4.1363, -2.1009, -0.9256,  1.2687,  0.7083, -0.3800, -2.5566]])\n",
      "tensor([3])\n",
      "tensor([[-4.9447, -2.3500, -1.4670,  1.3243,  1.2767, -0.4558, -2.8716]])\n",
      "tensor([3])\n",
      "tensor([[-4.3184, -1.8931, -1.6515,  0.3349,  1.1778,  1.1824, -1.3740]])\n",
      "tensor([5])\n",
      "tensor([[-9.1638, -4.0881, -3.3484,  1.4797,  2.5524,  0.5485, -4.3040]])\n",
      "tensor([4])\n",
      "tensor([[-8.2072, -3.6707, -2.7952,  1.6049,  2.4434, -0.1129, -4.2787]])\n",
      "tensor([4])\n",
      "tensor([[-7.5861, -3.4589, -2.6097,  1.4154,  2.0438,  0.2595, -3.7284]])\n",
      "tensor([4])\n",
      "tensor([[-3.1929, -1.3548, -1.2254,  0.1368,  0.9390,  1.1521, -0.7829]])\n",
      "tensor([5])\n",
      "tensor([[-3.8383, -2.0012, -0.7835,  1.2506,  0.4998, -0.4278, -2.4618]])\n",
      "tensor([3])\n",
      "tensor([[-6.7488, -3.0940, -2.1955,  1.4670,  1.9062, -0.2011, -3.5939]])\n",
      "tensor([4])\n",
      "tensor([[-6.9193, -3.1403, -2.3315,  1.3444,  1.9021,  0.1291, -3.4823]])\n",
      "tensor([4])\n",
      "tensor([[-9.1947, -4.1097, -3.1825,  1.8062,  2.7457, -0.2067, -4.8158]])\n",
      "tensor([4])\n",
      "tensor([[-8.7139, -3.9399, -2.9563,  1.7805,  2.5066, -0.2210, -4.6229]])\n",
      "tensor([4])\n",
      "tensor([[-7.4015, -3.4842, -2.3906,  1.8504,  1.8678, -0.5606, -4.1941]])\n",
      "tensor([4])\n",
      "tensor([[-7.0717, -3.2379, -2.3471,  1.4524,  1.9177,  0.0307, -3.6174]])\n",
      "tensor([4])\n",
      "tensor([[-8.4637, -3.8131, -3.3745,  0.8425,  1.9112,  1.9348, -3.0851]])\n",
      "tensor([5])\n",
      "tensor([[-4.8221, -2.2604, -1.4342,  1.1250,  1.2931, -0.0946, -2.5604]])\n",
      "tensor([4])\n",
      "tensor([[-3.1187, -1.6881, -0.6179,  1.0644,  0.3579, -0.4210, -2.0503]])\n",
      "tensor([3])\n",
      "tensor([[-7.8598, -3.6125, -3.1434,  0.7259,  1.5094,  2.0900, -2.7089]])\n",
      "tensor([5])\n",
      "tensor([[-5.2791, -2.2848, -2.1305,  0.3014,  1.3431,  1.6802, -1.5752]])\n",
      "tensor([5])\n",
      "tensor([[-8.3598, -3.8516, -2.7848,  1.8031,  2.2477, -0.2608, -4.5091]])\n",
      "tensor([4])\n",
      "tensor([[-8.7239, -3.9262, -3.4761,  0.8853,  2.0002,  1.8686, -3.2672]])\n",
      "tensor([4])\n",
      "tensor([[-6.3351, -2.9055, -1.9957,  1.4681,  1.7935, -0.3420, -3.4828]])\n",
      "tensor([4])\n",
      "tensor([[-4.1694, -2.0785, -1.0543,  1.3207,  0.9450, -0.6662, -2.6842]])\n",
      "tensor([3])\n",
      "tensor([[-6.9882, -3.3699, -2.5748,  0.8736,  0.8742,  1.6976, -2.6604]])\n",
      "tensor([5])\n",
      "tensor([[-7.1222, -3.1689, -2.7845,  0.4360,  1.2927,  2.4748, -2.1517]])\n",
      "tensor([5])\n",
      "tensor([[-4.5551, -2.0282, -1.6826,  0.4568,  1.1405,  1.1418, -1.5398]])\n",
      "tensor([5])\n",
      "tensor([[-5.1092, -2.2783, -1.8698,  0.6003,  1.3762,  0.9775, -1.9602]])\n",
      "tensor([4])\n",
      "tensor([[-9.6103, -4.3304, -3.2902,  2.0082,  2.8687, -0.4696, -5.2050]])\n",
      "tensor([4])\n",
      "tensor([[-7.4290, -3.4758, -2.3181,  1.9024,  2.0291, -0.7647, -4.3433]])\n",
      "tensor([4])\n",
      "tensor([[-5.0966, -2.2119, -2.0153,  0.2535,  1.1794,  1.8478, -1.4192]])\n",
      "tensor([5])\n",
      "tensor([[-5.5010, -2.6872, -1.6027,  1.6035,  1.3359, -0.7464, -3.3872]])\n",
      "tensor([3])\n",
      "tensor([[-8.6045, -3.8906, -2.9628,  1.6640,  2.4397, -0.0176, -4.4377]])\n",
      "tensor([4])\n",
      "tensor([[-8.8036, -3.9847, -3.0042,  1.8431,  2.5539, -0.3468, -4.7256]])\n",
      "tensor([4])\n",
      "tensor([[-7.1528, -3.2694, -2.6072,  1.1562,  1.8287,  0.6293, -3.2295]])\n",
      "tensor([4])\n",
      "tensor([[-6.5046, -2.9922, -2.0658,  1.4926,  1.8667, -0.3685, -3.5858]])\n",
      "tensor([4])\n",
      "tensor([[-8.6009, -3.8530, -2.9657,  1.6845,  2.5090, -0.1120, -4.4649]])\n",
      "tensor([4])\n",
      "tensor([[-5.1711, -2.4465, -1.5817,  1.2807,  1.3896, -0.3477, -2.8983]])\n",
      "tensor([4])\n",
      "tensor([[-6.7834, -3.1313, -2.1249,  1.6602,  1.9900, -0.6502, -3.9076]])\n",
      "tensor([4])\n",
      "tensor([[-7.2654, -3.3349, -2.3661,  1.6817,  2.0967, -0.5032, -4.0347]])\n",
      "tensor([4])\n",
      "tensor([[-5.9102, -2.9685, -1.8016,  1.5235,  0.7644,  0.0108, -3.1680]])\n",
      "tensor([3])\n",
      "tensor([[-5.6760, -2.6663, -1.7952,  1.3200,  1.4423, -0.1807, -3.0428]])\n",
      "tensor([4])\n",
      "tensor([[-3.8206, -1.6576, -1.3952,  0.3154,  1.0699,  1.0920, -1.1663]])\n",
      "tensor([5])\n",
      "tensor([[-7.8422, -3.5173, -2.6823,  1.5328,  2.3134, -0.0799, -4.0541]])\n",
      "tensor([4])\n",
      "tensor([[-7.2781, -3.2567, -2.4144,  1.5528,  2.2960, -0.4318, -3.9605]])\n",
      "tensor([4])\n",
      "tensor([[-4.7428, -2.1089, -1.8178,  0.4719,  1.1756,  1.1955, -1.5442]])\n",
      "tensor([5])\n",
      "tensor([[-7.4692, -3.2743, -2.9296,  0.7599,  2.0292,  1.4395, -2.8287]])\n",
      "tensor([4])\n",
      "tensor([[-5.7334, -2.4705, -2.2895,  0.3406,  1.5276,  1.7381, -1.7717]])\n",
      "tensor([5])\n",
      "tensor([[-6.1548, -2.7402, -2.2992,  0.7630,  1.6827,  0.9920, -2.4506]])\n",
      "tensor([4])\n",
      "tensor([[-9.4879, -4.3203, -3.3559,  1.8199,  2.5894,  0.0546, -4.8295]])\n",
      "tensor([4])\n",
      "tensor([[-6.7140, -2.9439, -2.7535,  0.3936,  1.5554,  2.1537, -2.0188]])\n",
      "tensor([5])\n",
      "tensor([[-8.6201, -3.8559, -3.1140,  1.5161,  2.4616,  0.2703, -4.1768]])\n",
      "tensor([4])\n",
      "tensor([[-5.1650, -2.4791, -1.4656,  1.4320,  1.3703, -0.6288, -3.1116]])\n",
      "tensor([3])\n",
      "tensor([[-8.1826, -3.6732, -2.8630,  1.5523,  2.3628,  0.0180, -4.1465]])\n",
      "tensor([4])\n",
      "tensor([[-6.4089, -2.9509, -2.1335,  1.2725,  1.7128,  0.1228, -3.2418]])\n",
      "tensor([4])\n",
      "tensor([[-6.6917, -2.9627, -2.7109,  0.4086,  1.3720,  2.2342, -2.0296]])\n",
      "tensor([5])\n",
      "tensor([[-9.1392, -4.0400, -3.5231,  1.2319,  2.5193,  1.0450, -3.9098]])\n",
      "tensor([4])\n",
      "tensor([[-5.9229, -2.8278, -1.6860,  1.6861,  1.6125, -0.8589, -3.6730]])\n",
      "tensor([3])\n",
      "tensor([[-5.1853, -2.3728, -1.7023,  1.0792,  1.5021, -0.0111, -2.6087]])\n",
      "tensor([4])\n",
      "tensor([[-6.1448, -2.8945, -1.8331,  1.6080,  1.6921, -0.6421, -3.6131]])\n",
      "tensor([4])\n",
      "tensor([[-4.6544, -2.0260, -1.8090,  0.3279,  1.1696,  1.4152, -1.4243]])\n",
      "tensor([5])\n",
      "tensor([[-6.1411, -2.8349, -1.9196,  1.3617,  1.6156, -0.0751, -3.2103]])\n",
      "tensor([4])\n",
      "tensor([[-4.8327, -2.0729, -1.9338,  0.2526,  1.3848,  1.4749, -1.4166]])\n",
      "tensor([5])\n",
      "tensor([[-6.8680, -3.2349, -2.5034,  1.1375,  1.3796,  0.9046, -2.9826]])\n",
      "tensor([4])\n",
      "tensor([[-6.2564, -2.9782, -1.9311,  1.6478,  1.5107, -0.4975, -3.5855]])\n",
      "tensor([3])\n",
      "tensor([[-5.6560, -2.4353, -2.1984,  0.4680,  1.6256,  1.3304, -1.9408]])\n",
      "tensor([4])\n",
      "tensor([[-5.7389, -2.6299, -2.2074,  0.4997,  1.0899,  1.7108, -1.9129]])\n",
      "tensor([5])\n",
      "tensor([[-7.7213, -3.4261, -2.7381,  1.3654,  2.2823,  0.1845, -3.7882]])\n",
      "tensor([4])\n",
      "tensor([[-4.3588, -2.2593, -0.9607,  1.4087,  0.6563, -0.5656, -2.8261]])\n",
      "tensor([3])\n",
      "tensor([[-6.5106, -2.9261, -2.4701,  0.8040,  1.6735,  1.0875, -2.5911]])\n",
      "tensor([4])\n",
      "tensor([[-7.1104, -3.1519, -2.5008,  1.2442,  2.1001,  0.2628, -3.4205]])\n",
      "tensor([4])\n",
      "tensor([[-8.3057, -3.7487, -2.8831,  1.6693,  2.3724, -0.1163, -4.2902]])\n",
      "tensor([4])\n",
      "Accuracy on the test set: 50 %\n"
     ]
    }
   ],
   "source": [
    "correct = 0\n",
    "total = 0\n",
    "with torch.no_grad():\n",
    "    net.eval()\n",
    "    for i in range(len(x_test)):\n",
    "        inputs, labels =torch.unsqueeze(x_test[i], 0).to(device).float(), torch.unsqueeze(y_test[i], 0).to(device)\n",
    "        outputs, (hn, cn) = net(inputs)\n",
    "        output = torch.mean(outputs, dim=1)  \n",
    "        #print(inputs)\n",
    "        print(output)\n",
    "        _, predicted = torch.max(output.data, 1)\n",
    "        print(predicted)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "final = 100 * correct / total\n",
    "print('Accuracy on the test set: %d %%' % (final))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
