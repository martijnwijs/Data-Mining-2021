{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np \n",
    "from sklearn.model_selection import train_test_split\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>no</th>\n",
       "      <th>target</th>\n",
       "      <th>t</th>\n",
       "      <th>activity</th>\n",
       "      <th>appCat.builtin</th>\n",
       "      <th>appCat.communication</th>\n",
       "      <th>appCat.entertainment</th>\n",
       "      <th>appCat.finance</th>\n",
       "      <th>appCat.game</th>\n",
       "      <th>...</th>\n",
       "      <th>appCat.travel</th>\n",
       "      <th>appCat.unknown</th>\n",
       "      <th>appCat.utilities</th>\n",
       "      <th>appCat.weather</th>\n",
       "      <th>call</th>\n",
       "      <th>circumplex.arousal</th>\n",
       "      <th>circumplex.valence</th>\n",
       "      <th>mood</th>\n",
       "      <th>screen</th>\n",
       "      <th>sms</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0.641645</td>\n",
       "      <td>1.103108</td>\n",
       "      <td>1.636492</td>\n",
       "      <td>0.244791</td>\n",
       "      <td>1.129913</td>\n",
       "      <td>-0.259976</td>\n",
       "      <td>...</td>\n",
       "      <td>4.689448</td>\n",
       "      <td>-0.322651</td>\n",
       "      <td>7.439909</td>\n",
       "      <td>-0.230130</td>\n",
       "      <td>1.319838</td>\n",
       "      <td>0.485487</td>\n",
       "      <td>-1.266137</td>\n",
       "      <td>-1.209901</td>\n",
       "      <td>2.770542</td>\n",
       "      <td>-0.497599</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>1.074310</td>\n",
       "      <td>-0.242798</td>\n",
       "      <td>1.062958</td>\n",
       "      <td>-0.575133</td>\n",
       "      <td>0.292739</td>\n",
       "      <td>-0.259976</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.207470</td>\n",
       "      <td>-0.322651</td>\n",
       "      <td>1.198651</td>\n",
       "      <td>-0.230130</td>\n",
       "      <td>0.287520</td>\n",
       "      <td>1.143750</td>\n",
       "      <td>-0.496733</td>\n",
       "      <td>-0.899697</td>\n",
       "      <td>0.106958</td>\n",
       "      <td>0.147818</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>0.065088</td>\n",
       "      <td>0.067334</td>\n",
       "      <td>1.182367</td>\n",
       "      <td>-0.574217</td>\n",
       "      <td>0.949321</td>\n",
       "      <td>-0.259976</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.415500</td>\n",
       "      <td>-0.322651</td>\n",
       "      <td>0.063147</td>\n",
       "      <td>2.406086</td>\n",
       "      <td>-0.744797</td>\n",
       "      <td>0.485487</td>\n",
       "      <td>0.272670</td>\n",
       "      <td>-0.279289</td>\n",
       "      <td>0.249101</td>\n",
       "      <td>-0.497599</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>-0.085503</td>\n",
       "      <td>-0.167041</td>\n",
       "      <td>2.937521</td>\n",
       "      <td>0.217447</td>\n",
       "      <td>0.675919</td>\n",
       "      <td>-0.259976</td>\n",
       "      <td>...</td>\n",
       "      <td>1.925529</td>\n",
       "      <td>-0.322651</td>\n",
       "      <td>1.991383</td>\n",
       "      <td>-0.230130</td>\n",
       "      <td>2.696262</td>\n",
       "      <td>1.472881</td>\n",
       "      <td>-1.779072</td>\n",
       "      <td>-1.520105</td>\n",
       "      <td>2.110863</td>\n",
       "      <td>-0.497599</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>1.074310</td>\n",
       "      <td>-0.242798</td>\n",
       "      <td>1.062958</td>\n",
       "      <td>-0.575133</td>\n",
       "      <td>0.292739</td>\n",
       "      <td>-0.259976</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.207470</td>\n",
       "      <td>-0.322651</td>\n",
       "      <td>1.198651</td>\n",
       "      <td>-0.230130</td>\n",
       "      <td>0.287520</td>\n",
       "      <td>1.143750</td>\n",
       "      <td>-0.496733</td>\n",
       "      <td>-0.899697</td>\n",
       "      <td>0.106958</td>\n",
       "      <td>0.147818</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4191</th>\n",
       "      <td>4191</td>\n",
       "      <td>1048</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>0.272023</td>\n",
       "      <td>0.774332</td>\n",
       "      <td>-0.254069</td>\n",
       "      <td>-0.107484</td>\n",
       "      <td>-0.327054</td>\n",
       "      <td>-0.259976</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.415500</td>\n",
       "      <td>-0.322651</td>\n",
       "      <td>0.070671</td>\n",
       "      <td>-0.230130</td>\n",
       "      <td>2.696262</td>\n",
       "      <td>0.156356</td>\n",
       "      <td>1.298542</td>\n",
       "      <td>1.892137</td>\n",
       "      <td>1.947385</td>\n",
       "      <td>0.147818</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4192</th>\n",
       "      <td>4192</td>\n",
       "      <td>1049</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.328753</td>\n",
       "      <td>-0.065428</td>\n",
       "      <td>-0.559067</td>\n",
       "      <td>-0.041053</td>\n",
       "      <td>-0.327054</td>\n",
       "      <td>-0.259976</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.415500</td>\n",
       "      <td>-0.322651</td>\n",
       "      <td>-0.327129</td>\n",
       "      <td>-0.230130</td>\n",
       "      <td>2.696262</td>\n",
       "      <td>-0.501907</td>\n",
       "      <td>-1.779072</td>\n",
       "      <td>-2.450716</td>\n",
       "      <td>2.983480</td>\n",
       "      <td>1.438652</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4193</th>\n",
       "      <td>4193</td>\n",
       "      <td>1049</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>-1.058736</td>\n",
       "      <td>-0.245614</td>\n",
       "      <td>-0.192281</td>\n",
       "      <td>-0.546996</td>\n",
       "      <td>-0.327054</td>\n",
       "      <td>-0.259976</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.415500</td>\n",
       "      <td>-0.322651</td>\n",
       "      <td>0.401548</td>\n",
       "      <td>-0.230130</td>\n",
       "      <td>-0.400691</td>\n",
       "      <td>-0.831038</td>\n",
       "      <td>-0.753201</td>\n",
       "      <td>-1.209901</td>\n",
       "      <td>-0.354860</td>\n",
       "      <td>0.793235</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4194</th>\n",
       "      <td>4194</td>\n",
       "      <td>1049</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>0.272023</td>\n",
       "      <td>0.774332</td>\n",
       "      <td>-0.254069</td>\n",
       "      <td>-0.107484</td>\n",
       "      <td>-0.327054</td>\n",
       "      <td>-0.259976</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.415500</td>\n",
       "      <td>-0.322651</td>\n",
       "      <td>0.070671</td>\n",
       "      <td>-0.230130</td>\n",
       "      <td>2.696262</td>\n",
       "      <td>0.156356</td>\n",
       "      <td>1.298542</td>\n",
       "      <td>1.892137</td>\n",
       "      <td>1.947385</td>\n",
       "      <td>0.147818</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4195</th>\n",
       "      <td>4195</td>\n",
       "      <td>1049</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>1.242266</td>\n",
       "      <td>-0.428041</td>\n",
       "      <td>-0.907386</td>\n",
       "      <td>-0.536193</td>\n",
       "      <td>-0.327054</td>\n",
       "      <td>-0.259976</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.410263</td>\n",
       "      <td>-0.322651</td>\n",
       "      <td>-0.285631</td>\n",
       "      <td>-0.230130</td>\n",
       "      <td>0.975732</td>\n",
       "      <td>-2.037854</td>\n",
       "      <td>0.785606</td>\n",
       "      <td>0.030914</td>\n",
       "      <td>-0.471995</td>\n",
       "      <td>0.147818</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4196 rows × 23 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Unnamed: 0    no  target  t  activity  appCat.builtin  \\\n",
       "0              0     1       5  0  0.641645        1.103108   \n",
       "1              1     1       5  1  1.074310       -0.242798   \n",
       "2              2     1       5  2  0.065088        0.067334   \n",
       "3              3     1       5  3 -0.085503       -0.167041   \n",
       "4              4     2       5  0  1.074310       -0.242798   \n",
       "...          ...   ...     ... ..       ...             ...   \n",
       "4191        4191  1048       5  3  0.272023        0.774332   \n",
       "4192        4192  1049       5  0 -0.328753       -0.065428   \n",
       "4193        4193  1049       5  1 -1.058736       -0.245614   \n",
       "4194        4194  1049       5  2  0.272023        0.774332   \n",
       "4195        4195  1049       5  3  1.242266       -0.428041   \n",
       "\n",
       "      appCat.communication  appCat.entertainment  appCat.finance  appCat.game  \\\n",
       "0                 1.636492              0.244791        1.129913    -0.259976   \n",
       "1                 1.062958             -0.575133        0.292739    -0.259976   \n",
       "2                 1.182367             -0.574217        0.949321    -0.259976   \n",
       "3                 2.937521              0.217447        0.675919    -0.259976   \n",
       "4                 1.062958             -0.575133        0.292739    -0.259976   \n",
       "...                    ...                   ...             ...          ...   \n",
       "4191             -0.254069             -0.107484       -0.327054    -0.259976   \n",
       "4192             -0.559067             -0.041053       -0.327054    -0.259976   \n",
       "4193             -0.192281             -0.546996       -0.327054    -0.259976   \n",
       "4194             -0.254069             -0.107484       -0.327054    -0.259976   \n",
       "4195             -0.907386             -0.536193       -0.327054    -0.259976   \n",
       "\n",
       "      ...  appCat.travel  appCat.unknown  appCat.utilities  appCat.weather  \\\n",
       "0     ...       4.689448       -0.322651          7.439909       -0.230130   \n",
       "1     ...      -0.207470       -0.322651          1.198651       -0.230130   \n",
       "2     ...      -0.415500       -0.322651          0.063147        2.406086   \n",
       "3     ...       1.925529       -0.322651          1.991383       -0.230130   \n",
       "4     ...      -0.207470       -0.322651          1.198651       -0.230130   \n",
       "...   ...            ...             ...               ...             ...   \n",
       "4191  ...      -0.415500       -0.322651          0.070671       -0.230130   \n",
       "4192  ...      -0.415500       -0.322651         -0.327129       -0.230130   \n",
       "4193  ...      -0.415500       -0.322651          0.401548       -0.230130   \n",
       "4194  ...      -0.415500       -0.322651          0.070671       -0.230130   \n",
       "4195  ...      -0.410263       -0.322651         -0.285631       -0.230130   \n",
       "\n",
       "          call  circumplex.arousal  circumplex.valence      mood    screen  \\\n",
       "0     1.319838            0.485487           -1.266137 -1.209901  2.770542   \n",
       "1     0.287520            1.143750           -0.496733 -0.899697  0.106958   \n",
       "2    -0.744797            0.485487            0.272670 -0.279289  0.249101   \n",
       "3     2.696262            1.472881           -1.779072 -1.520105  2.110863   \n",
       "4     0.287520            1.143750           -0.496733 -0.899697  0.106958   \n",
       "...        ...                 ...                 ...       ...       ...   \n",
       "4191  2.696262            0.156356            1.298542  1.892137  1.947385   \n",
       "4192  2.696262           -0.501907           -1.779072 -2.450716  2.983480   \n",
       "4193 -0.400691           -0.831038           -0.753201 -1.209901 -0.354860   \n",
       "4194  2.696262            0.156356            1.298542  1.892137  1.947385   \n",
       "4195  0.975732           -2.037854            0.785606  0.030914 -0.471995   \n",
       "\n",
       "           sms  \n",
       "0    -0.497599  \n",
       "1     0.147818  \n",
       "2    -0.497599  \n",
       "3    -0.497599  \n",
       "4     0.147818  \n",
       "...        ...  \n",
       "4191  0.147818  \n",
       "4192  1.438652  \n",
       "4193  0.793235  \n",
       "4194  0.147818  \n",
       "4195  0.147818  \n",
       "\n",
       "[4196 rows x 23 columns]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load dataset\n",
    "#dataset = \"dataframe_normalized_outliers_removed.csv\" \n",
    "dataset = \"dataframe_standardized_outliers_removed_classes.csv\"\n",
    "#dataset = \"dataframe_new.csv\"  ## debug\n",
    "df = pd.read_csv(dataset) # dataframe in pandas\n",
    "\n",
    "\n",
    "df = df[df['target'] != 7] # debug check if it learns to predict not only 7\n",
    "#df['target'] = df['target'].sub(2)# change to 7 classes\n",
    "#df = df[df['target'] != 7]\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>no</th>\n",
       "      <th>target</th>\n",
       "      <th>t</th>\n",
       "      <th>activity</th>\n",
       "      <th>appCat.builtin</th>\n",
       "      <th>appCat.communication</th>\n",
       "      <th>appCat.entertainment</th>\n",
       "      <th>appCat.finance</th>\n",
       "      <th>appCat.game</th>\n",
       "      <th>...</th>\n",
       "      <th>appCat.travel</th>\n",
       "      <th>appCat.unknown</th>\n",
       "      <th>appCat.utilities</th>\n",
       "      <th>appCat.weather</th>\n",
       "      <th>call</th>\n",
       "      <th>circumplex.arousal</th>\n",
       "      <th>circumplex.valence</th>\n",
       "      <th>mood</th>\n",
       "      <th>screen</th>\n",
       "      <th>sms</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>924</th>\n",
       "      <td>924</td>\n",
       "      <td>232</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0.311020</td>\n",
       "      <td>0.439437</td>\n",
       "      <td>1.433216</td>\n",
       "      <td>-0.658839</td>\n",
       "      <td>-0.327054</td>\n",
       "      <td>-0.259976</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.230060</td>\n",
       "      <td>0.026141</td>\n",
       "      <td>-0.327129</td>\n",
       "      <td>-0.23013</td>\n",
       "      <td>-0.056586</td>\n",
       "      <td>-1.900715</td>\n",
       "      <td>-1.779072</td>\n",
       "      <td>-3.458879</td>\n",
       "      <td>0.750804</td>\n",
       "      <td>4.665737</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>925</th>\n",
       "      <td>925</td>\n",
       "      <td>232</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0.489266</td>\n",
       "      <td>0.042690</td>\n",
       "      <td>0.607178</td>\n",
       "      <td>0.817177</td>\n",
       "      <td>-0.327054</td>\n",
       "      <td>-0.259976</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.415500</td>\n",
       "      <td>-0.322651</td>\n",
       "      <td>-0.327129</td>\n",
       "      <td>-0.23013</td>\n",
       "      <td>-0.400691</td>\n",
       "      <td>-1.818433</td>\n",
       "      <td>-2.804944</td>\n",
       "      <td>0.030914</td>\n",
       "      <td>0.482135</td>\n",
       "      <td>-0.497599</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>926</th>\n",
       "      <td>926</td>\n",
       "      <td>232</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>-0.551005</td>\n",
       "      <td>-0.144878</td>\n",
       "      <td>0.450725</td>\n",
       "      <td>0.246428</td>\n",
       "      <td>-0.327054</td>\n",
       "      <td>-0.259976</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.415500</td>\n",
       "      <td>-0.322651</td>\n",
       "      <td>-0.327129</td>\n",
       "      <td>-0.23013</td>\n",
       "      <td>-0.400691</td>\n",
       "      <td>-1.489301</td>\n",
       "      <td>-2.804944</td>\n",
       "      <td>-2.760920</td>\n",
       "      <td>0.202455</td>\n",
       "      <td>0.793235</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>927</th>\n",
       "      <td>927</td>\n",
       "      <td>232</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>-1.199436</td>\n",
       "      <td>-0.529230</td>\n",
       "      <td>-0.624870</td>\n",
       "      <td>-0.534593</td>\n",
       "      <td>-0.327054</td>\n",
       "      <td>-0.259976</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.415500</td>\n",
       "      <td>-0.322651</td>\n",
       "      <td>-0.327129</td>\n",
       "      <td>-0.23013</td>\n",
       "      <td>-0.744797</td>\n",
       "      <td>0.567770</td>\n",
       "      <td>0.144437</td>\n",
       "      <td>0.030914</td>\n",
       "      <td>-0.813664</td>\n",
       "      <td>-0.497599</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>944</th>\n",
       "      <td>944</td>\n",
       "      <td>237</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.337792</td>\n",
       "      <td>-0.057635</td>\n",
       "      <td>1.302856</td>\n",
       "      <td>1.564893</td>\n",
       "      <td>-0.327054</td>\n",
       "      <td>-0.259976</td>\n",
       "      <td>...</td>\n",
       "      <td>3.683158</td>\n",
       "      <td>0.900727</td>\n",
       "      <td>-0.327129</td>\n",
       "      <td>-0.23013</td>\n",
       "      <td>-0.744797</td>\n",
       "      <td>-0.501907</td>\n",
       "      <td>0.272670</td>\n",
       "      <td>-0.589493</td>\n",
       "      <td>0.799253</td>\n",
       "      <td>-0.497599</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>945</th>\n",
       "      <td>945</td>\n",
       "      <td>237</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0.091190</td>\n",
       "      <td>-0.062785</td>\n",
       "      <td>0.091268</td>\n",
       "      <td>0.821783</td>\n",
       "      <td>-0.327054</td>\n",
       "      <td>-0.259976</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.415500</td>\n",
       "      <td>-0.322651</td>\n",
       "      <td>-0.327129</td>\n",
       "      <td>-0.23013</td>\n",
       "      <td>-0.744797</td>\n",
       "      <td>-0.172776</td>\n",
       "      <td>-0.753201</td>\n",
       "      <td>-1.520105</td>\n",
       "      <td>0.009429</td>\n",
       "      <td>0.793235</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>946</th>\n",
       "      <td>946</td>\n",
       "      <td>237</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>-0.138200</td>\n",
       "      <td>0.162041</td>\n",
       "      <td>2.291177</td>\n",
       "      <td>-0.215947</td>\n",
       "      <td>-0.327054</td>\n",
       "      <td>-0.259976</td>\n",
       "      <td>...</td>\n",
       "      <td>0.037934</td>\n",
       "      <td>6.193170</td>\n",
       "      <td>-0.327129</td>\n",
       "      <td>-0.23013</td>\n",
       "      <td>0.975732</td>\n",
       "      <td>-0.940749</td>\n",
       "      <td>-1.779072</td>\n",
       "      <td>-1.520105</td>\n",
       "      <td>1.376216</td>\n",
       "      <td>-0.497599</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>947</th>\n",
       "      <td>947</td>\n",
       "      <td>237</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>1.075279</td>\n",
       "      <td>-0.401963</td>\n",
       "      <td>0.451940</td>\n",
       "      <td>-0.658839</td>\n",
       "      <td>-0.327054</td>\n",
       "      <td>-0.259976</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.415500</td>\n",
       "      <td>-0.322651</td>\n",
       "      <td>-0.314118</td>\n",
       "      <td>-0.23013</td>\n",
       "      <td>0.287520</td>\n",
       "      <td>-0.831038</td>\n",
       "      <td>-0.753201</td>\n",
       "      <td>-2.140512</td>\n",
       "      <td>-0.561040</td>\n",
       "      <td>0.147818</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 23 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Unnamed: 0   no  target  t  activity  appCat.builtin  \\\n",
       "924         924  232       3  0  0.311020        0.439437   \n",
       "925         925  232       3  1  0.489266        0.042690   \n",
       "926         926  232       3  2 -0.551005       -0.144878   \n",
       "927         927  232       3  3 -1.199436       -0.529230   \n",
       "944         944  237       3  0 -0.337792       -0.057635   \n",
       "945         945  237       3  1  0.091190       -0.062785   \n",
       "946         946  237       3  2 -0.138200        0.162041   \n",
       "947         947  237       3  3  1.075279       -0.401963   \n",
       "\n",
       "     appCat.communication  appCat.entertainment  appCat.finance  appCat.game  \\\n",
       "924              1.433216             -0.658839       -0.327054    -0.259976   \n",
       "925              0.607178              0.817177       -0.327054    -0.259976   \n",
       "926              0.450725              0.246428       -0.327054    -0.259976   \n",
       "927             -0.624870             -0.534593       -0.327054    -0.259976   \n",
       "944              1.302856              1.564893       -0.327054    -0.259976   \n",
       "945              0.091268              0.821783       -0.327054    -0.259976   \n",
       "946              2.291177             -0.215947       -0.327054    -0.259976   \n",
       "947              0.451940             -0.658839       -0.327054    -0.259976   \n",
       "\n",
       "     ...  appCat.travel  appCat.unknown  appCat.utilities  appCat.weather  \\\n",
       "924  ...      -0.230060        0.026141         -0.327129        -0.23013   \n",
       "925  ...      -0.415500       -0.322651         -0.327129        -0.23013   \n",
       "926  ...      -0.415500       -0.322651         -0.327129        -0.23013   \n",
       "927  ...      -0.415500       -0.322651         -0.327129        -0.23013   \n",
       "944  ...       3.683158        0.900727         -0.327129        -0.23013   \n",
       "945  ...      -0.415500       -0.322651         -0.327129        -0.23013   \n",
       "946  ...       0.037934        6.193170         -0.327129        -0.23013   \n",
       "947  ...      -0.415500       -0.322651         -0.314118        -0.23013   \n",
       "\n",
       "         call  circumplex.arousal  circumplex.valence      mood    screen  \\\n",
       "924 -0.056586           -1.900715           -1.779072 -3.458879  0.750804   \n",
       "925 -0.400691           -1.818433           -2.804944  0.030914  0.482135   \n",
       "926 -0.400691           -1.489301           -2.804944 -2.760920  0.202455   \n",
       "927 -0.744797            0.567770            0.144437  0.030914 -0.813664   \n",
       "944 -0.744797           -0.501907            0.272670 -0.589493  0.799253   \n",
       "945 -0.744797           -0.172776           -0.753201 -1.520105  0.009429   \n",
       "946  0.975732           -0.940749           -1.779072 -1.520105  1.376216   \n",
       "947  0.287520           -0.831038           -0.753201 -2.140512 -0.561040   \n",
       "\n",
       "          sms  \n",
       "924  4.665737  \n",
       "925 -0.497599  \n",
       "926  0.793235  \n",
       "927 -0.497599  \n",
       "944 -0.497599  \n",
       "945  0.793235  \n",
       "946 -0.497599  \n",
       "947  0.147818  \n",
       "\n",
       "[8 rows x 23 columns]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[df['target'] == 3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Empty DataFrame\n",
      "Columns: [Unnamed: 0, no, target, t, activity, appCat.builtin, appCat.communication, appCat.entertainment, appCat.finance, appCat.game, appCat.office, appCat.other, appCat.social, appCat.travel, appCat.unknown, appCat.utilities, appCat.weather, call, circumplex.arousal, circumplex.valence, mood, screen, sms]\n",
      "Index: []\n",
      "\n",
      "[0 rows x 23 columns]\n",
      "Empty DataFrame\n",
      "Columns: [Unnamed: 0, no, target, t, activity, appCat.builtin, appCat.communication, appCat.entertainment, appCat.finance, appCat.game, appCat.office, appCat.other, appCat.social, appCat.travel, appCat.unknown, appCat.utilities, appCat.weather, call, circumplex.arousal, circumplex.valence, mood, screen, sms]\n",
      "Index: []\n",
      "\n",
      "[0 rows x 23 columns]\n"
     ]
    }
   ],
   "source": [
    "print(df[df['no'] == 723])\n",
    "for i in range(710, 730):  ### debug\n",
    "    df = df[df['no'] != i]\n",
    "print(df[df['no'] == 723])\n",
    "df = df.sample(frac=1) # shuffle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([8, 6, 6, 6, 8, 6, 6, 8, 8, 8, 6, 8, 6, 8, 9, 5, 8, 8, 5, 6, 8, 6,\n",
       "       6, 6, 6, 8, 6, 6, 6, 8, 6, 6, 3, 8, 8, 8, 6, 6, 6, 8, 8, 6, 8, 6,\n",
       "       6, 6, 6, 6, 8, 6, 8, 6, 8, 8, 6, 8, 4, 8, 8, 8, 6, 6, 6, 8, 6, 6,\n",
       "       8, 6, 6, 8, 8, 8, 6, 6, 6, 6, 8, 6, 4, 6, 6, 8, 8, 6, 8, 8, 6, 8,\n",
       "       8, 8, 8, 6, 6, 6, 6, 8, 6, 6, 6, 6, 8, 8, 6, 6, 6, 6, 6, 6, 8, 6,\n",
       "       8, 6, 6, 8, 8, 6, 8, 6, 6, 6, 5, 6, 6, 8, 6, 8, 8, 6, 6, 6, 5, 6,\n",
       "       8, 8, 8, 8, 8, 6, 6, 8, 6, 8, 6, 5, 8, 6, 6, 6, 8, 8, 6, 8, 8, 6,\n",
       "       4, 8, 6, 6, 6, 6, 5, 6, 8, 6, 8, 8, 8, 6, 6, 6, 8, 6, 8, 6, 8, 6,\n",
       "       8, 6, 6, 8, 5, 8, 6, 8, 6, 8, 6, 6, 5, 8, 8, 6, 8, 6, 6, 6, 8, 8,\n",
       "       6, 6, 8, 8, 6, 5, 5, 8, 8, 6, 6, 6, 6, 6, 6, 8, 6, 6, 8, 8, 8, 6,\n",
       "       6, 8, 6, 6, 6, 6, 8, 8, 8, 8, 5, 8, 6, 8, 8, 8, 6, 6, 8, 8, 8, 8,\n",
       "       6, 6, 6, 8, 8, 8, 6, 8, 8, 6, 8, 8, 6, 8, 6, 8, 6, 8, 8, 6, 8, 6,\n",
       "       8, 6, 6, 6, 4, 6, 9, 8, 8, 8, 8, 8, 5, 8, 8, 6, 8, 6, 8, 6, 8, 8,\n",
       "       8, 8, 6, 8, 8, 8, 6, 6, 8, 8, 8, 6, 8, 8, 8, 8, 6, 8, 6, 8, 6, 6,\n",
       "       6, 6, 8, 6, 8, 8, 8, 8, 6, 8, 8, 6, 6, 6, 6, 6, 6, 8, 8, 4, 6, 6,\n",
       "       6, 8, 6, 6, 5, 8, 6, 6, 6, 6, 5, 8, 8, 8, 8, 8, 6, 8, 6, 6, 8, 8,\n",
       "       6, 8, 6, 8, 8, 6, 6, 8, 8, 8, 6, 8, 6, 8, 8, 8, 6, 8, 6, 6, 8, 6,\n",
       "       6, 8, 6, 8, 8, 6, 8, 8, 6, 8, 8, 6, 8, 6, 6, 6, 6, 8, 6, 6, 9, 8,\n",
       "       8, 8, 8, 6, 6, 8, 4, 5, 8, 6, 6, 8, 6, 8, 6, 8, 8, 8, 5, 8, 8, 6,\n",
       "       8, 6, 8, 9, 6, 8, 8, 8, 6, 8, 6, 6, 6, 8, 4, 8, 6, 6, 6, 8, 6, 5,\n",
       "       6, 8, 8, 6, 8, 6, 8, 8, 8, 8, 8, 8, 6, 6, 6, 6, 4, 8, 6, 6, 8, 8,\n",
       "       8, 8, 6, 6, 6, 8, 6, 6, 8, 8, 6, 6, 6, 8, 6, 9, 8, 6, 6, 6, 8, 8,\n",
       "       6, 6, 8, 8, 8, 8, 6, 6, 6, 8, 9, 6, 6, 8, 8, 6, 8, 8, 6, 6, 8, 6,\n",
       "       8, 6, 6, 8, 8], dtype=int64)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get labels\n",
    "Y = df['target'].to_numpy()\n",
    "Y = Y[::4]\n",
    "Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get input \n",
    "X = df.iloc[:, 3:].to_numpy()\n",
    "X = X[:, 1:]\n",
    "split = len(X[:, 0]) / 4\n",
    "X = np.array_split(X, split)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split train and test set\n",
    "x_train, x_test, y_train, y_test = train_test_split(X, Y, test_size=0.2, random_state=123, shuffle=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 16\n",
    "def batch_generator(X, Y, batch_size):\n",
    "    batchesx = []\n",
    "    batchesy = []\n",
    "    batchx = [] # batches\n",
    "    batchy = []\n",
    "    for i in range(len(X)):\n",
    "        batchx.append(X[i]) # add to batch\n",
    "        batchy.append(Y[i])\n",
    "        #print(batchy)\n",
    "        if i % batch_size == 0: # batch full?\n",
    "            batchesx.append([batchx])\n",
    "            batchesy.append([batchy])\n",
    "            batchx = [] # batches\n",
    "            batchy = []\n",
    "    print(batchesy)\n",
    "    return batchesx, batchesy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# to torch tensor\n",
    "x_train = torch.tensor(x_train)\n",
    "#x_train = x_train[:724]#### debug\n",
    "#for i in range(710, 730):  ### debug\n",
    "    #np.delete(x_train, i)\n",
    "    #np.delete(y_train, i)\n",
    "#x_train = x_train[4:] ## debug\n",
    "y_train = torch.tensor(y_train).to(torch.int64)\n",
    "#print(x_train[724])\n",
    "#print(y_train[724])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test = torch.tensor(x_test)\n",
    "y_test = torch.tensor(y_test).to(torch.int64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(x_train[728])\n",
    "#print(y_train[728])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cpu\n"
     ]
    }
   ],
   "source": [
    "# training on GPU\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class lstm(nn.Module):\n",
    "    def __init__ (self, input_size, hidden_size, num_layers, seq_length, output_size):\n",
    "        super(). __init__()\n",
    "        self.input_size = input_size\n",
    "        self.hidden_size = hidden_size\n",
    "        self.num_layers = num_layers\n",
    "        self.seq_length = seq_length\n",
    "        self.output_size = output_size\n",
    "        \n",
    "        self.ltsm = torch.nn.LSTM(self.input_size, self.hidden_size, batch_first=True) \n",
    "        #self.dropout = torch.nn.Dropout(0.3)\n",
    "        self.lin1 = nn.Linear(self.hidden_size, self.output_size) # 1 for regression, 10 for classification\n",
    "    def forward(self, x):\n",
    "        x, (hn, cn) = self.ltsm(x)\n",
    "        #x  = self.dropout(x)\n",
    "        x = F.relu(x) # is this ok?\n",
    "        x = self.lin1(x)  \n",
    "        return x, (hn, cn)\n",
    "net = lstm(input_size=19, hidden_size=70, num_layers=1, seq_length=4, output_size=10).float()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "\n",
    "learning_rate = 0.00005\n",
    "#criterion =  nn.MSELoss()    # MSE for regression\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(net.parameters(), lr=learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "target = torch.randint(0, 10, (10,))\n",
    "one_hot = torch.nn.functional.one_hot(target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1,   100] loss: 2.326\n",
      "[1,   200] loss: 2.307\n",
      "[1,   300] loss: 2.273\n",
      "[1,   400] loss: 2.254\n",
      "[2,   100] loss: 2.235\n",
      "[2,   200] loss: 2.210\n",
      "[2,   300] loss: 2.172\n",
      "[2,   400] loss: 2.136\n",
      "[3,   100] loss: 2.106\n",
      "[3,   200] loss: 2.058\n",
      "[3,   300] loss: 2.005\n",
      "[3,   400] loss: 1.920\n",
      "[4,   100] loss: 1.855\n",
      "[4,   200] loss: 1.745\n",
      "[4,   300] loss: 1.646\n",
      "[4,   400] loss: 1.474\n",
      "[5,   100] loss: 1.396\n",
      "[5,   200] loss: 1.290\n",
      "[5,   300] loss: 1.217\n",
      "[5,   400] loss: 1.098\n",
      "[6,   100] loss: 1.111\n",
      "[6,   200] loss: 1.079\n",
      "[6,   300] loss: 1.046\n",
      "[6,   400] loss: 0.970\n",
      "[7,   100] loss: 1.017\n",
      "[7,   200] loss: 1.009\n",
      "[7,   300] loss: 0.988\n",
      "[7,   400] loss: 0.923\n",
      "[8,   100] loss: 0.980\n",
      "[8,   200] loss: 0.978\n",
      "[8,   300] loss: 0.964\n",
      "[8,   400] loss: 0.900\n",
      "[9,   100] loss: 0.961\n",
      "[9,   200] loss: 0.961\n",
      "[9,   300] loss: 0.950\n",
      "[9,   400] loss: 0.887\n",
      "[10,   100] loss: 0.949\n",
      "[10,   200] loss: 0.950\n",
      "[10,   300] loss: 0.942\n",
      "[10,   400] loss: 0.878\n",
      "[11,   100] loss: 0.941\n",
      "[11,   200] loss: 0.941\n",
      "[11,   300] loss: 0.935\n",
      "[11,   400] loss: 0.870\n",
      "[12,   100] loss: 0.935\n",
      "[12,   200] loss: 0.934\n",
      "[12,   300] loss: 0.930\n",
      "[12,   400] loss: 0.865\n",
      "[13,   100] loss: 0.929\n",
      "[13,   200] loss: 0.927\n",
      "[13,   300] loss: 0.925\n",
      "[13,   400] loss: 0.859\n",
      "[14,   100] loss: 0.924\n",
      "[14,   200] loss: 0.921\n",
      "[14,   300] loss: 0.921\n",
      "[14,   400] loss: 0.855\n",
      "[15,   100] loss: 0.919\n",
      "[15,   200] loss: 0.914\n",
      "[15,   300] loss: 0.917\n",
      "[15,   400] loss: 0.850\n",
      "[16,   100] loss: 0.914\n",
      "[16,   200] loss: 0.908\n",
      "[16,   300] loss: 0.914\n",
      "[16,   400] loss: 0.846\n",
      "[17,   100] loss: 0.909\n",
      "[17,   200] loss: 0.902\n",
      "[17,   300] loss: 0.910\n",
      "[17,   400] loss: 0.842\n",
      "[18,   100] loss: 0.904\n",
      "[18,   200] loss: 0.896\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-15-7e6711bfcaa7>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     24\u001b[0m         \u001b[1;31m#print(labels[0])\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     25\u001b[0m         \u001b[0mloss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 26\u001b[1;33m         \u001b[0mloss\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     27\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     28\u001b[0m         \u001b[1;31m#print(i, loss.item())\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\torch\\tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[1;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[0;32m    243\u001b[0m                 \u001b[0mcreate_graph\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcreate_graph\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    244\u001b[0m                 inputs=inputs)\n\u001b[1;32m--> 245\u001b[1;33m         \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    246\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    247\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\torch\\autograd\\__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[1;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[0;32m    143\u001b[0m         \u001b[0mretain_graph\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    144\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 145\u001b[1;33m     Variable._execution_engine.run_backward(\n\u001b[0m\u001b[0;32m    146\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgrad_tensors_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    147\u001b[0m         allow_unreachable=True, accumulate_grad=True)  # allow_unreachable flag\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# train the network\n",
    "\n",
    "n = 10 # for one hot\n",
    "\n",
    "for epoch in range(100):\n",
    "    running_loss = 0.0\n",
    "    net.train()\n",
    "    for i in range(len(x_train)):\n",
    "        \n",
    "        # get the inputs\n",
    "        #print(torch.unsqueeze(x_train[i], 0))\n",
    "        inputs, labels =torch.unsqueeze(x_train[i], 0).to(device).float(), torch.unsqueeze(y_train[i], 0).to(device)\n",
    "        labels_onehot = torch.nn.functional.one_hot(labels[0].to(torch.int64), n)\n",
    "        # zero the parameter gradients\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # forward + backward + optimize\n",
    "        outputs, (hn, cn) = net(inputs)\n",
    "        #print(outputs)\n",
    "        output = torch.mean(outputs, dim=1) # takes the average over the outputs \n",
    "        #output = outputs[3] # takes the last, (does that makes more sense)\n",
    "        \n",
    "        #print(output[0])\n",
    "        #print(labels[0])\n",
    "        loss = criterion(output, labels)\n",
    "        loss.backward() \n",
    "        optimizer.step()\n",
    "        #print(i, loss.item())\n",
    "        # running loss\n",
    "        running_loss += loss.item()\n",
    "        #print(i, loss.item())\n",
    "        # statistics tensorboard\n",
    "        if i % 100 == 99:    # every 30 mini-batches\n",
    "\n",
    "            # print\n",
    "            print('[%d, %5d] loss: %.3f' %\n",
    "                  (epoch + 1, i + 1, running_loss / 100))\n",
    "            \n",
    "            '''\n",
    "            # ...log the running loss\n",
    "            writer.add_scalar('training loss',\n",
    "                            running_loss / 30,\n",
    "                            epoch * len(x_train) + i)\n",
    "            '''\n",
    "            running_loss = 0.0\n",
    "'''\n",
    "    # run on validation set\n",
    "    net.eval()\n",
    "    for j, data in enumerate(x_val, 0):\n",
    "        inputs, labels = x_val[j].to(device), y_val[j].to(device)\n",
    "        \n",
    "        # calculate outputs and loss\n",
    "        outputs, (hn, cn) = net(inputs)\n",
    "        output = torch.mean(outputs, dim=1)  \n",
    "        loss = criterion(output, labels)\n",
    "        \n",
    "        # running loss\n",
    "        running_loss += loss.item()\n",
    "        \n",
    "    # add to tensorboard\n",
    "    writer.add_scalar('validation_loss',\n",
    "                            running_loss / j,\n",
    "                            epoch)\n",
    "    print(\"validation loss:\", running_loss / j, j)\n",
    "'''\n",
    "print('Finished Training')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-4.5887, -4.6609, -4.7949, -2.7222, -1.7126, -0.8135,  2.0492, -4.8686,\n",
      "          1.9052, -2.3245]])\n",
      "tensor([6])\n",
      "tensor([[-3.9862, -3.9921, -4.1451, -2.4158, -1.4284, -0.8091,  1.5244, -4.2962,\n",
      "          1.9104, -1.9902]])\n",
      "tensor([8])\n",
      "tensor([[-4.1295, -4.2198, -4.3531, -2.5389, -1.5962, -0.6954,  1.9850, -4.3688,\n",
      "          1.6277, -2.1371]])\n",
      "tensor([6])\n",
      "tensor([[-3.7012, -3.8068, -3.9109, -2.3046, -1.4450, -0.6629,  1.8351, -3.8765,\n",
      "          1.4295, -1.9301]])\n",
      "tensor([6])\n",
      "tensor([[-4.4677, -4.4533, -4.7282, -2.7211, -1.6764, -0.7677,  1.9566, -4.8234,\n",
      "          1.9390, -2.2794]])\n",
      "tensor([6])\n",
      "tensor([[-3.8840, -4.0075, -4.1542, -2.4205, -1.5358, -0.6683,  1.9553, -4.0937,\n",
      "          1.5056, -2.0138]])\n",
      "tensor([6])\n",
      "tensor([[-4.5925, -4.5633, -4.8151, -2.6837, -1.7284, -0.8006,  2.0157, -4.9066,\n",
      "          1.9362, -2.2666]])\n",
      "tensor([6])\n",
      "tensor([[-4.4226, -4.5823, -4.6590, -2.7031, -1.6594, -0.8527,  1.9317, -4.7247,\n",
      "          1.9424, -2.2341]])\n",
      "tensor([8])\n",
      "tensor([[-3.8917, -3.9206, -4.1239, -2.2549, -1.4126, -0.6952,  1.5658, -4.2341,\n",
      "          1.8327, -1.9353]])\n",
      "tensor([8])\n",
      "tensor([[-4.3308, -4.3293, -4.6009, -2.5382, -1.5834, -0.8134,  1.6254, -4.7596,\n",
      "          2.1311, -2.1231]])\n",
      "tensor([8])\n",
      "tensor([[-4.7788, -4.7449, -5.0274, -2.7998, -1.7072, -0.9304,  1.7009, -5.2153,\n",
      "          2.3756, -2.3128]])\n",
      "tensor([8])\n",
      "tensor([[-4.0811, -4.1670, -4.3071, -2.4911, -1.5148, -0.7508,  1.7927, -4.4136,\n",
      "          1.7879, -2.1025]])\n",
      "tensor([6])\n",
      "tensor([[-4.5487, -4.5878, -4.7658, -2.7006, -1.6623, -0.8603,  1.8686, -4.9167,\n",
      "          2.0850, -2.1983]])\n",
      "tensor([8])\n",
      "tensor([[-3.9292, -3.9691, -4.0631, -2.4372, -1.4792, -0.7344,  1.7256, -4.2070,\n",
      "          1.7163, -2.0158]])\n",
      "tensor([6])\n",
      "tensor([[-4.2948, -4.3608, -4.5364, -2.6184, -1.6718, -0.7041,  2.1669, -4.5266,\n",
      "          1.5982, -2.2140]])\n",
      "tensor([6])\n",
      "tensor([[-4.9235, -5.0480, -5.1910, -3.0039, -1.8181, -0.9251,  1.9780, -5.2975,\n",
      "          2.2155, -2.4738]])\n",
      "tensor([8])\n",
      "tensor([[-5.2375, -5.0880, -5.4727, -2.9193, -1.9221, -0.8893,  2.0492, -5.5586,\n",
      "          2.3131, -2.4691]])\n",
      "tensor([8])\n",
      "tensor([[-5.1447, -5.1114, -5.4526, -2.9517, -1.8952, -0.9103,  1.9649, -5.6105,\n",
      "          2.4558, -2.5368]])\n",
      "tensor([8])\n",
      "tensor([[-4.7057, -4.7191, -4.9286, -2.7850, -1.8386, -0.7460,  2.1835, -5.0014,\n",
      "          1.8793, -2.3521]])\n",
      "tensor([6])\n",
      "tensor([[-4.1599, -4.2809, -4.4357, -2.5444, -1.6193, -0.7491,  1.9912, -4.4007,\n",
      "          1.6424, -2.1162]])\n",
      "tensor([6])\n",
      "tensor([[-4.0746, -4.1211, -4.2337, -2.5547, -1.5461, -0.7156,  1.8853, -4.3043,\n",
      "          1.6642, -2.1183]])\n",
      "tensor([6])\n",
      "tensor([[-5.0717, -5.2062, -5.3182, -3.0709, -1.9503, -0.8748,  2.3069, -5.4128,\n",
      "          2.0602, -2.5915]])\n",
      "tensor([6])\n",
      "tensor([[-5.1253, -5.2957, -5.4213, -3.0796, -1.9588, -0.9272,  2.2696, -5.4867,\n",
      "          2.1431, -2.5603]])\n",
      "tensor([6])\n",
      "tensor([[-4.8185, -4.7965, -5.0674, -2.8083, -1.7623, -0.8706,  1.7964, -5.2307,\n",
      "          2.3229, -2.3485]])\n",
      "tensor([8])\n",
      "tensor([[-4.1153, -4.2191, -4.2979, -2.5367, -1.5229, -0.7974,  1.7132, -4.4043,\n",
      "          1.8239, -2.1259]])\n",
      "tensor([8])\n",
      "tensor([[-5.6137, -5.6836, -5.8550, -3.3251, -2.1385, -1.0536,  2.2817, -6.1055,\n",
      "          2.5498, -2.7604]])\n",
      "tensor([8])\n",
      "tensor([[-4.2582, -4.3083, -4.5443, -2.5819, -1.6206, -0.7313,  1.9676, -4.5827,\n",
      "          1.7864, -2.2223]])\n",
      "tensor([6])\n",
      "tensor([[-4.1831, -4.3005, -4.4132, -2.5556, -1.6344, -0.7013,  2.1127, -4.4282,\n",
      "          1.5708, -2.1986]])\n",
      "tensor([6])\n",
      "tensor([[-4.6601, -4.6735, -4.8461, -2.7544, -1.7079, -0.8741,  1.9217, -4.9845,\n",
      "          2.1027, -2.2677]])\n",
      "tensor([8])\n",
      "tensor([[-4.2802, -4.2764, -4.5047, -2.5170, -1.5860, -0.7875,  1.7112, -4.6411,\n",
      "          1.9970, -2.1307]])\n",
      "tensor([8])\n",
      "tensor([[-4.3794, -4.4521, -4.6634, -2.6377, -1.6305, -0.7952,  1.9944, -4.6782,\n",
      "          1.7843, -2.2660]])\n",
      "tensor([6])\n",
      "tensor([[-4.4432, -4.4628, -4.7115, -2.6568, -1.6582, -0.8287,  1.8520, -4.8511,\n",
      "          2.0309, -2.2838]])\n",
      "tensor([8])\n",
      "tensor([[-3.9700, -4.0046, -4.2112, -2.4227, -1.5166, -0.6742,  1.9217, -4.1931,\n",
      "          1.5576, -2.0243]])\n",
      "tensor([6])\n",
      "tensor([[-4.6077, -4.5978, -4.8883, -2.7898, -1.6683, -0.8826,  1.7927, -4.9705,\n",
      "          2.1370, -2.2984]])\n",
      "tensor([8])\n",
      "tensor([[-4.3641, -4.3642, -4.5599, -2.6253, -1.6822, -0.7193,  2.0187, -4.6596,\n",
      "          1.7938, -2.2043]])\n",
      "tensor([6])\n",
      "tensor([[-4.5388, -4.5739, -4.7359, -2.7618, -1.6910, -0.8463,  1.9431, -4.8641,\n",
      "          2.0012, -2.2764]])\n",
      "tensor([8])\n",
      "tensor([[-4.0584, -4.0747, -4.2859, -2.5035, -1.4820, -0.7738,  1.6384, -4.3637,\n",
      "          1.8165, -2.0793]])\n",
      "tensor([8])\n",
      "tensor([[-4.3995, -4.4641, -4.6610, -2.6532, -1.7134, -0.7452,  2.0601, -4.6958,\n",
      "          1.7775, -2.2429]])\n",
      "tensor([6])\n",
      "tensor([[-4.3063, -4.3592, -4.4880, -2.6078, -1.6050, -0.8188,  1.8758, -4.5582,\n",
      "          1.8511, -2.1870]])\n",
      "tensor([6])\n",
      "tensor([[-5.6120, -5.6099, -5.8978, -3.2578, -2.0930, -1.1020,  2.0160, -6.1145,\n",
      "          2.7425, -2.6660]])\n",
      "tensor([8])\n",
      "tensor([[-4.5824, -4.6393, -4.9078, -2.7664, -1.7247, -0.8624,  1.8798, -4.9617,\n",
      "          2.0759, -2.3139]])\n",
      "tensor([8])\n",
      "tensor([[-4.1170, -4.1309, -4.3946, -2.4656, -1.6000, -0.7080,  1.8654, -4.4537,\n",
      "          1.8109, -2.0805]])\n",
      "tensor([6])\n",
      "tensor([[-4.5892, -4.5402, -4.7789, -2.6169, -1.6846, -0.8177,  1.9062, -4.7956,\n",
      "          1.9244, -2.1953]])\n",
      "tensor([8])\n",
      "tensor([[-4.3128, -4.3120, -4.4917, -2.5631, -1.6142, -0.8136,  1.8224, -4.6183,\n",
      "          1.9129, -2.1888]])\n",
      "tensor([8])\n",
      "tensor([[-4.6390, -4.7266, -4.8688, -2.7871, -1.7237, -0.9437,  1.8657, -5.0177,\n",
      "          2.1470, -2.3179]])\n",
      "tensor([8])\n",
      "tensor([[-4.0976, -4.3187, -4.3856, -2.5592, -1.6247, -0.7675,  2.0225, -4.3581,\n",
      "          1.6154, -2.1652]])\n",
      "tensor([6])\n",
      "tensor([[-4.1730, -4.2805, -4.4255, -2.4902, -1.5539, -0.7311,  1.8678, -4.4449,\n",
      "          1.7187, -2.1383]])\n",
      "tensor([6])\n",
      "tensor([[-4.3488, -4.3705, -4.4954, -2.6754, -1.6667, -0.8202,  1.9321, -4.6307,\n",
      "          1.8804, -2.1966]])\n",
      "tensor([6])\n",
      "tensor([[-4.4807, -4.6148, -4.7313, -2.6653, -1.6851, -0.8223,  1.9219, -4.8421,\n",
      "          1.9663, -2.2465]])\n",
      "tensor([8])\n",
      "tensor([[-4.2659, -4.3326, -4.5008, -2.5768, -1.6520, -0.7355,  2.0386, -4.5118,\n",
      "          1.6874, -2.1764]])\n",
      "tensor([6])\n",
      "tensor([[-4.0076, -4.0451, -4.2705, -2.5004, -1.4997, -0.6801,  1.9688, -4.2259,\n",
      "          1.5399, -2.1217]])\n",
      "tensor([6])\n",
      "tensor([[-4.5650, -4.5453, -4.7224, -2.8046, -1.7565, -0.8344,  2.0348, -4.8704,\n",
      "          1.9623, -2.2635]])\n",
      "tensor([6])\n",
      "tensor([[-4.3871, -4.4855, -4.6212, -2.6722, -1.6834, -0.8217,  1.9294, -4.6793,\n",
      "          1.8834, -2.2501]])\n",
      "tensor([6])\n",
      "tensor([[-4.7582, -4.7320, -4.9986, -2.7799, -1.7132, -0.8686,  1.8106, -5.1635,\n",
      "          2.2495, -2.3611]])\n",
      "tensor([8])\n",
      "tensor([[-4.7251, -4.7128, -4.8854, -2.8212, -1.7324, -0.9110,  1.8941, -5.0486,\n",
      "          2.1526, -2.2732]])\n",
      "tensor([8])\n",
      "tensor([[-4.2238, -4.2416, -4.4491, -2.5294, -1.5016, -0.7730,  1.7074, -4.5487,\n",
      "          1.9168, -2.1023]])\n",
      "tensor([8])\n",
      "tensor([[-4.4615, -4.4341, -4.7487, -2.5341, -1.6326, -0.8006,  1.7262, -4.8709,\n",
      "          2.0841, -2.1424]])\n",
      "tensor([8])\n",
      "tensor([[-4.6075, -4.6955, -4.8402, -2.7590, -1.7705, -0.8083,  2.0643, -4.9585,\n",
      "          1.9528, -2.3206]])\n",
      "tensor([6])\n",
      "tensor([[-4.0418, -4.1772, -4.2888, -2.4555, -1.5843, -0.6801,  2.0380, -4.2641,\n",
      "          1.5215, -2.0862]])\n",
      "tensor([6])\n",
      "tensor([[-4.0729, -4.1546, -4.2662, -2.5127, -1.5471, -0.7812,  1.8624, -4.3513,\n",
      "          1.7126, -2.0977]])\n",
      "tensor([6])\n",
      "tensor([[-4.2395, -4.3309, -4.4900, -2.5134, -1.5754, -0.7469,  1.8473, -4.5396,\n",
      "          1.8557, -2.1221]])\n",
      "tensor([8])\n",
      "tensor([[-3.9663, -4.0178, -4.1409, -2.4833, -1.5352, -0.7821,  1.7813, -4.1977,\n",
      "          1.7325, -2.0016]])\n",
      "tensor([6])\n",
      "tensor([[-4.3749, -4.4064, -4.5970, -2.6615, -1.5696, -0.8584,  1.6650, -4.7754,\n",
      "          2.1096, -2.1681]])\n",
      "tensor([8])\n",
      "tensor([[-5.5469, -5.7023, -5.7864, -3.3093, -2.1654, -1.0084,  2.4045, -5.9856,\n",
      "          2.4094, -2.7497]])\n",
      "tensor([8])\n",
      "tensor([[-3.7763, -3.9149, -4.0100, -2.3729, -1.4782, -0.6809,  1.9862, -3.9941,\n",
      "          1.3720, -2.0224]])\n",
      "tensor([6])\n",
      "tensor([[-3.8041, -3.8160, -4.0279, -2.2389, -1.3485, -0.7225,  1.3838, -4.1933,\n",
      "          1.9216, -1.8920]])\n",
      "tensor([8])\n",
      "tensor([[-4.2511, -4.2806, -4.4248, -2.6009, -1.5247, -0.8497,  1.6792, -4.5906,\n",
      "          2.0257, -2.1214]])\n",
      "tensor([8])\n",
      "tensor([[-4.9839, -4.9627, -5.2402, -2.8612, -1.8666, -0.8565,  2.1159, -5.3305,\n",
      "          2.1462, -2.4225]])\n",
      "tensor([8])\n",
      "tensor([[-4.3437, -4.5456, -4.6088, -2.7258, -1.6722, -0.8641,  2.0324, -4.6925,\n",
      "          1.8327, -2.3028]])\n",
      "tensor([6])\n",
      "tensor([[-5.0666, -5.1759, -5.4430, -2.9929, -1.9186, -0.8982,  2.1520, -5.4848,\n",
      "          2.2236, -2.5212]])\n",
      "tensor([8])\n",
      "tensor([[-3.8506, -3.9847, -4.0725, -2.4243, -1.4925, -0.6756,  1.9638, -4.0446,\n",
      "          1.4376, -2.0269]])\n",
      "tensor([6])\n",
      "tensor([[-4.5151, -4.5481, -4.7414, -2.6955, -1.7106, -0.7526,  2.0141, -4.7866,\n",
      "          1.8565, -2.2879]])\n",
      "tensor([6])\n",
      "tensor([[-4.0340, -4.2354, -4.3098, -2.4690, -1.5516, -0.7397,  1.9445, -4.3042,\n",
      "          1.6238, -2.0870]])\n",
      "tensor([6])\n",
      "tensor([[-4.1644, -4.2027, -4.3794, -2.5366, -1.5280, -0.7698,  1.9086, -4.4475,\n",
      "          1.6857, -2.1658]])\n",
      "tensor([6])\n",
      "tensor([[-3.9936, -4.1278, -4.2127, -2.4513, -1.5121, -0.7613,  1.7999, -4.2299,\n",
      "          1.6928, -2.0468]])\n",
      "tensor([6])\n",
      "tensor([[-4.9130, -4.9355, -5.1285, -2.9274, -1.8634, -0.8586,  2.1194, -5.2139,\n",
      "          2.0921, -2.4433]])\n",
      "tensor([6])\n",
      "tensor([[-4.7037, -4.6819, -4.8801, -2.8236, -1.7808, -0.8547,  2.1087, -5.0109,\n",
      "          1.9719, -2.3555]])\n",
      "tensor([6])\n",
      "tensor([[-4.5526, -4.5690, -4.8058, -2.6862, -1.6355, -0.8600,  1.8156, -4.8626,\n",
      "          2.0648, -2.2429]])\n",
      "tensor([8])\n",
      "tensor([[-4.3659, -4.3931, -4.5198, -2.6373, -1.5615, -0.8666,  1.6863, -4.7030,\n",
      "          2.0520, -2.2041]])\n",
      "tensor([8])\n",
      "tensor([[-5.0135, -5.2066, -5.2990, -3.0774, -1.9665, -0.8575,  2.3555, -5.3609,\n",
      "          1.9788, -2.5758]])\n",
      "tensor([6])\n",
      "tensor([[-4.2661, -4.2825, -4.4631, -2.6031, -1.6487, -0.7777,  1.8793, -4.5264,\n",
      "          1.8527, -2.0636]])\n",
      "tensor([6])\n",
      "tensor([[-4.5174, -4.6080, -4.7425, -2.7124, -1.7409, -0.7886,  2.0505, -4.8349,\n",
      "          1.8683, -2.2867]])\n",
      "tensor([6])\n",
      "tensor([[-4.8002, -4.9687, -5.0763, -2.8692, -1.8840, -0.8365,  2.2018, -5.1140,\n",
      "          1.9726, -2.4075]])\n",
      "tensor([6])\n",
      "tensor([[-3.9054, -3.9854, -4.1376, -2.4343, -1.5535, -0.7293,  1.9045, -4.1224,\n",
      "          1.5929, -1.9268]])\n",
      "tensor([6])\n",
      "tensor([[-4.1471, -4.1854, -4.3557, -2.5141, -1.5586, -0.7438,  1.9012, -4.4087,\n",
      "          1.7082, -2.1104]])\n",
      "tensor([6])\n",
      "tensor([[-4.5500, -4.6341, -4.8277, -2.7398, -1.7794, -0.7391,  2.1715, -4.8304,\n",
      "          1.8137, -2.3373]])\n",
      "tensor([6])\n",
      "tensor([[-4.2592, -4.3078, -4.4461, -2.6001, -1.5648, -0.8198,  1.8529, -4.5542,\n",
      "          1.8185, -2.2101]])\n",
      "tensor([6])\n",
      "tensor([[-4.1339, -4.1379, -4.3033, -2.5459, -1.5560, -0.6936,  1.9272, -4.3221,\n",
      "          1.6665, -2.1036]])\n",
      "tensor([6])\n",
      "tensor([[-4.9988, -4.9932, -5.2255, -2.8882, -1.9100, -0.8424,  2.1893, -5.3029,\n",
      "          2.1147, -2.4043]])\n",
      "tensor([6])\n",
      "tensor([[-3.9272, -4.0867, -4.1690, -2.4640, -1.5396, -0.7133,  1.9591, -4.2032,\n",
      "          1.5462, -2.0909]])\n",
      "tensor([6])\n",
      "tensor([[-3.7261, -3.8342, -3.9200, -2.3065, -1.4239, -0.6520,  1.8813, -3.9093,\n",
      "          1.3932, -2.0006]])\n",
      "tensor([6])\n",
      "tensor([[-4.2022, -4.3007, -4.4108, -2.5880, -1.6414, -0.7483,  2.0860, -4.4649,\n",
      "          1.6029, -2.1963]])\n",
      "tensor([6])\n",
      "tensor([[-4.2782, -4.3998, -4.4953, -2.6326, -1.6088, -0.7932,  1.8897, -4.5448,\n",
      "          1.7976, -2.1688]])\n",
      "tensor([6])\n",
      "tensor([[-3.8014, -3.8918, -4.1127, -2.2874, -1.4287, -0.7029,  1.6537, -4.1827,\n",
      "          1.7199, -1.9615]])\n",
      "tensor([8])\n",
      "tensor([[-4.2108, -4.3405, -4.4266, -2.5815, -1.6152, -0.7546,  1.9293, -4.4823,\n",
      "          1.7481, -2.1756]])\n",
      "tensor([6])\n",
      "tensor([[-4.8069, -4.7958, -5.0458, -2.8230, -1.8154, -0.9271,  1.8375, -5.2359,\n",
      "          2.3247, -2.3370]])\n",
      "tensor([8])\n",
      "tensor([[-4.1224, -4.1611, -4.3678, -2.4923, -1.5219, -0.7538,  1.7510, -4.4612,\n",
      "          1.8505, -2.1512]])\n",
      "tensor([8])\n",
      "tensor([[-4.3648, -4.4819, -4.5655, -2.6196, -1.5992, -0.7742,  1.8573, -4.6333,\n",
      "          1.8873, -2.2030]])\n",
      "tensor([8])\n",
      "tensor([[-3.8849, -3.9665, -4.0701, -2.3932, -1.4750, -0.7043,  1.7975, -4.0976,\n",
      "          1.5936, -2.0157]])\n",
      "tensor([6])\n",
      "tensor([[-5.4851, -5.5515, -5.7505, -3.2328, -2.0925, -0.9800,  2.3179, -5.8521,\n",
      "          2.3434, -2.6925]])\n",
      "tensor([8])\n",
      "tensor([[-3.9047, -3.9945, -4.1520, -2.4010, -1.5406, -0.6335,  2.0214, -4.1101,\n",
      "          1.4198, -2.0435]])\n",
      "tensor([6])\n",
      "tensor([[-5.5362, -5.5488, -5.8517, -3.1939, -2.0850, -1.0654,  1.9482, -6.0569,\n",
      "          2.7624, -2.6143]])\n",
      "tensor([8])\n",
      "tensor([[-5.3795, -5.3948, -5.6595, -3.1356, -1.9600, -1.0084,  1.9975, -5.8390,\n",
      "          2.5736, -2.6492]])\n",
      "tensor([8])\n",
      "Accuracy on the test set: 61 %\n"
     ]
    }
   ],
   "source": [
    "correct = 0\n",
    "total = 0\n",
    "with torch.no_grad():\n",
    "    net.eval()\n",
    "    for i in range(len(x_test)):\n",
    "        inputs, labels =torch.unsqueeze(x_test[i], 0).to(device).float(), torch.unsqueeze(y_test[i], 0).to(device)\n",
    "        outputs, (hn, cn) = net(inputs)\n",
    "        output = torch.mean(outputs, dim=1)  \n",
    "        #print(inputs)\n",
    "        print(output)\n",
    "        _, predicted = torch.max(output.data, 1)\n",
    "        print(predicted)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "final = 100 * correct / total\n",
    "print('Accuracy on the test set: %d %%' % (final))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
