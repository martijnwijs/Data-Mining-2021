{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np \n",
    "from sklearn.model_selection import train_test_split\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load dataset\n",
    "dataset = \"dataframe_standardized_outliers_removed_classes.csv\"\n",
    "df = pd.read_csv(dataset) # dataframe in pandas\n",
    "df['target'] = df['target'].sub(3)# change to 7 classes 0 1 2 3 4 5 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      Unnamed: 0   no  target  t  activity  appCat.builtin  \\\n",
      "2888        2888  723       4  0 -0.499064       -0.032645   \n",
      "2889        2889  723       4  1  0.989888        0.949300   \n",
      "2890        2890  723       4  2  0.457188        0.335828   \n",
      "2891        2891  723       4  3 -0.154787       -0.272890   \n",
      "\n",
      "      appCat.communication  appCat.entertainment  appCat.finance  appCat.game  \\\n",
      "2888              0.554783             -0.628182       -0.327054    -0.259976   \n",
      "2889              0.538962             -0.513537       -0.327054    -0.259976   \n",
      "2890             -0.591393             -0.658839       -0.327054    -0.259976   \n",
      "2891             -0.855933             -0.658839       -0.327054    -0.259976   \n",
      "\n",
      "      ...  appCat.travel  appCat.unknown  appCat.utilities  appCat.weather  \\\n",
      "2888  ...        -0.4155       -0.322651         -0.089520        -0.23013   \n",
      "2889  ...        -0.4155        0.060803         -0.166846        -0.23013   \n",
      "2890  ...        -0.4155       -0.322651         -0.327129        -0.23013   \n",
      "2891  ...        -0.4155       -0.243459         -0.327129        -0.23013   \n",
      "\n",
      "          call  circumplex.arousal  circumplex.valence      mood    screen  \\\n",
      "2888  1.319838            2.213427           -1.779072 -1.520105 -0.158017   \n",
      "2889  0.975732            0.156356           -0.069287 -1.003098  0.490905   \n",
      "2890 -0.744797           -1.160170            0.785606  0.651322 -0.339057   \n",
      "2891 -0.744797           -1.489301            0.785606  0.030914 -0.797037   \n",
      "\n",
      "           sms  \n",
      "2888 -0.497599  \n",
      "2889  0.793235  \n",
      "2890 -0.497599  \n",
      "2891 -0.497599  \n",
      "\n",
      "[4 rows x 23 columns]\n"
     ]
    }
   ],
   "source": [
    "print(df[df['no'] == 723])\n",
    "for i in range(720, 729):  ### debug\n",
    "    df = df[df['no'] != i]\n",
    "df = df.sample(frac=1) # shuffle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get labels\n",
    "Y = df['target'].to_numpy()\n",
    "Y = Y[::4]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get input \n",
    "X = df.iloc[:, 3:].to_numpy()\n",
    "X = X[:, 1:]\n",
    "split = len(X[:, 0]) / 4\n",
    "X = np.array_split(X, split)\n",
    "X = np.array(X)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# k-fold cross validation\n",
    "from sklearn.model_selection import KFold\n",
    "kf = KFold(n_splits=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cpu\n"
     ]
    }
   ],
   "source": [
    "# training on GPU\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class lstm(nn.Module):\n",
    "    def __init__ (self, input_size, hidden_size, num_layers, seq_length, output_size):\n",
    "        super(). __init__()\n",
    "        self.input_size = input_size\n",
    "        self.hidden_size = hidden_size\n",
    "        self.num_layers = num_layers\n",
    "        self.seq_length = seq_length\n",
    "        self.output_size = output_size\n",
    "        self.hidden_lin_size = 20\n",
    "        self.ltsm = torch.nn.LSTM(self.input_size, self.hidden_size, batch_first=True) \n",
    "        self.lin1 = nn.Linear(self.hidden_size, self.hidden_lin_size) \n",
    "        self.lin2 = nn.Linear(self.hidden_lin_size, self.output_size)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x, (hn, cn) = self.ltsm(x)\n",
    "        x = F.relu(x) # is this ok?\n",
    "        x = F.relu(self.lin1(x))  \n",
    "        x = self.lin2(x)\n",
    "        return x, (hn, cn)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.optim as optim\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1,   100] loss: 1.916\n",
      "[1,   200] loss: 1.309\n",
      "[1,   300] loss: 1.012\n",
      "[1,   400] loss: 1.245\n",
      "[1,   500] loss: 1.185\n",
      "[1,   600] loss: 1.128\n",
      "[1,   700] loss: 1.078\n",
      "[1,   800] loss: 1.169\n",
      "[1,   900] loss: 1.244\n",
      "[2,   100] loss: 1.208\n",
      "[2,   200] loss: 1.178\n",
      "[2,   300] loss: 0.969\n",
      "[2,   400] loss: 1.164\n",
      "[2,   500] loss: 1.148\n",
      "[2,   600] loss: 1.094\n",
      "[2,   700] loss: 1.006\n",
      "[2,   800] loss: 1.120\n",
      "[2,   900] loss: 1.105\n",
      "[3,   100] loss: 1.178\n",
      "[3,   200] loss: 1.138\n",
      "[3,   300] loss: 0.908\n",
      "[3,   400] loss: 1.028\n",
      "[3,   500] loss: 1.086\n",
      "[3,   600] loss: 1.034\n",
      "[3,   700] loss: 0.960\n",
      "[3,   800] loss: 1.060\n",
      "[3,   900] loss: 1.043\n",
      "[4,   100] loss: 1.128\n",
      "[4,   200] loss: 1.111\n",
      "[4,   300] loss: 0.867\n",
      "[4,   400] loss: 0.952\n",
      "[4,   500] loss: 1.051\n",
      "[4,   600] loss: 0.992\n",
      "[4,   700] loss: 0.919\n",
      "[4,   800] loss: 1.017\n",
      "[4,   900] loss: 1.018\n",
      "[5,   100] loss: 1.106\n",
      "[5,   200] loss: 1.081\n",
      "[5,   300] loss: 0.836\n",
      "[5,   400] loss: 0.913\n",
      "[5,   500] loss: 1.018\n",
      "[5,   600] loss: 0.963\n",
      "[5,   700] loss: 0.881\n",
      "[5,   800] loss: 0.968\n",
      "[5,   900] loss: 0.999\n",
      "[6,   100] loss: 1.075\n",
      "[6,   200] loss: 1.057\n",
      "[6,   300] loss: 0.819\n",
      "[6,   400] loss: 0.872\n",
      "[6,   500] loss: 0.982\n",
      "[6,   600] loss: 0.919\n",
      "[6,   700] loss: 0.859\n",
      "[6,   800] loss: 0.926\n",
      "[6,   900] loss: 0.975\n",
      "[7,   100] loss: 1.043\n",
      "[7,   200] loss: 1.042\n",
      "[7,   300] loss: 0.796\n",
      "[7,   400] loss: 0.832\n",
      "[7,   500] loss: 0.959\n",
      "[7,   600] loss: 0.875\n",
      "[7,   700] loss: 0.818\n",
      "[7,   800] loss: 0.897\n",
      "[7,   900] loss: 0.935\n",
      "[8,   100] loss: 1.008\n",
      "[8,   200] loss: 1.006\n",
      "[8,   300] loss: 0.776\n",
      "[8,   400] loss: 0.806\n",
      "[8,   500] loss: 0.933\n",
      "[8,   600] loss: 0.843\n",
      "[8,   700] loss: 0.786\n",
      "[8,   800] loss: 0.817\n",
      "[8,   900] loss: 0.898\n",
      "Finished Training\n",
      "Accuracy on the test set: 54 %\n",
      "[1,   100] loss: 1.713\n",
      "[1,   200] loss: 1.260\n",
      "[1,   300] loss: 1.010\n",
      "[1,   400] loss: 1.257\n",
      "[1,   500] loss: 1.163\n",
      "[1,   600] loss: 1.134\n",
      "[1,   700] loss: 1.046\n",
      "[1,   800] loss: 1.180\n",
      "[1,   900] loss: 1.175\n",
      "[2,   100] loss: 1.102\n",
      "[2,   200] loss: 1.195\n",
      "[2,   300] loss: 0.940\n",
      "[2,   400] loss: 1.112\n",
      "[2,   500] loss: 1.084\n",
      "[2,   600] loss: 1.075\n",
      "[2,   700] loss: 0.979\n",
      "[2,   800] loss: 1.076\n",
      "[2,   900] loss: 1.083\n",
      "[3,   100] loss: 1.071\n",
      "[3,   200] loss: 1.156\n",
      "[3,   300] loss: 0.900\n",
      "[3,   400] loss: 1.045\n",
      "[3,   500] loss: 1.031\n",
      "[3,   600] loss: 1.030\n",
      "[3,   700] loss: 0.951\n",
      "[3,   800] loss: 1.025\n",
      "[3,   900] loss: 1.029\n",
      "[4,   100] loss: 1.046\n",
      "[4,   200] loss: 1.125\n",
      "[4,   300] loss: 0.864\n",
      "[4,   400] loss: 0.993\n",
      "[4,   500] loss: 0.994\n",
      "[4,   600] loss: 1.007\n",
      "[4,   700] loss: 0.926\n",
      "[4,   800] loss: 0.983\n",
      "[4,   900] loss: 0.991\n",
      "[5,   100] loss: 1.027\n",
      "[5,   200] loss: 1.096\n",
      "[5,   300] loss: 0.839\n",
      "[5,   400] loss: 0.958\n",
      "[5,   500] loss: 0.957\n",
      "[5,   600] loss: 0.973\n",
      "[5,   700] loss: 0.892\n",
      "[5,   800] loss: 0.946\n",
      "[5,   900] loss: 0.967\n",
      "[6,   100] loss: 0.995\n",
      "[6,   200] loss: 1.064\n",
      "[6,   300] loss: 0.816\n",
      "[6,   400] loss: 0.923\n",
      "[6,   500] loss: 0.924\n",
      "[6,   600] loss: 0.941\n",
      "[6,   700] loss: 0.861\n",
      "[6,   800] loss: 0.912\n",
      "[6,   900] loss: 0.922\n",
      "[7,   100] loss: 0.952\n",
      "[7,   200] loss: 1.034\n",
      "[7,   300] loss: 0.791\n",
      "[7,   400] loss: 0.875\n",
      "[7,   500] loss: 0.882\n",
      "[7,   600] loss: 0.901\n",
      "[7,   700] loss: 0.829\n",
      "[7,   800] loss: 0.857\n",
      "[7,   900] loss: 0.880\n",
      "[8,   100] loss: 0.901\n",
      "[8,   200] loss: 0.983\n",
      "[8,   300] loss: 0.768\n",
      "[8,   400] loss: 0.813\n",
      "[8,   500] loss: 0.821\n",
      "[8,   600] loss: 0.856\n",
      "[8,   700] loss: 0.779\n",
      "[8,   800] loss: 0.811\n",
      "[8,   900] loss: 0.835\n",
      "Finished Training\n",
      "Accuracy on the test set: 55 %\n",
      "[1,   100] loss: 1.676\n",
      "[1,   200] loss: 1.301\n",
      "[1,   300] loss: 1.052\n",
      "[1,   400] loss: 1.239\n",
      "[1,   500] loss: 1.168\n",
      "[1,   600] loss: 1.140\n",
      "[1,   700] loss: 1.045\n",
      "[1,   800] loss: 1.137\n",
      "[1,   900] loss: 1.172\n",
      "[2,   100] loss: 1.125\n",
      "[2,   200] loss: 1.200\n",
      "[2,   300] loss: 0.955\n",
      "[2,   400] loss: 1.063\n",
      "[2,   500] loss: 1.071\n",
      "[2,   600] loss: 1.032\n",
      "[2,   700] loss: 0.962\n",
      "[2,   800] loss: 1.061\n",
      "[2,   900] loss: 1.061\n",
      "[3,   100] loss: 1.072\n",
      "[3,   200] loss: 1.171\n",
      "[3,   300] loss: 0.891\n",
      "[3,   400] loss: 0.971\n",
      "[3,   500] loss: 1.024\n",
      "[3,   600] loss: 1.020\n",
      "[3,   700] loss: 0.937\n",
      "[3,   800] loss: 1.013\n",
      "[3,   900] loss: 1.020\n",
      "[4,   100] loss: 1.046\n",
      "[4,   200] loss: 1.131\n",
      "[4,   300] loss: 0.851\n",
      "[4,   400] loss: 0.911\n",
      "[4,   500] loss: 0.985\n",
      "[4,   600] loss: 0.992\n",
      "[4,   700] loss: 0.908\n",
      "[4,   800] loss: 0.977\n",
      "[4,   900] loss: 0.993\n",
      "[5,   100] loss: 1.014\n",
      "[5,   200] loss: 1.097\n",
      "[5,   300] loss: 0.819\n",
      "[5,   400] loss: 0.871\n",
      "[5,   500] loss: 0.946\n",
      "[5,   600] loss: 0.964\n",
      "[5,   700] loss: 0.888\n",
      "[5,   800] loss: 0.943\n",
      "[5,   900] loss: 0.960\n",
      "[6,   100] loss: 0.975\n",
      "[6,   200] loss: 1.057\n",
      "[6,   300] loss: 0.788\n",
      "[6,   400] loss: 0.836\n",
      "[6,   500] loss: 0.911\n",
      "[6,   600] loss: 0.920\n",
      "[6,   700] loss: 0.857\n",
      "[6,   800] loss: 0.911\n",
      "[6,   900] loss: 0.918\n",
      "[7,   100] loss: 0.929\n",
      "[7,   200] loss: 1.013\n",
      "[7,   300] loss: 0.755\n",
      "[7,   400] loss: 0.783\n",
      "[7,   500] loss: 0.880\n",
      "[7,   600] loss: 0.888\n",
      "[7,   700] loss: 0.822\n",
      "[7,   800] loss: 0.883\n",
      "[7,   900] loss: 0.849\n",
      "[8,   100] loss: 0.878\n",
      "[8,   200] loss: 0.964\n",
      "[8,   300] loss: 0.729\n",
      "[8,   400] loss: 0.738\n",
      "[8,   500] loss: 0.832\n",
      "[8,   600] loss: 0.839\n",
      "[8,   700] loss: 0.780\n",
      "[8,   800] loss: 0.826\n",
      "[8,   900] loss: 0.784\n",
      "Finished Training\n",
      "Accuracy on the test set: 54 %\n",
      "[1,   100] loss: 1.817\n",
      "[1,   200] loss: 1.283\n",
      "[1,   300] loss: 1.233\n",
      "[1,   400] loss: 1.217\n",
      "[1,   500] loss: 1.168\n",
      "[1,   600] loss: 1.126\n",
      "[1,   700] loss: 1.046\n",
      "[1,   800] loss: 1.189\n",
      "[1,   900] loss: 1.159\n",
      "[2,   100] loss: 1.096\n",
      "[2,   200] loss: 1.226\n",
      "[2,   300] loss: 1.190\n",
      "[2,   400] loss: 1.098\n",
      "[2,   500] loss: 1.101\n",
      "[2,   600] loss: 1.044\n",
      "[2,   700] loss: 0.987\n",
      "[2,   800] loss: 1.079\n",
      "[2,   900] loss: 1.080\n",
      "[3,   100] loss: 1.060\n",
      "[3,   200] loss: 1.190\n",
      "[3,   300] loss: 1.147\n",
      "[3,   400] loss: 1.035\n",
      "[3,   500] loss: 1.055\n",
      "[3,   600] loss: 1.009\n",
      "[3,   700] loss: 0.947\n",
      "[3,   800] loss: 1.032\n",
      "[3,   900] loss: 1.038\n",
      "[4,   100] loss: 1.034\n",
      "[4,   200] loss: 1.146\n",
      "[4,   300] loss: 1.106\n",
      "[4,   400] loss: 0.986\n",
      "[4,   500] loss: 1.014\n",
      "[4,   600] loss: 0.979\n",
      "[4,   700] loss: 0.915\n",
      "[4,   800] loss: 0.987\n",
      "[4,   900] loss: 1.006\n",
      "[5,   100] loss: 1.000\n",
      "[5,   200] loss: 1.098\n",
      "[5,   300] loss: 1.063\n",
      "[5,   400] loss: 0.949\n",
      "[5,   500] loss: 0.972\n",
      "[5,   600] loss: 0.955\n",
      "[5,   700] loss: 0.891\n",
      "[5,   800] loss: 0.937\n",
      "[5,   900] loss: 0.968\n",
      "[6,   100] loss: 0.950\n",
      "[6,   200] loss: 1.061\n",
      "[6,   300] loss: 1.030\n",
      "[6,   400] loss: 0.907\n",
      "[6,   500] loss: 0.922\n",
      "[6,   600] loss: 0.918\n",
      "[6,   700] loss: 0.856\n",
      "[6,   800] loss: 0.911\n",
      "[6,   900] loss: 0.936\n",
      "[7,   100] loss: 0.897\n",
      "[7,   200] loss: 1.003\n",
      "[7,   300] loss: 0.979\n",
      "[7,   400] loss: 0.876\n",
      "[7,   500] loss: 0.883\n",
      "[7,   600] loss: 0.853\n",
      "[7,   700] loss: 0.826\n",
      "[7,   800] loss: 0.842\n",
      "[7,   900] loss: 0.887\n",
      "[8,   100] loss: 0.843\n",
      "[8,   200] loss: 0.965\n",
      "[8,   300] loss: 0.925\n",
      "[8,   400] loss: 0.816\n",
      "[8,   500] loss: 0.834\n",
      "[8,   600] loss: 0.788\n",
      "[8,   700] loss: 0.792\n",
      "[8,   800] loss: 0.767\n",
      "[8,   900] loss: 0.828\n",
      "Finished Training\n",
      "Accuracy on the test set: 61 %\n",
      "[1,   100] loss: 1.658\n",
      "[1,   200] loss: 1.277\n",
      "[1,   300] loss: 1.231\n",
      "[1,   400] loss: 0.982\n",
      "[1,   500] loss: 1.169\n",
      "[1,   600] loss: 1.138\n",
      "[1,   700] loss: 1.050\n",
      "[1,   800] loss: 1.191\n",
      "[1,   900] loss: 1.184\n",
      "[2,   100] loss: 1.072\n",
      "[2,   200] loss: 1.244\n",
      "[2,   300] loss: 1.187\n",
      "[2,   400] loss: 0.927\n",
      "[2,   500] loss: 1.078\n",
      "[2,   600] loss: 1.070\n",
      "[2,   700] loss: 0.989\n",
      "[2,   800] loss: 1.071\n",
      "[2,   900] loss: 1.079\n",
      "[3,   100] loss: 1.031\n",
      "[3,   200] loss: 1.190\n",
      "[3,   300] loss: 1.162\n",
      "[3,   400] loss: 0.886\n",
      "[3,   500] loss: 1.025\n",
      "[3,   600] loss: 1.032\n",
      "[3,   700] loss: 0.947\n",
      "[3,   800] loss: 1.008\n",
      "[3,   900] loss: 1.036\n",
      "[4,   100] loss: 1.009\n",
      "[4,   200] loss: 1.142\n",
      "[4,   300] loss: 1.123\n",
      "[4,   400] loss: 0.849\n",
      "[4,   500] loss: 0.976\n",
      "[4,   600] loss: 1.010\n",
      "[4,   700] loss: 0.917\n",
      "[4,   800] loss: 0.964\n",
      "[4,   900] loss: 0.996\n",
      "[5,   100] loss: 0.976\n",
      "[5,   200] loss: 1.103\n",
      "[5,   300] loss: 1.087\n",
      "[5,   400] loss: 0.816\n",
      "[5,   500] loss: 0.932\n",
      "[5,   600] loss: 0.978\n",
      "[5,   700] loss: 0.891\n",
      "[5,   800] loss: 0.930\n",
      "[5,   900] loss: 0.951\n",
      "[6,   100] loss: 0.929\n",
      "[6,   200] loss: 1.056\n",
      "[6,   300] loss: 1.038\n",
      "[6,   400] loss: 0.791\n",
      "[6,   500] loss: 0.881\n",
      "[6,   600] loss: 0.934\n",
      "[6,   700] loss: 0.866\n",
      "[6,   800] loss: 0.897\n",
      "[6,   900] loss: 0.889\n",
      "[7,   100] loss: 0.875\n",
      "[7,   200] loss: 0.998\n",
      "[7,   300] loss: 0.993\n",
      "[7,   400] loss: 0.769\n",
      "[7,   500] loss: 0.820\n",
      "[7,   600] loss: 0.874\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[7,   700] loss: 0.838\n",
      "[7,   800] loss: 0.850\n",
      "[7,   900] loss: 0.823\n",
      "[8,   100] loss: 0.829\n",
      "[8,   200] loss: 0.938\n",
      "[8,   300] loss: 0.939\n",
      "[8,   400] loss: 0.746\n",
      "[8,   500] loss: 0.771\n",
      "[8,   600] loss: 0.811\n",
      "[8,   700] loss: 0.807\n",
      "[8,   800] loss: 0.778\n",
      "[8,   900] loss: 0.764\n",
      "Finished Training\n",
      "Accuracy on the test set: 59 %\n",
      "[1,   100] loss: 1.851\n",
      "[1,   200] loss: 1.301\n",
      "[1,   300] loss: 1.225\n",
      "[1,   400] loss: 0.993\n",
      "[1,   500] loss: 1.236\n",
      "[1,   600] loss: 1.148\n",
      "[1,   700] loss: 1.060\n",
      "[1,   800] loss: 1.178\n",
      "[1,   900] loss: 1.182\n",
      "[2,   100] loss: 1.126\n",
      "[2,   200] loss: 1.210\n",
      "[2,   300] loss: 1.172\n",
      "[2,   400] loss: 0.902\n",
      "[2,   500] loss: 1.084\n",
      "[2,   600] loss: 1.049\n",
      "[2,   700] loss: 0.965\n",
      "[2,   800] loss: 1.085\n",
      "[2,   900] loss: 1.081\n",
      "[3,   100] loss: 1.102\n",
      "[3,   200] loss: 1.164\n",
      "[3,   300] loss: 1.121\n",
      "[3,   400] loss: 0.846\n",
      "[3,   500] loss: 0.999\n",
      "[3,   600] loss: 0.991\n",
      "[3,   700] loss: 0.930\n",
      "[3,   800] loss: 1.032\n",
      "[3,   900] loss: 1.032\n",
      "[4,   100] loss: 1.074\n",
      "[4,   200] loss: 1.134\n",
      "[4,   300] loss: 1.080\n",
      "[4,   400] loss: 0.816\n",
      "[4,   500] loss: 0.958\n",
      "[4,   600] loss: 0.934\n",
      "[4,   700] loss: 0.917\n",
      "[4,   800] loss: 0.981\n",
      "[4,   900] loss: 0.998\n",
      "[5,   100] loss: 1.047\n",
      "[5,   200] loss: 1.092\n",
      "[5,   300] loss: 1.049\n",
      "[5,   400] loss: 0.797\n",
      "[5,   500] loss: 0.921\n",
      "[5,   600] loss: 0.879\n",
      "[5,   700] loss: 0.878\n",
      "[5,   800] loss: 0.935\n",
      "[5,   900] loss: 0.960\n",
      "[6,   100] loss: 1.022\n",
      "[6,   200] loss: 1.049\n",
      "[6,   300] loss: 1.018\n",
      "[6,   400] loss: 0.776\n",
      "[6,   500] loss: 0.880\n",
      "[6,   600] loss: 0.832\n",
      "[6,   700] loss: 0.846\n",
      "[6,   800] loss: 0.892\n",
      "[6,   900] loss: 0.918\n",
      "[7,   100] loss: 0.966\n",
      "[7,   200] loss: 1.016\n",
      "[7,   300] loss: 0.990\n",
      "[7,   400] loss: 0.752\n",
      "[7,   500] loss: 0.846\n",
      "[7,   600] loss: 0.799\n",
      "[7,   700] loss: 0.787\n",
      "[7,   800] loss: 0.825\n",
      "[7,   900] loss: 0.872\n",
      "[8,   100] loss: 0.906\n",
      "[8,   200] loss: 0.968\n",
      "[8,   300] loss: 0.951\n",
      "[8,   400] loss: 0.730\n",
      "[8,   500] loss: 0.803\n",
      "[8,   600] loss: 0.756\n",
      "[8,   700] loss: 0.748\n",
      "[8,   800] loss: 0.742\n",
      "[8,   900] loss: 0.816\n",
      "Finished Training\n",
      "Accuracy on the test set: 52 %\n",
      "[1,   100] loss: 1.672\n",
      "[1,   200] loss: 1.268\n",
      "[1,   300] loss: 1.226\n",
      "[1,   400] loss: 0.976\n",
      "[1,   500] loss: 1.206\n",
      "[1,   600] loss: 1.102\n",
      "[1,   700] loss: 1.098\n",
      "[1,   800] loss: 1.120\n",
      "[1,   900] loss: 1.146\n",
      "[2,   100] loss: 1.109\n",
      "[2,   200] loss: 1.205\n",
      "[2,   300] loss: 1.175\n",
      "[2,   400] loss: 0.889\n",
      "[2,   500] loss: 1.071\n",
      "[2,   600] loss: 1.038\n",
      "[2,   700] loss: 1.066\n",
      "[2,   800] loss: 1.061\n",
      "[2,   900] loss: 1.058\n",
      "[3,   100] loss: 1.065\n",
      "[3,   200] loss: 1.190\n",
      "[3,   300] loss: 1.143\n",
      "[3,   400] loss: 0.858\n",
      "[3,   500] loss: 1.008\n",
      "[3,   600] loss: 0.995\n",
      "[3,   700] loss: 1.033\n",
      "[3,   800] loss: 1.020\n",
      "[3,   900] loss: 1.022\n",
      "[4,   100] loss: 1.035\n",
      "[4,   200] loss: 1.153\n",
      "[4,   300] loss: 1.108\n",
      "[4,   400] loss: 0.825\n",
      "[4,   500] loss: 0.969\n",
      "[4,   600] loss: 0.967\n",
      "[4,   700] loss: 0.988\n",
      "[4,   800] loss: 1.002\n",
      "[4,   900] loss: 0.990\n",
      "[5,   100] loss: 1.005\n",
      "[5,   200] loss: 1.117\n",
      "[5,   300] loss: 1.080\n",
      "[5,   400] loss: 0.795\n",
      "[5,   500] loss: 0.936\n",
      "[5,   600] loss: 0.946\n",
      "[5,   700] loss: 0.967\n",
      "[5,   800] loss: 0.947\n",
      "[5,   900] loss: 0.947\n",
      "[6,   100] loss: 0.956\n",
      "[6,   200] loss: 1.068\n",
      "[6,   300] loss: 1.044\n",
      "[6,   400] loss: 0.764\n",
      "[6,   500] loss: 0.875\n",
      "[6,   600] loss: 0.901\n",
      "[6,   700] loss: 0.907\n",
      "[6,   800] loss: 0.879\n",
      "[6,   900] loss: 0.911\n",
      "[7,   100] loss: 0.909\n",
      "[7,   200] loss: 1.024\n",
      "[7,   300] loss: 0.998\n",
      "[7,   400] loss: 0.739\n",
      "[7,   500] loss: 0.832\n",
      "[7,   600] loss: 0.856\n",
      "[7,   700] loss: 0.838\n",
      "[7,   800] loss: 0.822\n",
      "[7,   900] loss: 0.860\n",
      "[8,   100] loss: 0.867\n",
      "[8,   200] loss: 0.954\n",
      "[8,   300] loss: 0.946\n",
      "[8,   400] loss: 0.706\n",
      "[8,   500] loss: 0.781\n",
      "[8,   600] loss: 0.800\n",
      "[8,   700] loss: 0.781\n",
      "[8,   800] loss: 0.745\n",
      "[8,   900] loss: 0.799\n",
      "Finished Training\n",
      "Accuracy on the test set: 58 %\n",
      "[1,   100] loss: 1.755\n",
      "[1,   200] loss: 1.289\n",
      "[1,   300] loss: 1.229\n",
      "[1,   400] loss: 0.988\n",
      "[1,   500] loss: 1.233\n",
      "[1,   600] loss: 1.137\n",
      "[1,   700] loss: 1.140\n",
      "[1,   800] loss: 1.054\n",
      "[1,   900] loss: 1.156\n",
      "[2,   100] loss: 1.073\n",
      "[2,   200] loss: 1.219\n",
      "[2,   300] loss: 1.180\n",
      "[2,   400] loss: 0.907\n",
      "[2,   500] loss: 1.105\n",
      "[2,   600] loss: 1.045\n",
      "[2,   700] loss: 1.065\n",
      "[2,   800] loss: 0.958\n",
      "[2,   900] loss: 1.072\n",
      "[3,   100] loss: 1.048\n",
      "[3,   200] loss: 1.177\n",
      "[3,   300] loss: 1.142\n",
      "[3,   400] loss: 0.868\n",
      "[3,   500] loss: 1.013\n",
      "[3,   600] loss: 0.997\n",
      "[3,   700] loss: 1.048\n",
      "[3,   800] loss: 0.898\n",
      "[3,   900] loss: 1.031\n",
      "[4,   100] loss: 1.023\n",
      "[4,   200] loss: 1.130\n",
      "[4,   300] loss: 1.102\n",
      "[4,   400] loss: 0.835\n",
      "[4,   500] loss: 0.961\n",
      "[4,   600] loss: 0.954\n",
      "[4,   700] loss: 1.015\n",
      "[4,   800] loss: 0.864\n",
      "[4,   900] loss: 0.992\n",
      "[5,   100] loss: 0.988\n",
      "[5,   200] loss: 1.094\n",
      "[5,   300] loss: 1.068\n",
      "[5,   400] loss: 0.814\n",
      "[5,   500] loss: 0.921\n",
      "[5,   600] loss: 0.906\n",
      "[5,   700] loss: 0.990\n",
      "[5,   800] loss: 0.841\n",
      "[5,   900] loss: 0.940\n",
      "[6,   100] loss: 0.948\n",
      "[6,   200] loss: 1.058\n",
      "[6,   300] loss: 1.034\n",
      "[6,   400] loss: 0.797\n",
      "[6,   500] loss: 0.875\n",
      "[6,   600] loss: 0.870\n",
      "[6,   700] loss: 0.941\n",
      "[6,   800] loss: 0.820\n",
      "[6,   900] loss: 0.899\n",
      "[7,   100] loss: 0.902\n",
      "[7,   200] loss: 1.018\n",
      "[7,   300] loss: 0.997\n",
      "[7,   400] loss: 0.781\n",
      "[7,   500] loss: 0.834\n",
      "[7,   600] loss: 0.833\n",
      "[7,   700] loss: 0.880\n",
      "[7,   800] loss: 0.784\n",
      "[7,   900] loss: 0.838\n",
      "[8,   100] loss: 0.852\n",
      "[8,   200] loss: 0.961\n",
      "[8,   300] loss: 0.941\n",
      "[8,   400] loss: 0.755\n",
      "[8,   500] loss: 0.771\n",
      "[8,   600] loss: 0.770\n",
      "[8,   700] loss: 0.831\n",
      "[8,   800] loss: 0.733\n",
      "[8,   900] loss: 0.777\n",
      "Finished Training\n",
      "Accuracy on the test set: 48 %\n",
      "[1,   100] loss: 1.687\n",
      "[1,   200] loss: 1.272\n",
      "[1,   300] loss: 1.235\n",
      "[1,   400] loss: 0.987\n",
      "[1,   500] loss: 1.242\n",
      "[1,   600] loss: 1.144\n",
      "[1,   700] loss: 1.146\n",
      "[1,   800] loss: 1.042\n",
      "[1,   900] loss: 1.169\n",
      "[2,   100] loss: 1.116\n",
      "[2,   200] loss: 1.217\n",
      "[2,   300] loss: 1.181\n",
      "[2,   400] loss: 0.907\n",
      "[2,   500] loss: 1.095\n",
      "[2,   600] loss: 1.059\n",
      "[2,   700] loss: 1.060\n",
      "[2,   800] loss: 0.963\n",
      "[2,   900] loss: 1.061\n",
      "[3,   100] loss: 1.076\n",
      "[3,   200] loss: 1.180\n",
      "[3,   300] loss: 1.151\n",
      "[3,   400] loss: 0.868\n",
      "[3,   500] loss: 1.000\n",
      "[3,   600] loss: 1.003\n",
      "[3,   700] loss: 1.046\n",
      "[3,   800] loss: 0.928\n",
      "[3,   900] loss: 1.008\n",
      "[4,   100] loss: 1.043\n",
      "[4,   200] loss: 1.141\n",
      "[4,   300] loss: 1.117\n",
      "[4,   400] loss: 0.837\n",
      "[4,   500] loss: 0.945\n",
      "[4,   600] loss: 0.957\n",
      "[4,   700] loss: 1.021\n",
      "[4,   800] loss: 0.893\n",
      "[4,   900] loss: 0.983\n",
      "[5,   100] loss: 1.014\n",
      "[5,   200] loss: 1.108\n",
      "[5,   300] loss: 1.088\n",
      "[5,   400] loss: 0.813\n",
      "[5,   500] loss: 0.902\n",
      "[5,   600] loss: 0.909\n",
      "[5,   700] loss: 1.004\n",
      "[5,   800] loss: 0.864\n",
      "[5,   900] loss: 0.945\n",
      "[6,   100] loss: 0.967\n",
      "[6,   200] loss: 1.087\n",
      "[6,   300] loss: 1.055\n",
      "[6,   400] loss: 0.786\n",
      "[6,   500] loss: 0.872\n",
      "[6,   600] loss: 0.864\n",
      "[6,   700] loss: 0.972\n",
      "[6,   800] loss: 0.816\n",
      "[6,   900] loss: 0.886\n",
      "[7,   100] loss: 0.908\n",
      "[7,   200] loss: 1.052\n",
      "[7,   300] loss: 1.018\n",
      "[7,   400] loss: 0.758\n",
      "[7,   500] loss: 0.824\n",
      "[7,   600] loss: 0.818\n",
      "[7,   700] loss: 0.924\n",
      "[7,   800] loss: 0.779\n",
      "[7,   900] loss: 0.815\n",
      "[8,   100] loss: 0.851\n",
      "[8,   200] loss: 1.003\n",
      "[8,   300] loss: 0.971\n",
      "[8,   400] loss: 0.738\n",
      "[8,   500] loss: 0.761\n",
      "[8,   600] loss: 0.756\n",
      "[8,   700] loss: 0.876\n",
      "[8,   800] loss: 0.725\n",
      "[8,   900] loss: 0.742\n",
      "Finished Training\n",
      "Accuracy on the test set: 53 %\n",
      "[1,   100] loss: 1.769\n",
      "[1,   200] loss: 1.346\n",
      "[1,   300] loss: 1.232\n",
      "[1,   400] loss: 0.988\n",
      "[1,   500] loss: 1.240\n",
      "[1,   600] loss: 1.138\n",
      "[1,   700] loss: 1.154\n",
      "[1,   800] loss: 1.043\n",
      "[1,   900] loss: 1.101\n",
      "[2,   100] loss: 1.130\n",
      "[2,   200] loss: 1.220\n",
      "[2,   300] loss: 1.185\n",
      "[2,   400] loss: 0.897\n",
      "[2,   500] loss: 1.110\n",
      "[2,   600] loss: 1.069\n",
      "[2,   700] loss: 1.058\n",
      "[2,   800] loss: 0.950\n",
      "[2,   900] loss: 1.001\n",
      "[3,   100] loss: 1.098\n",
      "[3,   200] loss: 1.184\n",
      "[3,   300] loss: 1.145\n",
      "[3,   400] loss: 0.856\n",
      "[3,   500] loss: 1.030\n",
      "[3,   600] loss: 1.017\n",
      "[3,   700] loss: 1.037\n",
      "[3,   800] loss: 0.903\n",
      "[3,   900] loss: 0.949\n",
      "[4,   100] loss: 1.052\n",
      "[4,   200] loss: 1.143\n",
      "[4,   300] loss: 1.112\n",
      "[4,   400] loss: 0.821\n",
      "[4,   500] loss: 0.994\n",
      "[4,   600] loss: 1.006\n",
      "[4,   700] loss: 1.008\n",
      "[4,   800] loss: 0.874\n",
      "[4,   900] loss: 0.923\n",
      "[5,   100] loss: 1.029\n",
      "[5,   200] loss: 1.094\n",
      "[5,   300] loss: 1.086\n",
      "[5,   400] loss: 0.799\n",
      "[5,   500] loss: 0.946\n",
      "[5,   600] loss: 0.980\n",
      "[5,   700] loss: 0.985\n",
      "[5,   800] loss: 0.847\n",
      "[5,   900] loss: 0.885\n",
      "[6,   100] loss: 0.989\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[6,   200] loss: 1.061\n",
      "[6,   300] loss: 1.063\n",
      "[6,   400] loss: 0.774\n",
      "[6,   500] loss: 0.912\n",
      "[6,   600] loss: 0.957\n",
      "[6,   700] loss: 0.950\n",
      "[6,   800] loss: 0.809\n",
      "[6,   900] loss: 0.862\n",
      "[7,   100] loss: 0.942\n",
      "[7,   200] loss: 1.020\n",
      "[7,   300] loss: 1.027\n",
      "[7,   400] loss: 0.747\n",
      "[7,   500] loss: 0.868\n",
      "[7,   600] loss: 0.905\n",
      "[7,   700] loss: 0.913\n",
      "[7,   800] loss: 0.783\n",
      "[7,   900] loss: 0.839\n",
      "[8,   100] loss: 0.875\n",
      "[8,   200] loss: 0.977\n",
      "[8,   300] loss: 0.980\n",
      "[8,   400] loss: 0.727\n",
      "[8,   500] loss: 0.823\n",
      "[8,   600] loss: 0.851\n",
      "[8,   700] loss: 0.847\n",
      "[8,   800] loss: 0.752\n",
      "[8,   900] loss: 0.786\n",
      "Finished Training\n",
      "Accuracy on the test set: 55 %\n"
     ]
    }
   ],
   "source": [
    "test_accuracy = []\n",
    "\n",
    "# train 10 times FOR STATISTICS\n",
    "for train_index, test_index in kf.split(X): # K-FOLD CROSS VALIDATION\n",
    "    net = lstm(input_size=19, hidden_size=100, num_layers=1, seq_length=4, output_size=7).float() # reset NN\n",
    "    learning_rate = 0.001\n",
    "    optimizer = optim.Adam(net.parameters(), lr=learning_rate)\n",
    "    \n",
    "    # split test and train\n",
    "    x_train, x_test = X[train_index], X[test_index]\n",
    "    y_train, y_test = Y[train_index], Y[test_index]\n",
    "    \n",
    "    # to torch tensor\n",
    "    x_train = torch.tensor(x_train)\n",
    "    y_train = torch.tensor(y_train).to(torch.int64)\n",
    "    x_test = torch.tensor(x_test)\n",
    "    y_test = torch.tensor(y_test).to(torch.int64)\n",
    "\n",
    "    # weighted cross entropy\n",
    "    unique, counts = np.unique(y_train, return_counts=True)\n",
    "    nSamples = [887, 6130, 480, 317, 972, 101, 128]\n",
    "    normedWeights = [(1 - (x / sum(counts))) for x in counts]\n",
    "    normedWeights = torch.FloatTensor(normedWeights).to(device)\n",
    "    criterion = nn.CrossEntropyLoss(weight=normedWeights)\n",
    "    \n",
    "    # train the network\n",
    "    for epoch in range(8):\n",
    "        running_loss = 0.0\n",
    "        net.train()\n",
    "        for i in range(len(x_train)):\n",
    "            \n",
    "            inputs, labels =torch.unsqueeze(x_train[i], 0).to(device).float(), torch.unsqueeze(y_train[i], 0).to(device)\n",
    "            \n",
    "            # zero the parameter gradients\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            # forward + backward + optimize\n",
    "            outputs, (hn, cn) = net(inputs)\n",
    "            output = torch.mean(outputs, dim=1) # takes the average over the outputs \n",
    "            loss = criterion(output, labels)\n",
    "            loss.backward() \n",
    "            optimizer.step()\n",
    "            running_loss += loss.item()\n",
    "\n",
    "            # statistics tensorboard\n",
    "            if i % 100 == 99:    # every 30 mini-batches\n",
    "\n",
    "                # print\n",
    "                print('[%d, %5d] loss: %.3f' %\n",
    "                      (epoch + 1, i + 1, running_loss / 100))\n",
    "\n",
    "                running_loss = 0.0\n",
    "\n",
    "    print('Finished Training')\n",
    "    \n",
    "    \n",
    "    # validation \n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        net.eval()\n",
    "        for i in range(len(x_test)):\n",
    "            inputs, labels =torch.unsqueeze(x_test[i], 0).to(device).float(), torch.unsqueeze(y_test[i], 0).to(device)\n",
    "            outputs, (hn, cn) = net(inputs)\n",
    "            output = torch.mean(outputs, dim=1)  \n",
    "            _, predicted = torch.max(output.data, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "    final = 100 * correct / total\n",
    "    print('Accuracy on the test set: %d %%' % (final))\n",
    "    test_accuracy.append(final)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean 55.57692307692307\n",
      "stdev 3.5926041715902692\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "test_accuracy = np.array(test_accuracy)\n",
    "plt.hist(test_accuracy, bins=10)\n",
    "plt.show()\n",
    "mean = np.mean(test_accuracy)\n",
    "print(\"mean\", mean)\n",
    "print(\"stdev\", np.std(test_accuracy))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
