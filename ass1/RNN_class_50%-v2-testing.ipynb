{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np \n",
    "from sklearn.model_selection import train_test_split\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load dataset\n",
    "dataset = \"dataframe_standardized_outliers_removed_classes.csv\"\n",
    "df = pd.read_csv(dataset) # dataframe in pandas\n",
    "df['target'] = df['target'].sub(3)# change to 7 classes 0 1 2 3 4 5 6\n",
    "#print(df[df['target'] == 0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      Unnamed: 0   no  target  t  activity  appCat.builtin  \\\n",
      "2888        2888  723       4  0 -0.499064       -0.032645   \n",
      "2889        2889  723       4  1  0.989888        0.949300   \n",
      "2890        2890  723       4  2  0.457188        0.335828   \n",
      "2891        2891  723       4  3 -0.154787       -0.272890   \n",
      "\n",
      "      appCat.communication  appCat.entertainment  appCat.finance  appCat.game  \\\n",
      "2888              0.554783             -0.628182       -0.327054    -0.259976   \n",
      "2889              0.538962             -0.513537       -0.327054    -0.259976   \n",
      "2890             -0.591393             -0.658839       -0.327054    -0.259976   \n",
      "2891             -0.855933             -0.658839       -0.327054    -0.259976   \n",
      "\n",
      "      ...  appCat.travel  appCat.unknown  appCat.utilities  appCat.weather  \\\n",
      "2888  ...        -0.4155       -0.322651         -0.089520        -0.23013   \n",
      "2889  ...        -0.4155        0.060803         -0.166846        -0.23013   \n",
      "2890  ...        -0.4155       -0.322651         -0.327129        -0.23013   \n",
      "2891  ...        -0.4155       -0.243459         -0.327129        -0.23013   \n",
      "\n",
      "          call  circumplex.arousal  circumplex.valence      mood    screen  \\\n",
      "2888  1.319838            2.213427           -1.779072 -1.520105 -0.158017   \n",
      "2889  0.975732            0.156356           -0.069287 -1.003098  0.490905   \n",
      "2890 -0.744797           -1.160170            0.785606  0.651322 -0.339057   \n",
      "2891 -0.744797           -1.489301            0.785606  0.030914 -0.797037   \n",
      "\n",
      "           sms  \n",
      "2888 -0.497599  \n",
      "2889  0.793235  \n",
      "2890 -0.497599  \n",
      "2891 -0.497599  \n",
      "\n",
      "[4 rows x 23 columns]\n"
     ]
    }
   ],
   "source": [
    "print(df[df['no'] == 723])\n",
    "for i in range(720, 729):  ### debug\n",
    "    df = df[df['no'] != i]\n",
    "df = df.sample(frac=1) # shuffle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get labels\n",
    "Y = df['target'].to_numpy()\n",
    "Y = Y[::4]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get input \n",
    "X = df.iloc[:, 3:].to_numpy()\n",
    "X = X[:, 1:]\n",
    "split = len(X[:, 0]) / 4\n",
    "X = np.array_split(X, split)\n",
    "X = np.array(X)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# k-fold cross validation\n",
    "from sklearn.model_selection import KFold\n",
    "kf = KFold(n_splits=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cpu\n"
     ]
    }
   ],
   "source": [
    "# training on GPU\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class lstm(nn.Module):\n",
    "    def __init__ (self, input_size, hidden_size, num_layers, seq_length, output_size):\n",
    "        super(). __init__()\n",
    "        self.input_size = input_size\n",
    "        self.hidden_size = hidden_size\n",
    "        self.num_layers = num_layers\n",
    "        self.seq_length = seq_length\n",
    "        self.output_size = output_size\n",
    "        self.hidden_lin_size = 20\n",
    "        self.ltsm = torch.nn.LSTM(self.input_size, self.hidden_size, batch_first=True) \n",
    "        self.lin1 = nn.Linear(self.hidden_size, self.hidden_lin_size) \n",
    "        self.lin2 = nn.Linear(self.hidden_lin_size, self.output_size)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x, (hn, cn) = self.ltsm(x)\n",
    "        x = F.relu(x) # is this ok?\n",
    "        x = F.relu(self.lin1(x))  \n",
    "        x = self.lin2(x)\n",
    "        return x, (hn, cn)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.optim as optim\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1,   100] loss: 1.618\n",
      "[1,   200] loss: 1.416\n",
      "[1,   300] loss: 1.165\n",
      "[1,   400] loss: 1.132\n",
      "[1,   500] loss: 1.301\n",
      "[1,   600] loss: 1.121\n",
      "[1,   700] loss: 1.076\n",
      "[1,   800] loss: 1.064\n",
      "[1,   900] loss: 1.193\n",
      "[2,   100] loss: 1.083\n",
      "[2,   200] loss: 1.300\n",
      "[2,   300] loss: 1.071\n",
      "[2,   400] loss: 1.079\n",
      "[2,   500] loss: 1.248\n",
      "[2,   600] loss: 1.074\n",
      "[2,   700] loss: 0.998\n",
      "[2,   800] loss: 1.025\n",
      "[2,   900] loss: 1.139\n",
      "[3,   100] loss: 1.069\n",
      "[3,   200] loss: 1.252\n",
      "[3,   300] loss: 1.053\n",
      "[3,   400] loss: 1.047\n",
      "[3,   500] loss: 1.216\n",
      "[3,   600] loss: 1.053\n",
      "[3,   700] loss: 0.962\n",
      "[3,   800] loss: 0.998\n",
      "[3,   900] loss: 1.110\n",
      "[4,   100] loss: 1.037\n",
      "[4,   200] loss: 1.219\n",
      "[4,   300] loss: 1.049\n",
      "[4,   400] loss: 1.011\n",
      "[4,   500] loss: 1.186\n",
      "[4,   600] loss: 1.030\n",
      "[4,   700] loss: 0.920\n",
      "[4,   800] loss: 0.967\n",
      "[4,   900] loss: 1.048\n",
      "[5,   100] loss: 0.989\n",
      "[5,   200] loss: 1.169\n",
      "[5,   300] loss: 1.030\n",
      "[5,   400] loss: 0.975\n",
      "[5,   500] loss: 1.153\n",
      "[5,   600] loss: 1.001\n",
      "[5,   700] loss: 0.870\n",
      "[5,   800] loss: 0.931\n",
      "[5,   900] loss: 0.993\n",
      "[6,   100] loss: 0.920\n",
      "[6,   200] loss: 1.096\n",
      "[6,   300] loss: 0.991\n",
      "[6,   400] loss: 0.938\n",
      "[6,   500] loss: 1.117\n",
      "[6,   600] loss: 0.957\n",
      "[6,   700] loss: 0.822\n",
      "[6,   800] loss: 0.884\n",
      "[6,   900] loss: 0.935\n",
      "[7,   100] loss: 0.859\n",
      "[7,   200] loss: 1.032\n",
      "[7,   300] loss: 0.958\n",
      "[7,   400] loss: 0.917\n",
      "[7,   500] loss: 1.073\n",
      "[7,   600] loss: 0.927\n",
      "[7,   700] loss: 0.778\n",
      "[7,   800] loss: 0.851\n",
      "[7,   900] loss: 0.878\n",
      "[8,   100] loss: 0.794\n",
      "[8,   200] loss: 0.953\n",
      "[8,   300] loss: 0.908\n",
      "[8,   400] loss: 0.861\n",
      "[8,   500] loss: 1.022\n",
      "[8,   600] loss: 0.901\n",
      "[8,   700] loss: 0.744\n",
      "[8,   800] loss: 0.806\n",
      "[8,   900] loss: 0.837\n",
      "Finished Training\n",
      "Accuracy on the test set: 63 %\n",
      "[1,   100] loss: 1.697\n",
      "[1,   200] loss: 1.466\n",
      "[1,   300] loss: 1.178\n",
      "[1,   400] loss: 1.153\n",
      "[1,   500] loss: 1.312\n",
      "[1,   600] loss: 1.138\n",
      "[1,   700] loss: 1.102\n",
      "[1,   800] loss: 1.066\n",
      "[1,   900] loss: 1.197\n",
      "[2,   100] loss: 1.068\n",
      "[2,   200] loss: 1.292\n",
      "[2,   300] loss: 1.068\n",
      "[2,   400] loss: 1.096\n",
      "[2,   500] loss: 1.237\n",
      "[2,   600] loss: 1.074\n",
      "[2,   700] loss: 1.007\n",
      "[2,   800] loss: 1.033\n",
      "[2,   900] loss: 1.146\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-13-4407296c844d>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     43\u001b[0m             \u001b[1;31m#print(output)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     44\u001b[0m             \u001b[0mloss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 45\u001b[1;33m             \u001b[0mloss\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     46\u001b[0m             \u001b[0moptimizer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     47\u001b[0m             \u001b[0mrunning_loss\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[0mloss\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\torch\\tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[1;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[0;32m    243\u001b[0m                 \u001b[0mcreate_graph\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcreate_graph\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    244\u001b[0m                 inputs=inputs)\n\u001b[1;32m--> 245\u001b[1;33m         \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    246\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    247\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\torch\\autograd\\__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[1;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[0;32m    143\u001b[0m         \u001b[0mretain_graph\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    144\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 145\u001b[1;33m     Variable._execution_engine.run_backward(\n\u001b[0m\u001b[0;32m    146\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgrad_tensors_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    147\u001b[0m         allow_unreachable=True, accumulate_grad=True)  # allow_unreachable flag\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "test_accuracy = []\n",
    "\n",
    "# train 10 times FOR STATISTICS\n",
    "for train_index, test_index in kf.split(X): # K-FOLD CROSS VALIDATION\n",
    "    net = lstm(input_size=19, hidden_size=100, num_layers=1, seq_length=4, output_size=7).float() # reset NN\n",
    "    learning_rate = 0.001\n",
    "    optimizer = optim.Adam(net.parameters(), lr=learning_rate)\n",
    "    \n",
    "    # split test and train\n",
    "    x_train, x_test = X[train_index], X[test_index]\n",
    "    y_train, y_test = Y[train_index], Y[test_index]\n",
    "    \n",
    "    # to torch tensor\n",
    "    x_train = torch.tensor(x_train)\n",
    "    y_train = torch.tensor(y_train).to(torch.int64)\n",
    "    x_test = torch.tensor(x_test)\n",
    "    y_test = torch.tensor(y_test).to(torch.int64)\n",
    "\n",
    "    # weighted cross entropy\n",
    "    unique, counts = np.unique(y_train, return_counts=True)\n",
    "    nSamples = [887, 6130, 480, 317, 972, 101, 128]\n",
    "    normedWeights = [(1 - (x / sum(counts))) for x in counts]\n",
    "    normedWeights = torch.FloatTensor(normedWeights).to(device)\n",
    "    criterion = nn.CrossEntropyLoss(weight=normedWeights)\n",
    "    \n",
    "    # train the network\n",
    "    for epoch in range(8):\n",
    "        running_loss = 0.0\n",
    "        net.train()\n",
    "        for i in range(len(x_train)):\n",
    "            \n",
    "            inputs, labels =torch.unsqueeze(x_train[i], 0).to(device).float(), torch.unsqueeze(y_train[i], 0).to(device)\n",
    "            \n",
    "            # zero the parameter gradients\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            # forward + backward + optimize\n",
    "            outputs, (hn, cn) = net(inputs)\n",
    "            output = torch.mean(outputs, dim=1) # takes the average over the outputs \n",
    "            #print(output)\n",
    "            #print(outputs)\n",
    "            #output = torch.unsqueeze(outputs[-1][-1], 0)  # takes the last output\n",
    "            #print(output)\n",
    "            loss = criterion(output, labels)\n",
    "            loss.backward() \n",
    "            optimizer.step()\n",
    "            running_loss += loss.item()\n",
    "\n",
    "            # statistics tensorboard\n",
    "            if i % 100 == 99:    # every 30 mini-batches\n",
    "\n",
    "                # print\n",
    "                print('[%d, %5d] loss: %.3f' %\n",
    "                      (epoch + 1, i + 1, running_loss / 100))\n",
    "\n",
    "                running_loss = 0.0\n",
    "\n",
    "    print('Finished Training')\n",
    "    \n",
    "    \n",
    "    # validation \n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        net.eval()\n",
    "        for i in range(len(x_test)):\n",
    "            inputs, labels =torch.unsqueeze(x_test[i], 0).to(device).float(), torch.unsqueeze(y_test[i], 0).to(device)\n",
    "            outputs, (hn, cn) = net(inputs)\n",
    "            output = torch.mean(outputs, dim=1)  \n",
    "            _, predicted = torch.max(output.data, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "    final = 100 * correct / total\n",
    "    print('Accuracy on the test set: %d %%' % (final))\n",
    "    test_accuracy.append(final)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean 54.7008547008547\n",
      "stdev 5.412777392970396\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "#acc = np.array(test_accuracy)\n",
    "#np.append(acc, 54.700854700854705)\n",
    "plt.hist(acc, bins=10)\n",
    "plt.title(r'Histogram of test accuracies')\n",
    "plt.show()\n",
    "mean = np.mean(acc)\n",
    "print(\"mean\", mean)\n",
    "print(\"stdev\", np.std(acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'histogram_rnn' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-23-97bb5ef325b4>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m plt.savefig(histogram_rnn, dpi=None, facecolor='w', edgecolor='w',\n\u001b[0m\u001b[0;32m      2\u001b[0m         \u001b[0morientation\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'portrait'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpapertype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mformat\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m         \u001b[0mtransparent\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbbox_inches\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpad_inches\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0.1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m         frameon=None, metadata=None)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'histogram_rnn' is not defined"
     ]
    }
   ],
   "source": [
    "plt.savefig(histogram_rnn, dpi=None, facecolor='w', edgecolor='w',\n",
    "        orientation='portrait', papertype=None, format=None,\n",
    "        transparent=False, bbox_inches=None, pad_inches=0.1,\n",
    "        frameon=None, metadata=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "acc = np.append(acc, 54.700854700854705)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([64.42307692, 59.61538462, 44.23076923, 55.76923077, 53.84615385,\n",
       "       55.76923077, 50.96153846, 58.65384615, 49.03846154, 54.7008547 ])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[64.42307692307692, 59.61538461538461, 44.23076923076923, 55.76923076923077, 53.84615384615385, 55.76923076923077, 50.96153846153846, 58.65384615384615, 49.03846153846154]\n"
     ]
    }
   ],
   "source": [
    "print(test_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[63.46153846153846]\n"
     ]
    }
   ],
   "source": [
    "print(test_accuracy)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "IR1",
   "language": "python",
   "name": "ir1"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
