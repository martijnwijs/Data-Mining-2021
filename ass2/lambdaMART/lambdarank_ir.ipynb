{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "parallel-biotechnology",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import itertools\n",
    "from argparse import Namespace\n",
    "from collections import OrderedDict\n",
    "from functools import partial\n",
    "\n",
    "\n",
    "import torch\n",
    "import numpy as np\n",
    "from torch import nn\n",
    "from torch.optim import Adam\n",
    "import torch.nn.functional as F\n",
    "from tqdm.notebook import tqdm, trange\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.pyplot import cm\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "# import dataset\n",
    "import evaluate\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "martial-functionality",
   "metadata": {},
   "source": [
    "## Read data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "arabic-documentation",
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAIN_DATA = \"../data/set_neg_zero_aff1.csv\"\n",
    "all_data = pd.read_csv(TRAIN_DATA)\n",
    "\n",
    "# Read the data into memory\n",
    "# training_data = pd.read_csv(TRAIN_DATA,nrows= 2500000)\n",
    "# validation_data = pd.read_csv(TRAIN_DATA,skiprows=2500000,nrows = 1000000, header=None, names= training_data.columns)\n",
    "# test_data = pd.read_csv(TRAIN_DATA,skiprows= 3500000,nrows = 1000000, header=None,names= training_data.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "equal-publication",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create label column\n",
    "\n",
    "def relevance(a):\n",
    "    if a[0] == a[1] == 1:\n",
    "        return 5\n",
    "    elif a[0] == 1 and a[1] == 0:\n",
    "        return 1\n",
    "    else:\n",
    "        return 0\n",
    "\n",
    "all_data['label'] = all_data[['click_bool', 'booking_bool']].apply(relevance,axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "herbal-modeling",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Divide into splits \n",
    "training_data = all_data[0:100000]\n",
    "validation_data = all_data[2500000:2600000]\n",
    "test_data = all_data[3500000:4500000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "whole-frontier",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>srch_id</th>\n",
       "      <th>date_time</th>\n",
       "      <th>site_id</th>\n",
       "      <th>visitor_location_country_id</th>\n",
       "      <th>visitor_hist_starrating</th>\n",
       "      <th>visitor_hist_adr_usd</th>\n",
       "      <th>prop_country_id</th>\n",
       "      <th>prop_id</th>\n",
       "      <th>prop_starrating</th>\n",
       "      <th>prop_review_score</th>\n",
       "      <th>...</th>\n",
       "      <th>comp7_rate</th>\n",
       "      <th>comp7_inv</th>\n",
       "      <th>comp7_rate_percent_diff</th>\n",
       "      <th>comp8_rate</th>\n",
       "      <th>comp8_inv</th>\n",
       "      <th>comp8_rate_percent_diff</th>\n",
       "      <th>click_bool</th>\n",
       "      <th>gross_bookings_usd</th>\n",
       "      <th>booking_bool</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>2013-04-04 08:32:15</td>\n",
       "      <td>12</td>\n",
       "      <td>187</td>\n",
       "      <td>-10.0</td>\n",
       "      <td>-10.0</td>\n",
       "      <td>219</td>\n",
       "      <td>893</td>\n",
       "      <td>3</td>\n",
       "      <td>3.5</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>2013-04-04 08:32:15</td>\n",
       "      <td>12</td>\n",
       "      <td>187</td>\n",
       "      <td>-10.0</td>\n",
       "      <td>-10.0</td>\n",
       "      <td>219</td>\n",
       "      <td>10404</td>\n",
       "      <td>4</td>\n",
       "      <td>4.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>2013-04-04 08:32:15</td>\n",
       "      <td>12</td>\n",
       "      <td>187</td>\n",
       "      <td>-10.0</td>\n",
       "      <td>-10.0</td>\n",
       "      <td>219</td>\n",
       "      <td>21315</td>\n",
       "      <td>3</td>\n",
       "      <td>4.5</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>2013-04-04 08:32:15</td>\n",
       "      <td>12</td>\n",
       "      <td>187</td>\n",
       "      <td>-10.0</td>\n",
       "      <td>-10.0</td>\n",
       "      <td>219</td>\n",
       "      <td>27348</td>\n",
       "      <td>2</td>\n",
       "      <td>4.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>2013-04-04 08:32:15</td>\n",
       "      <td>12</td>\n",
       "      <td>187</td>\n",
       "      <td>-10.0</td>\n",
       "      <td>-10.0</td>\n",
       "      <td>219</td>\n",
       "      <td>29604</td>\n",
       "      <td>4</td>\n",
       "      <td>3.5</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 55 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   srch_id            date_time  site_id  visitor_location_country_id  \\\n",
       "0        1  2013-04-04 08:32:15       12                          187   \n",
       "1        1  2013-04-04 08:32:15       12                          187   \n",
       "2        1  2013-04-04 08:32:15       12                          187   \n",
       "3        1  2013-04-04 08:32:15       12                          187   \n",
       "4        1  2013-04-04 08:32:15       12                          187   \n",
       "\n",
       "   visitor_hist_starrating  visitor_hist_adr_usd  prop_country_id  prop_id  \\\n",
       "0                    -10.0                 -10.0              219      893   \n",
       "1                    -10.0                 -10.0              219    10404   \n",
       "2                    -10.0                 -10.0              219    21315   \n",
       "3                    -10.0                 -10.0              219    27348   \n",
       "4                    -10.0                 -10.0              219    29604   \n",
       "\n",
       "   prop_starrating  prop_review_score  ...  comp7_rate  comp7_inv  \\\n",
       "0                3                3.5  ...         0.0        0.0   \n",
       "1                4                4.0  ...         0.0        0.0   \n",
       "2                3                4.5  ...         0.0        0.0   \n",
       "3                2                4.0  ...         0.0        0.0   \n",
       "4                4                3.5  ...         0.0        0.0   \n",
       "\n",
       "   comp7_rate_percent_diff  comp8_rate  comp8_inv  comp8_rate_percent_diff  \\\n",
       "0                      0.0         0.0        0.0                      0.0   \n",
       "1                      0.0         0.0        0.0                      0.0   \n",
       "2                      0.0         0.0        0.0                      0.0   \n",
       "3                      0.0        -1.0        0.0                      5.0   \n",
       "4                      0.0         0.0        0.0                      0.0   \n",
       "\n",
       "   click_bool  gross_bookings_usd  booking_bool  label  \n",
       "0           0                 NaN             0      0  \n",
       "1           0                 NaN             0      0  \n",
       "2           0                 NaN             0      0  \n",
       "3           0                 NaN             0      0  \n",
       "4           0                 NaN             0      0  \n",
       "\n",
       "[5 rows x 55 columns]"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_data.head"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "noble-vegetable",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.0e+00,  1.0e+00,  1.2e+01, ...,  0.0e+00,  0.0e+00,  0.0e+00],\n",
       "       [ 0.0e+00,  1.0e+00,  1.2e+01, ...,  0.0e+00,  0.0e+00,  0.0e+00],\n",
       "       [ 0.0e+00,  1.0e+00,  1.2e+01, ...,  0.0e+00,  0.0e+00,  0.0e+00],\n",
       "       ...,\n",
       "       [ 0.0e+00,  6.7e+03,  5.0e+00, ...,  0.0e+00,  0.0e+00,  0.0e+00],\n",
       "       [ 0.0e+00,  6.7e+03,  5.0e+00, ...,  0.0e+00,  0.0e+00,  0.0e+00],\n",
       "       [ 0.0e+00,  6.7e+03,  5.0e+00, ..., -1.0e+00,  0.0e+00,  1.4e+01]])"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "col_names = list(training_data.columns)\n",
    "col_names.remove('click_bool')\n",
    "col_names.remove('booking_bool')\n",
    "col_names.remove('srch_id')\n",
    "col_names.remove('date_time')\n",
    "col_names.remove('gross_bookings_usd')\n",
    "col_names.remove('label')\n",
    "\n",
    "inputdf = training_data[['label'] + ['srch_id'] + col_names]\n",
    "\n",
    "# df = df[ ['Mid'] + [ col for col in df.columns if col != 'Mid' ] ]\n",
    "\n",
    "# print(col_names)\n",
    "# print(training_data[training_data['srch_id']==1][col_names].values)\n",
    "inputdf.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "considered-sarah",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_data(data, column_names): \n",
    "    \"\"\"\n",
    "    This function reads the data set. \n",
    "    Input: \n",
    "        data: pandas dataframe \n",
    "        column_names: names of the values you want to use         \n",
    "    \"\"\"\n",
    "    features = []\n",
    "    labels = []\n",
    "    queries = data.srch_id.unique()\n",
    "    for query in queries: \n",
    "        features_i = data[data['srch_id']==query][column_names].values\n",
    "        features_i = torch.FloatTensor(features_i)\n",
    "        features.append(features_i)\n",
    "        labels_i = torch.FloatTensor(data['label'].values)\n",
    "        labels.append(labels_i)\n",
    "        \n",
    "    return queries, features, labels       \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "whole-announcement",
   "metadata": {},
   "outputs": [],
   "source": [
    "queries, features, train_labels = read_data(training_data, col_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "funky-thought",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.])\n"
     ]
    }
   ],
   "source": [
    "for q,l in zip(queries, labels): \n",
    "    print(q)\n",
    "    print(l)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "fewer-speaking",
   "metadata": {},
   "outputs": [],
   "source": [
    "validation_data = all_data[2500000:2600000]\n",
    "q_test, f_test, l_test = read_data(validation_data, col_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "former-figure",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([20, 49])"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f_test[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "touched-raising",
   "metadata": {},
   "outputs": [],
   "source": [
    "class QueryGroupedLTRData(Dataset):\n",
    "    def __init__(self, data, split):\n",
    "        self.split = {\n",
    "            \"train\": data.train,\n",
    "            \"validation\": data.validation,\n",
    "            \"test\": data.test\n",
    "        }.get(split)\n",
    "        assert self.split is not None, \"Invalid split!\"\n",
    "    \n",
    "    def __len__(self):\n",
    "        return self.split.num_queries()\n",
    "\n",
    "    def __getitem__(self, q_i):\n",
    "        feature = torch.FloatTensor(self.split.query_feat(q_i))\n",
    "        labels = torch.FloatTensor(self.split.query_labels(q_i))\n",
    "        return q_i, feature, labels\n",
    "\n",
    "# the return types are different from what pytorch expects, \n",
    "# so we will define a custom collate function which takes in\n",
    "# a batch and returns tensors (qids, features, labels) \n",
    "def qg_collate_fn(batch):\n",
    "    \n",
    "    qids = []\n",
    "    features = []\n",
    "    labels = []\n",
    "    \n",
    "    for (q, f, l) in batch:\n",
    "        qids.append(q)\n",
    "        features.append(f)\n",
    "        labels.append(l)\n",
    "    \n",
    "    return qids, features, labels\n",
    "    \n",
    "    \n",
    "## example - NOTE the collate_fn argument!\n",
    "train_dl = DataLoader(QueryGroupedLTRData(data, \"train\"), batch_size=1, shuffle=True, collate_fn=qg_collate_fn)\n",
    "# this is how you would use it to quickly iterate over the train/val/test sets \n",
    "for (qids, x, y) in train_dl:\n",
    "    # different from the previous data loader, qids, x and y aren't tensors, but lists!\n",
    "    for q_i, features_i, labels_i in zip(qids, x, y):\n",
    "        print(f\"Query {q_i} has {len(features_i)} query-document pairs\")\n",
    "        print(f\"Shape of features for Query {q_i}: {features_i.size()}\")\n",
    "        break\n",
    "    break\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "representative-therapist",
   "metadata": {},
   "source": [
    "## LambdaRank"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "experienced-broadway",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CHANGE: THE NUMBER OF FEATURES 501 TO WHATEVER WE HAVE\n",
    "\n",
    "class NeuralModule(nn.Module):\n",
    "    def __init__(self, output_dim):\n",
    "        \"\"\"\n",
    "        Initializes the Pointwise neural network. \n",
    "        Input: output_dim: The dimension of the output layer. In this assignment, \n",
    "                it is either 1 (regression) or 5 (classification)\n",
    "        \"\"\"\n",
    "        \n",
    "        super(NeuralModule, self).__init__()\n",
    "        self.output_dim = output_dim    \n",
    "        self.layer = nn.Sequential(nn.Linear(49, 16), \n",
    "                                   nn.ReLU(), \n",
    "                                   nn.Linear(16, self.output_dim))\n",
    "    \n",
    "    def forward(self, x):\n",
    "        \"\"\"\n",
    "        Takes in an input feature vector (of size 501) and produces the (regression/classification) output \n",
    "        Input: x: a [N, 501] tensor\n",
    "        Output: a [N, output_dim] tensor\n",
    "        \"\"\"\n",
    "        \n",
    "        result = self.layer(x)\n",
    "        return result\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "muslim-scotland",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clf_pred(inp, net):\n",
    "    \"\"\"\n",
    "    The output of the classifier network produces a [Nx5] output corresponding to \n",
    "    the relevance labels (each row does *not* add to 1!)\n",
    "    This function should predict the most probable relevance from the relevance labels\n",
    "    \n",
    "    inp: The input [N, num_features]\n",
    "    net: the neural network, takes in [N, num_features] and outputs [N, 5]\n",
    "    \n",
    "    return: a [N, 1] (long) tensor, the relevance labels\n",
    "    \"\"\"\n",
    "\n",
    "    output = net(inp)\n",
    "    \n",
    "    prediction = output.argmax(dim=1).detach()\n",
    "    \n",
    "    return prediction\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "neither-spray",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Implement this! (30 points)\n",
    "def compute_lambda_ij(scores, labels): \n",
    "    \n",
    "    N = len(scores)\n",
    "    if N < 2:\n",
    "        return None\n",
    "    \n",
    "    labels = labels.reshape(N, 1)\n",
    "    scores = scores.reshape(N, 1)\n",
    "    \n",
    "    # Create matrices from scores and labels\n",
    "    scores_i = torch.cat(N*[scores], dim=1)\n",
    "    scores_j= torch.transpose(scores_i, 0, 1)\n",
    "    labels_i = torch.cat(N*[labels], dim=1)\n",
    "    labels_j= torch.transpose(labels_i, 0, 1)\n",
    "    \n",
    "    # Compute Sij\n",
    "    Sij = torch.ones_like(labels_i)\n",
    "    Sij[labels_i == labels_j] = 0\n",
    "    Sij[labels_i<labels_j] = -1\n",
    "    \n",
    "    # Compute lambda_ij\n",
    "    lambda_ij = 0.5*(1-Sij) - 1/(1+torch.exp(scores_i-scores_j))\n",
    "    \n",
    "    return lambda_ij\n",
    "    \n",
    "\n",
    "def listwise_loss(scores, labels):\n",
    "    \n",
    "    \"\"\"\n",
    "    Compute the LambdaRank loss. (assume sigma=1.)\n",
    "    \n",
    "    scores: tensor of size [N, 1] (the output of a neural network), where N = length of <query, document> pairs\n",
    "    labels: tensor of size [N], contains the relevance labels \n",
    "    \n",
    "    returns: a tensor of size [N, 1]\n",
    "    \"\"\"\n",
    "    \n",
    "    N = len(scores)\n",
    "    # YOUR CODE HERE\n",
    "    if N < 2: \n",
    "        return None\n",
    "    \n",
    "    # calculate lambda_ij\n",
    "    lambda_ij = compute_lambda_ij(scores, labels)\n",
    "    \n",
    "    # calculate idcg\n",
    "    sorted_labels, _ = torch.sort(labels, descending=True)\n",
    "    ranks = torch.arange(2., N+2.)\n",
    "    idcg = torch.sum((2**sorted_labels-1) / torch.log2(ranks)) + 0.01\n",
    "    \n",
    "    # reshape labels\n",
    "    labels = labels.view(N,1)\n",
    "    \n",
    "    # create tensor with ranking of scores \n",
    "    _, indices = torch.sort(scores, descending=True, dim=0)\n",
    "    indices = indices.view(N,1)\n",
    "    rank_i = torch.cat(N*[indices.float()], dim=1)\n",
    "    rank_j = torch.transpose(rank_i, 0, 1)\n",
    "    \n",
    "    # create tensor with relevance scores\n",
    "    rel = labels[indices.view(N)]\n",
    "    rel_i = torch.cat(N*[rel], dim=1)\n",
    "    rel_j = torch.transpose(rel_i, 0, 1)\n",
    "    \n",
    "    # calculate difference in dcg for i, j    \n",
    "    diff_dcg = (2**rel_i - 2**rel_j)/torch.log2(rank_i+2) + (2**rel_j - 2**rel_i)/torch.log2(rank_j+2) \n",
    "    \n",
    "    ndcg = torch.abs(diff_dcg/idcg)\n",
    "    \n",
    "    loss_ij = ndcg * lambda_ij\n",
    "    \n",
    "    loss_i = torch.sum(loss_ij, 1)\n",
    "    \n",
    "    return loss_i.reshape(N, 1)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "abandoned-hayes",
   "metadata": {},
   "outputs": [],
   "source": [
    "# this function evaluates a model, on a given split\n",
    "def evaluate_model(pred_fn, features, labels):\n",
    "    \n",
    "    scores = []\n",
    "    np_labels = []\n",
    "    for x, y in zip(features, labels): \n",
    "        np_labels.append(y.squeeze().numpy)\n",
    "        with torch.no_grad(): \n",
    "            score = pred_fn(features)\n",
    "            scores.append(score.numpy())\n",
    "        \n",
    "    results = evaluate.evaluate2(np.asarray(scores), np.asarray(np_labels))\n",
    "    \n",
    "    return results "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "resistant-yukon",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Implement this! (50 points)\n",
    "def train_listwise(net, params, queries, features, labels):\n",
    "    \"\"\"\n",
    "    This function should train the given network using the listwise (LambdaRank) loss\n",
    "    \n",
    "    Note: Do not change the function definition! \n",
    "    Note: You can assume params.batch_size will always be equal to 1\n",
    "    \n",
    "    \n",
    "    net: the neural network to be trained\n",
    "    \n",
    "    params: params is an object which contains config used in training \n",
    "        (eg. params.epochs - the number of epochs to train). \n",
    "        For a full list of these params, see the next cell. \n",
    "        \n",
    "    Returns: a dictionary containing: \"metrics_val\" (a list of dictionaries) and \n",
    "             \"metrics_train\" (a list of dictionaries). \n",
    "             \n",
    "             \"metrics_val\" should contain metrics (the metrics in params.metrics) computed\n",
    "             after each epoch on the validation set (metrics_train is similar). \n",
    "             You can use this to debug your models\n",
    "    \"\"\"\n",
    "    \n",
    "    val_metrics_epoch = []\n",
    "    train_metrics_epoch = []\n",
    "\n",
    "    optimizer = torch.optim.Adam(net.parameters(), lr=params.lr)\n",
    "    criterion = listwise_loss\n",
    "    pred_fn = partial(clf_pred, net=net)\n",
    "    \n",
    "    for i in range(params.epochs):         \n",
    "        net.train()\n",
    "        for q_i, features_i, labels_i in zip(queries, features, labels):\n",
    "            print((q_i), (features_i.shape))\n",
    "                \n",
    "            net.zero_grad()\n",
    "                \n",
    "            scores = net(features_i)\n",
    "            print(scores.shape)\n",
    "            print(labels_i.shape)\n",
    "                \n",
    "            loss = criterion(scores, labels_i)\n",
    "                \n",
    "            if loss is None: \n",
    "                continue\n",
    "                \n",
    "            torch.autograd.backward(scores, loss)\n",
    "                \n",
    "            optimizer.step()\n",
    "\n",
    "        net.eval()\n",
    "    \n",
    "        with torch.no_grad():  \n",
    "            \n",
    "            train_metrics = evaluate_model(pred_fn, features, labels)\n",
    "            eval_metrics = evaluate_model(pred_fn, f_test, l_test)\n",
    "\n",
    "            \n",
    "        train_m = {m: train_metrics[m] for m in params.metrics}\n",
    "        eval_m = {m: eval_metrics[m] for m in params.metrics}\n",
    "            \n",
    "        train_metrics_epoch.append(train_m)\n",
    "        val_metrics_epoch.append(eval_m)\n",
    "        \n",
    "    \n",
    "    return {\n",
    "        \"metrics_val\": val_metrics_epoch,\n",
    "        \"metrics_train\": train_metrics_epoch\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "available-bookmark",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 torch.Size([28, 49])\n",
      "torch.Size([28, 1])\n",
      "torch.Size([100000])\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "shape '[28, 1]' is invalid for input of size 100000",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-72-ed50560864a8>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mlistwise_params_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mNamespace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1e-3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmetrics\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m\"ndcg\"\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mlistwise_net\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mNeuralModule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mtrain_listwise\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlistwise_net\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlistwise_params_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mqueries\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeatures\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_labels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;31m# evaluate_model(listwise_net, \"test\", print_results=True)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-67-a14cefbcd97a>\u001b[0m in \u001b[0;36mtrain_listwise\u001b[0;34m(net, params, queries, features, labels)\u001b[0m\n\u001b[1;32m     40\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabels_i\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     41\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 42\u001b[0;31m             \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mscores\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels_i\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     43\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     44\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mloss\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-27-378a3aa14b61>\u001b[0m in \u001b[0;36mlistwise_loss\u001b[0;34m(scores, labels)\u001b[0m\n\u001b[1;32m     43\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     44\u001b[0m     \u001b[0;31m# calculate lambda_ij\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 45\u001b[0;31m     \u001b[0mlambda_ij\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompute_lambda_ij\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mscores\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     46\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     47\u001b[0m     \u001b[0;31m# calculate idcg\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-27-378a3aa14b61>\u001b[0m in \u001b[0;36mcompute_lambda_ij\u001b[0;34m(scores, labels)\u001b[0m\n\u001b[1;32m      6\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m     \u001b[0mlabels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mN\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m     \u001b[0mscores\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mscores\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mN\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: shape '[28, 1]' is invalid for input of size 100000"
     ]
    }
   ],
   "source": [
    "listwise_params_test = Namespace(epochs=1, lr=1e-3, batch_size=1, metrics={\"ndcg\"})\n",
    "listwise_net = NeuralModule(1)\n",
    "train_listwise(listwise_net, listwise_params_test, queries, features, train_labels)\n",
    "# evaluate_model(listwise_net, \"test\", print_results=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "curious-president",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4046"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_labels)\n",
    "len(queries)\n",
    "len(features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "owned-supervision",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "IR1",
   "language": "python",
   "name": "ir1"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
